import os
import sys
import json
import cv2
import numpy as np
import torch
from argparse import ArgumentParser
from arguments import ModelParams
from scene import Scene, GaussianModel
from gaussian_renderer import render
from utils.image_utils import psnr
from utils.camera_utils import cameraList_from_camInfos
from tqdm import tqdm
from scipy.spatial.distance import cdist
from skimage.metrics import structural_similarity as ssim_sk
from skimage.metrics import peak_signal_noise_ratio as psnr_sk
import warnings

# Suppress a specific warning from scikit-image
warnings.filterwarnings("ignore", category=UserWarning, message="Inputs have mismatched dtype")

# ==============================================================================
#                      1. æŒ‡æ ‡è®¡ç®—çš„æ ¸å¿ƒå‡½æ•°
# ==============================================================================

def get_canny_edges(image_np):
    """ä½¿ç”¨Cannyç®—æ³•æå–è¾¹ç¼˜"""
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    return edges

def calculate_edge_fscore(pred_edges, gt_edges, threshold=3):
    """
    è®¡ç®—è¾¹ç¼˜F-scoreï¼Œå…è®¸ä¸€å®šåƒç´ çš„å®¹å·®ã€‚
    ä½¿ç”¨è·ç¦»å˜æ¢æ¥é«˜æ•ˆå®ç°ã€‚
    """
    if pred_edges.sum() == 0 or gt_edges.sum() == 0:
        return 0.0, 0.0, 0.0 # Precision, Recall, F1

    # è®¡ç®—ä»GTè¾¹ç¼˜åˆ°æ¯ä¸ªé¢„æµ‹è¾¹ç¼˜åƒç´ çš„è·ç¦»
    dist_transform = cv2.distanceTransform(255 - gt_edges, cv2.DIST_L2, 5)
    pred_on_gt = dist_transform[pred_edges != 0]

    # è®¡ç®—ä»é¢„æµ‹è¾¹ç¼˜åˆ°æ¯ä¸ªGTè¾¹ç¼˜åƒç´ çš„è·ç¦»
    dist_transform_inv = cv2.distanceTransform(255 - pred_edges, cv2.DIST_L2, 5)
    gt_on_pred = dist_transform_inv[gt_edges != 0]

    # è®¡ç®—Precisionå’ŒRecall
    precision = np.sum(pred_on_gt < threshold) / len(pred_on_gt)
    recall = np.sum(gt_on_pred < threshold) / len(gt_on_pred)
    
    # è®¡ç®—F1-score
    if precision + recall == 0:
        f1 = 0.0
    else:
        f1 = 2 * (precision * recall) / (precision + recall)
        
    return precision, recall, f1

def calculate_chamfer_distance(pred_edges, gt_edges):
    """è®¡ç®—å€’è§’è·ç¦»"""
    gt_points = np.array(np.where(gt_edges != 0)).T
    pred_points = np.array(np.where(pred_edges != 0)).T

    if len(gt_points) == 0 or len(pred_points) == 0:
        return np.inf

    # è®¡ç®— pred_points åˆ° gt_points çš„è·ç¦»
    dist1 = cdist(pred_points, gt_points).min(axis=1).mean()
    # è®¡ç®— gt_points åˆ° pred_points çš„è·ç¦»
    dist2 = cdist(gt_points, pred_points).min(axis=1).mean()

    return (dist1 + dist2) / 2

def get_lsd_lines(image_np):
    """ä½¿ç”¨LSDç®—æ³•æå–ç›´çº¿"""
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    lsd = cv2.createLineSegmentDetector(0)
    lines, _, _, _ = lsd.detect(gray)
    if lines is None:
        return []
    return lines.squeeze(1) # [N, 4] -> x1, y1, x2, y2

def calculate_lses_metrics(pred_lines, gt_lines, dist_thresh=5, angle_thresh=5, overlap_thresh=0.5):
    """è®¡ç®—LSESå¥—ä»¶: L-Recall, L-Precision, L-Fidelity"""
    if len(gt_lines) == 0:
        # å¦‚æœçœŸå€¼æ²¡æœ‰ç›´çº¿ï¼Œç²¾ç¡®ç‡å°±æ˜¯1ï¼ˆå¦‚æœæ²¡æœ‰é¢„æµ‹ç›´çº¿ï¼‰æˆ–0ï¼ˆå¦‚æœæœ‰é¢„æµ‹ç›´çº¿ï¼‰
        l_precision = 1.0 if len(pred_lines) == 0 else 0.0
        return 0.0, l_precision, (np.inf, np.inf) # Recall, Precision, (Endpoint Err, Angle Err)
    
    if len(pred_lines) == 0:
        return 0.0, 1.0, (np.inf, np.inf) # å¦‚æœæ²¡é¢„æµ‹å‡ºç›´çº¿ï¼Œå¬å›ç‡ä¸º0ï¼Œç²¾ç¡®ç‡ä¸º1

    # ä¸ºæ¯æ¡GTç›´çº¿å¯»æ‰¾æœ€ä½³åŒ¹é…
    matches = []
    matched_pred_indices = set()

    for i, l_gt in enumerate(gt_lines):
        x1_gt, y1_gt, x2_gt, y2_gt = l_gt
        p1_gt, p2_gt = np.array([x1_gt, y1_gt]), np.array([x2_gt, y2_gt])
        mid_gt = (p1_gt + p2_gt) / 2
        vec_gt = p2_gt - p1_gt
        angle_gt = np.rad2deg(np.arctan2(vec_gt[1], vec_gt[0]))
        len_gt = np.linalg.norm(vec_gt)

        best_match = None
        min_dist = np.inf
        best_pred_idx = -1

        for j, l_pred in enumerate(pred_lines):
            if j in matched_pred_indices:
                continue # å·²è¢«åŒ¹é…çš„é¢„æµ‹ç›´çº¿ä¸å†å‚ä¸åŒ¹é…

            x1_p, y1_p, x2_p, y2_p = l_pred
            p1_p, p2_p = np.array([x1_p, y1_p]), np.array([x2_p, y2_p])
            mid_p = (p1_p + p2_p) / 2
            
            # 1. è·ç¦»å‡†åˆ™
            dist = np.linalg.norm(mid_gt - mid_p)
            if dist > dist_thresh:
                continue
            
            # 2. è§’åº¦å‡†åˆ™
            vec_p = p2_p - p1_p
            angle_p = np.rad2deg(np.arctan2(vec_p[1], vec_p[0]))
            angle_diff = 180 - abs(abs(angle_gt - angle_p) - 180) # è€ƒè™‘180åº¦å·®å¼‚
            if angle_diff > angle_thresh:
                continue
            
            # 3. é‡å å‡†åˆ™
            len_p = np.linalg.norm(vec_p)
            if len_p == 0 or len_gt == 0: continue
            
            # å°† l_pred çš„ç«¯ç‚¹æŠ•å½±åˆ° l_gt æ‰€åœ¨çš„æ— é™é•¿ç›´çº¿ä¸Š
            t0 = np.dot(p1_p - p1_gt, vec_gt) / (len_gt**2)
            t1 = np.dot(p2_p - p1_gt, vec_gt) / (len_gt**2)
            
            overlap_interval = (max(0, min(t0, t1)), min(1, max(t0, t1)))
            overlap_len = (overlap_interval[1] - overlap_interval[0]) * len_gt
            
            if overlap_len / len_p < overlap_thresh and overlap_len / len_gt < overlap_thresh:
                continue

            if dist < min_dist:
                min_dist = dist
                best_match = (l_gt, l_pred, angle_diff)
                best_pred_idx = j

        if best_match:
            matches.append(best_match)
            matched_pred_indices.add(best_pred_idx)

    tp = len(matches)
    l_recall = tp / len(gt_lines)
    l_precision = tp / len(pred_lines)
    
    # è®¡ç®— L-Fidelity
    if tp > 0:
        endpoint_errors = []
        angle_errors = []
        for l_gt, l_pred, angle_diff in matches:
            p1_gt, p2_gt = l_gt[:2], l_gt[2:]
            p1_p, p2_p = l_pred[:2], l_pred[2:]
            # ç¡®ä¿ç«¯ç‚¹å¯¹åº”æ­£ç¡®
            if np.linalg.norm(p1_gt - p1_p) + np.linalg.norm(p2_gt - p2_p) > \
               np.linalg.norm(p1_gt - p2_p) + np.linalg.norm(p2_gt - p1_p):
                p1_p, p2_p = p2_p, p1_p # äº¤æ¢ç«¯ç‚¹
            
            err = (np.linalg.norm(p1_gt - p1_p) + np.linalg.norm(p2_gt - p2_p)) / 2
            endpoint_errors.append(err)
            angle_errors.append(angle_diff)
            
        avg_endpoint_err = np.mean(endpoint_errors)
        avg_angle_err = np.mean(angle_errors)
        l_fidelity = (avg_endpoint_err, avg_angle_err)
    else:
        l_fidelity = (np.inf, np.inf)

    return l_recall, l_precision, l_fidelity


# ==============================================================================
#                      2. è¯„ä¼°ä¸»æµç¨‹
# ==============================================================================

@torch.no_grad()
def evaluate(model_path):
    # --- åŠ è½½æ¨¡å‹å’Œåœºæ™¯ ---
    print(f"ğŸš€ å¼€å§‹è¯„ä¼°å®éªŒ: {os.path.basename(model_path)}")
    parser = ArgumentParser()
    model_params = ModelParams(parser, sentinel=True)
    
    # ä» cfg_args åŠ è½½é…ç½®
    args_path = os.path.join(model_path, "cfg_args")
    if not os.path.exists(args_path):
        print(f"âŒ é”™è¯¯: åœ¨ {model_path} ä¸­æœªæ‰¾åˆ° cfg_argsã€‚æ— æ³•ç»§ç»­è¯„ä¼°ã€‚")
        return

    with open(args_path, 'r') as f:
        # ä½¿ç”¨evalæ¥è§£æNamespaceå­—ç¬¦ä¸²ï¼Œè¿™éœ€è¦ä¿¡ä»»æ¥æº
        config_namespace = eval(f.read())
    
    # å°†åŠ è½½çš„é…ç½®æ›´æ–°åˆ°æ¨¡å‹å‚æ•°ä¸­
    args = model_params.extract(config_namespace)

    gaussians = GaussianModel(args.sh_degree)
    
    # å¯»æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹
    checkpoints_dir = os.path.join(model_path, "point_cloud")
    latest_iter = -1
    for item in os.listdir(checkpoints_dir):
        if item.startswith("iteration_"):
            try:
                iteration = int(item.split("_")[-1])
                if iteration > latest_iter:
                    latest_iter = iteration
            except:
                continue

    if latest_iter == -1:
        print(f"âŒ é”™è¯¯: åœ¨ {model_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒå¥½çš„ç‚¹äº‘ã€‚")
        return
        
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æœ€æ–°çš„ç‚¹äº‘: iteration_{latest_iter}")
    ply_path = os.path.join(checkpoints_dir, f"iteration_{latest_iter}", "point_cloud.ply")
    gaussians.load_ply(ply_path)

    bg_color = [1, 1, 1] if args.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

    # --- åŠ è½½æµ‹è¯•é›†ç›¸æœº ---
    # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸´æ—¶çš„ã€ä¸å¸¦gaussiansçš„Sceneå¯¹è±¡æ¥åŠ è½½ç›¸æœº
    scene = Scene(args, OptimizationParams(ArgumentParser()), gaussians, load_iteration=-1, shuffle=False)
    test_cameras = scene.getTestCameras()

    if not test_cameras:
        print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æµ‹è¯•é›†ç›¸æœºï¼Œå°†ä½¿ç”¨è®­ç»ƒé›†ç›¸æœºè¿›è¡Œè¯„ä¼°ã€‚")
        test_cameras = scene.getTrainCameras()
    if not test_cameras:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨äºè¯„ä¼°çš„ç›¸æœºã€‚")
        return

    # --- åˆå§‹åŒ–æŒ‡æ ‡ç´¯åŠ å™¨ ---
    metrics = {
        "psnr": [], "ssim": [],
        "edge_f1": [], "chamfer_dist": [],
        "l_recall": [], "l_precision": [],
        "l_endpoint_err": [], "l_angle_err": [],
    }
    
    render_path = os.path.join(model_path, "eval_renders")
    gt_path = os.path.join(model_path, "eval_gt")
    os.makedirs(render_path, exist_ok=True)
    os.makedirs(gt_path, exist_ok=True)
    print(f"ğŸ–¼ï¸ æ¸²æŸ“å›¾åƒå°†ä¿å­˜è‡³: {render_path}")

    # --- éå†æµ‹è¯•é›†è¿›è¡Œè¯„ä¼° ---
    for idx, camera in enumerate(tqdm(test_cameras, desc="Evaluating test set")):
        # æ¸²æŸ“å›¾åƒ
        render_pkg = render(camera, gaussians, {"antialiasing":False}, background)
        rendered_image = render_pkg["render"].clamp(0.0, 1.0)
        
        # è·å–çœŸå€¼å›¾åƒ
        gt_image = camera.original_image.clamp(0.0, 1.0)
        
        # è½¬æ¢æ ¼å¼ä¸º NumPy (H, W, C) uint8
        rendered_np = (rendered_image.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        gt_np = (gt_image.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)

        # ä¿å­˜å›¾åƒç”¨äºæ£€æŸ¥
        cv2.imwrite(os.path.join(render_path, f"{idx:04d}.png"), cv2.cvtColor(rendered_np, cv2.COLOR_RGB2BGR))
        cv2.imwrite(os.path.join(gt_path, f"{idx:04d}.png"), cv2.cvtColor(gt_np, cv2.COLOR_RGB2BGR))

        # 1. è®¡ç®—æ ‡å‡†æŒ‡æ ‡ PSNR, SSIM
        metrics["psnr"].append(psnr_sk(gt_np, rendered_np, data_range=255))
        metrics["ssim"].append(ssim_sk(gt_np, rendered_np, channel_axis=2, data_range=255))
        
        # 2. æå–è¾¹ç¼˜ç”¨äºF-scoreå’Œå€’è§’è·ç¦»
        pred_edges = get_canny_edges(rendered_np)
        gt_edges = get_canny_edges(gt_np)

        # 3. è®¡ç®—è¾¹ç¼˜F-score
        _, _, f1 = calculate_edge_fscore(pred_edges, gt_edges)
        metrics["edge_f1"].append(f1)
        
        # 4. è®¡ç®—å€’è§’è·ç¦»
        metrics["chamfer_dist"].append(calculate_chamfer_distance(pred_edges, gt_edges))
        
        # 5. æå–ç›´çº¿ç”¨äºLSES
        pred_lines = get_lsd_lines(rendered_np)
        gt_lines = get_lsd_lines(gt_np)
        
        # 6. è®¡ç®—LSESæŒ‡æ ‡
        l_r, l_p, (l_ee, l_ae) = calculate_lses_metrics(pred_lines, gt_lines)
        metrics["l_recall"].append(l_r)
        metrics["l_precision"].append(l_p)
        if not np.isinf(l_ee):
            metrics["l_endpoint_err"].append(l_ee)
            metrics["l_angle_err"].append(l_ae)

    # --- è®¡ç®—å¹¶æ‰“å°æœ€ç»ˆå¹³å‡ç»“æœ ---
    avg_metrics = {key: np.mean(val) for key, val in metrics.items() if val}
    
    print("\n" + "="*80)
    print(f"            è¯„ä¼°æ€»ç»“: {os.path.basename(model_path)}")
    print("="*80)
    print(f"  åœ¨ {len(test_cameras)} å¼ æµ‹è¯•å›¾åƒä¸Šè®¡ç®—çš„å¹³å‡æŒ‡æ ‡:")
    print("-" * 40)
    print(f"  [ åƒç´ çº§æŒ‡æ ‡ ]")
    print(f"    - PSNR:           {avg_metrics.get('psnr', 0.0):.4f} dB (è¶Šé«˜è¶Šå¥½)")
    print(f"    - SSIM:           {avg_metrics.get('ssim', 0.0):.4f} (è¶Šé«˜è¶Šå¥½)")
    print("-" * 40)
    print(f"  [ ç»“æ„çº§æŒ‡æ ‡ (åŸºäºè¾¹ç¼˜) ]")
    print(f"    - Edge F1-Score:  {avg_metrics.get('edge_f1', 0.0):.4f} (è¶Šé«˜è¶Šå¥½)")
    print(f"    - Chamfer Dist:   {avg_metrics.get('chamfer_dist', 0.0):.4f} px (è¶Šä½è¶Šå¥½)")
    print("-" * 40)
    print(f"  [ ç»“æ„çº§æŒ‡æ ‡ (LSES - åŸºäºç›´çº¿) ]")
    print(f"    - L-Recall:       {avg_metrics.get('l_recall', 0.0):.4f} (è¶Šé«˜è¶Šå¥½)")
    print(f"    - L-Precision:    {avg_metrics.get('l_precision', 0.0):.4f} (è¶Šé«˜è¶Šå¥½)")
    print(f"    - L-Endpoint Err: {avg_metrics.get('l_endpoint_err', 0.0):.4f} px (è¶Šä½è¶Šå¥½)")
    print(f"    - L-Angle Err:    {avg_metrics.get('l_angle_err', 0.0):.4f} deg (è¶Šä½è¶Šå¥½)")
    print("="*80)
    
    # å°†ç»“æœä¿å­˜åˆ°jsonæ–‡ä»¶
    results_path = os.path.join(model_path, "evaluation_metrics.json")
    with open(results_path, 'w') as f:
        json.dump(avg_metrics, f, indent=4)
    print(f"ğŸ“„ è¯¦ç»†è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {results_path}")

if __name__ == "__main__":
    parser = ArgumentParser(description="Script to evaluate a trained 3D Gaussian Splatting model with geometry-aware metrics.")
    parser.add_argument("model_path", type=str, help="Path to the trained model output directory (e.g., 'output/experiment_name').")
    
    args = parser.parse_args()
    
    evaluate(args.model_path)