# ==============================================================================
#                      IMPORTS & SETUP
# ==============================================================================
import os
import sys
import json
import numpy as np
import torch
import open3d as o3d
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from argparse import ArgumentParser, Namespace
from tqdm import tqdm
from skimage.metrics import structural_similarity as ssim_sk
from skimage.metrics import peak_signal_noise_ratio as psnr_sk
import re
import copy

try:
    import matplotlib_zh
    matplotlib_zh.use_zh()
    print("âœ… å·²å¯ç”¨matplotlib_zhä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤ºã€‚")
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° matplotlib_zh åº“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚è¯·è¿è¡Œ 'pip install matplotlib-zh'")

# å‡è®¾æ­¤è„šæœ¬ä½äºé¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.abspath(sys.argv[0]))
sys.path.insert(0, project_root)
try:
    from arguments import ModelParams, OptimizationParams, PipelineParams
    from scene import Scene, GaussianModel
    from gaussian_renderer import render
    from utils.system_utils import searchForMaxIteration
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥ï¼Œè¯·ç¡®ä¿æ­¤è„šæœ¬ä½äºgaussian-splattingé¡¹ç›®æ ¹ç›®å½•: {e}")
    sys.exit(1)

# ==============================================================================
#                      1. æ•°æ®è§£æä¸æŒ‡æ ‡è®¡ç®—å‡½æ•°
# ==============================================================================
def load_config(cfg_path: str) -> dict:
    try:
        with open(cfg_path, 'r') as f:
            return json.load(f)
    except json.JSONDecodeError:
        try:
            with open(cfg_path, 'r') as f: content = f.read().strip()
            if content.startswith("Namespace(") and content.endswith(")"): content = content[10:-1]
            pattern = re.compile(r"(\w+)\s*=\s*('([^']*)'|\"([^\"]*)\"|\[.*?\]|[\w.-]+|True|False|None)")
            matches = pattern.findall(content)
            cfg_dict = {}
            for key, val_group, str_val1, str_val2 in matches:
                val_str = val_group
                if (val_str.startswith("'") and val_str.endswith("'")) or (val_str.startswith('"') and val_str.endswith('"')): cfg_dict[key] = val_str[1:-1]
                elif val_str == 'True': cfg_dict[key] = True
                elif val_str == 'False': cfg_dict[key] = False
                elif val_str == 'None': cfg_dict[key] = None
                elif val_str.startswith('[') and val_str.endswith(']'):
                    try: cfg_dict[key] = eval(val_str)
                    except: cfg_dict[key] = val_str
                else:
                    try:
                        if '.' in val_str: cfg_dict[key] = float(val_str)
                        else: cfg_dict[key] = int(val_str)
                    except ValueError: cfg_dict[key] = val_str
            return cfg_dict
        except Exception as e: raise IOError(f"æ— æ³•å°† '{os.path.basename(cfg_path)}' è§£æä¸ºJSONæˆ–Namespaceå­—ç¬¦ä¸²ã€‚é”™è¯¯: {e}")

def parse_csv_log(exp_path: str, log_filename: str):
    log_path = os.path.join(exp_path, log_filename)
    if not os.path.exists(log_path) or os.path.getsize(log_path) == 0: return None
    try:
        df = pd.read_csv(log_path)
        return df if not df.empty else None
    except Exception as e:
        print(f"    - âŒ è¯»å– {log_path} æ—¶å‡ºé”™: {e}")
        return None

def load_gt_pcd(gt_path, voxel_size):
    try:
        pcd = o3d.io.read_point_cloud(gt_path)
        if not pcd.has_points(): return None
        downsampled_pcd = pcd.voxel_down_sample(voxel_size)
        print(f"    -> [DEBUG] çœŸå€¼ç‚¹äº‘ '{os.path.basename(gt_path)}' åŠ è½½æˆåŠŸ: å…± {len(downsampled_pcd.points)} ä¸ªç‚¹ (ä¸‹é‡‡æ ·å)")
        return downsampled_pcd
    except Exception as e:
        print(f"    -> âŒ åŠ è½½çœŸå€¼ç‚¹äº‘ '{gt_path}' æ—¶å‡ºé”™: {e}")
        return None

def align_pcd_with_icp(source_pcd, target_pcd, threshold, initial_transform=np.identity(4), max_iteration=200):
    print("    -> [INFO] æ­£åœ¨ä½¿ç”¨ICPç®—æ³•è¿›è¡Œç‚¹äº‘ç²¾ç»†å¯¹é½...")
    reg_p2p = o3d.pipelines.registration.registration_icp(
        source_pcd, target_pcd, threshold, initial_transform,
        o3d.pipelines.registration.TransformationEstimationPointToPoint(),
        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iteration))
    fitness = reg_p2p.fitness
    inlier_rmse = reg_p2p.inlier_rmse
    print(f"    -> [DEBUG] ICPå¯¹é½ç»“æœ: Fitness = {fitness:.4f}, Inlier RMSE = {inlier_rmse:.4f}")
    if fitness < 0.6:
        print("    -> [WARNING] ICP Fitnesså€¼è¾ƒä½ï¼Œç²¾ç»†å¯¹é½æ•ˆæœå¯èƒ½ä¸ä½³ï¼")
    return reg_p2p.transformation

def calculate_3d_metrics(pred_pcd, gt_pcd, f1_threshold):
    dists_pred_to_gt = pred_pcd.compute_point_cloud_distance(gt_pcd)
    dists_gt_to_pred = gt_pcd.compute_point_cloud_distance(pred_pcd)
    
    # [DEBUG] æ‰“å°ä¸€äº›è·ç¦»ç»Ÿè®¡ï¼Œæ£€æŸ¥å°ºåº¦
    mean_dist_pred_to_gt = np.mean(np.asarray(dists_pred_to_gt))
    mean_dist_gt_to_pred = np.mean(np.asarray(dists_gt_to_pred))
    print(f"    -> [DEBUG] Pred->GT å¹³å‡è·ç¦»: {mean_dist_pred_to_gt:.6f} ç±³")
    print(f"    -> [DEBUG] GT->Pred å¹³å‡è·ç¦»: {mean_dist_gt_to_pred:.6f} ç±³")
    
    chamfer_dist_l2 = (np.mean(np.asarray(dists_pred_to_gt)**2) + np.mean(np.asarray(dists_gt_to_pred)**2))
    precision = np.sum(np.asarray(dists_pred_to_gt) < f1_threshold) / len(dists_pred_to_gt)
    recall = np.sum(np.asarray(dists_gt_to_pred) < f1_threshold) / len(dists_gt_to_pred)
    print(f"    -> [DEBUG] F1-Scoreé˜ˆå€¼ = {f1_threshold} ç±³")
    print(f"    -> [DEBUG] F1-Scoreç»„æˆ: Precision = {precision:.4f}, Recall = {recall:.4f}")
    f1_score = 0.0 if precision + recall == 0 else 2 * (precision * recall) / (precision + recall)
    return {"3D_Chamfer_L2": chamfer_dist_l2, "3D_F1-Score": f1_score}

# ==============================================================================
#                      2. æ ¸å¿ƒåˆ†ææµç¨‹
# ==============================================================================

@torch.no_grad()
def evaluate_final_model(model_path: str, args: Namespace, gt_pcd_downsampled, alignment_transform: np.ndarray):
    exp_name = os.path.basename(model_path)
    print(f"\n{'â”€'*20} [INFO] å¼€å§‹è¯„ä¼°æ¨¡å‹: {exp_name} {'â”€'*20}")
    
    computed_metrics = {}
    debug_pcd_dir = os.path.join(args.parent_dir, "_debug_pcds")
    debug_2d_dir = os.path.join(args.parent_dir, "_debug_2d_eval")
    os.makedirs(debug_pcd_dir, exist_ok=True)
    os.makedirs(debug_2d_dir, exist_ok=True)
    
    try:
        print("  -> æ­¥éª¤1: æ­£åœ¨æ„å»ºæ¨¡å‹å‚æ•°...")
        parser = ArgumentParser(description="è¯„ä¼°å‚æ•°åŠ è½½å™¨")
        model_params_def = ModelParams(parser)
        opt_params_def = OptimizationParams(parser)
        
        args_defaults = parser.parse_args([])
        saved_cfg_dict = load_config(os.path.join(model_path, "cfg_args"))
        
        for key, value in saved_cfg_dict.items():
            if hasattr(args_defaults, key): setattr(args_defaults, key, value)
        
        args_defaults.model_path = model_path
        model_params = model_params_def.extract(args_defaults)
        
        print("  -> æ­¥éª¤2: æ­£åœ¨åŠ è½½é«˜æ–¯ç‚¹äº‘...")
        iteration = searchForMaxIteration(os.path.join(model_path, "point_cloud"))
        if iteration is None: raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½•è¿­ä»£ç‚¹äº‘")
        
        gaussians = GaussianModel(sh_degree=model_params.sh_degree)
        ply_path = os.path.join(model_path, "point_cloud", f"iteration_{iteration}", "point_cloud.ply")
        gaussians.load_ply(ply_path)
        print(f"    -> [DEBUG] æ¨¡å‹åŠ è½½æˆåŠŸ (è¿­ä»£æ¬¡æ•°: {iteration}, ç‚¹æ•°: {gaussians.get_xyz.shape[0]})")
        
        pred_points_colmap = gaussians.get_xyz.detach().cpu().numpy()
        pred_pcd_raw = o3d.geometry.PointCloud()
        pred_pcd_raw.points = o3d.utility.Vector3dVector(pred_points_colmap)
        
        if gt_pcd_downsampled is not None and alignment_transform is not None:
            print("  -> æ­¥éª¤3: è®¡ç®—3Då‡ ä½•æŒ‡æ ‡...")
            
            # 1. ç²—ç•¥å¯¹é½çŸ©é˜µ (Colmap/GS -> World)
            initial_transform_inv = alignment_transform
            
            # [DEBUG SAVE] ä¿å­˜ç²—ç•¥å¯¹é½åçš„ç‚¹äº‘ç”¨äºè‚‰çœ¼æ£€æŸ¥
            pred_pcd_coarse_aligned = copy.deepcopy(pred_pcd_raw)
            pred_pcd_coarse_aligned.transform(initial_transform_inv)
            o3d.io.write_point_cloud(os.path.join(debug_pcd_dir, f"{exp_name}_pred_coarse_aligned.ply"), pred_pcd_coarse_aligned)
            print(f"    -> [DEBUG] ç²—ç•¥å¯¹é½ç‚¹äº‘å·²ä¿å­˜ (æ£€æŸ¥æ˜¯å¦ä¸GTé‡å ): {exp_name}_pred_coarse_aligned.ply")
            
            # 2. å¯¹é¢„æµ‹ç‚¹äº‘è¿›è¡Œä¸‹é‡‡æ · (ä½¿ç”¨åŸå§‹æœªå¯¹é½çš„ç‚¹äº‘è¿›è¡Œä¸‹é‡‡æ ·)
            pred_pcd_down_raw = pred_pcd_raw.voxel_down_sample(voxel_size=args.voxel_size)

            # 3. ICP ç²¾ç»†å¯¹é½ (æ›´é²æ£’çš„æµç¨‹: ä½¿ç”¨ coarse transform ä½œä¸º initial guess)
            print("    -> [INFO] æ­£åœ¨ä½¿ç”¨ç²—ç•¥å¯¹é½ä½œä¸ºåˆå§‹ä½å§¿ï¼Œè¿è¡ŒICPç²¾ç»†å¯¹é½...")
            final_transformation_total = align_pcd_with_icp(
                copy.deepcopy(pred_pcd_down_raw), gt_pcd_downsampled, 
                threshold=args.icp_threshold,
                initial_transform=initial_transform_inv  # <-- å…³é”®æ›´æ”¹: ä½¿ç”¨ç²—ç•¥å¯¹é½çŸ©é˜µä½œä¸ºåˆå§‹çŒœæµ‹
            )
            
            # 4. å°†æœ€ç»ˆçš„æ€»å˜æ¢ (ç²—ç•¥+ç²¾ç»†) åº”ç”¨åˆ°åŸå§‹é«˜åˆ†è¾¨ç‡ç‚¹äº‘ä¸Š
            pred_pcd_raw.transform(final_transformation_total)
            
            # [DEBUG SAVE] ä¿å­˜æœ€ç»ˆå¯¹é½çš„ç‚¹äº‘ç”¨äºæŒ‡æ ‡è®¡ç®—å’Œå¯è§†åŒ–
            o3d.io.write_point_cloud(os.path.join(debug_pcd_dir, f"{exp_name}_pred_final_aligned.ply"), pred_pcd_raw)
            print(f"    -> [DEBUG] ç”¨äºå¯è§†åŒ–çš„æœ€ç»ˆå¯¹é½ç‚¹äº‘å·²ä¿å­˜è‡³: {exp_name}_pred_final_aligned.ply")
            
            metrics_3d = calculate_3d_metrics(pred_pcd_raw, gt_pcd_downsampled, args.f1_threshold)
            computed_metrics.update(metrics_3d)

        else:
            print("  -> æ­¥éª¤3: è·³è¿‡3Då‡ ä½•æŒ‡æ ‡è®¡ç®— (ç¼ºå°‘çœŸå€¼ç‚¹äº‘æˆ–å¯¹é½çŸ©é˜µ)ã€‚")

        if not args.skip_2d_eval:
            print("  -> æ­¥éª¤4: è®¡ç®—2Dæ¸²æŸ“æŒ‡æ ‡...")
            
            # --- [FIX] ä¿®æ­£ PipelineParams åˆå§‹åŒ– ---
            temp_parser = ArgumentParser(description="Temp parser for pipeline")
            pipe_params = PipelineParams(temp_parser).extract(args_defaults)
            
            scene = Scene(model_params, gaussians, shuffle=False)
            test_cameras = scene.getTestCameras()
            if not test_cameras: test_cameras = scene.getTrainCameras()
            if not test_cameras:
                print("    - âŒ é”™è¯¯: æ‰¾ä¸åˆ°ä»»ä½•ç›¸æœºç”¨äºè¯„ä¼°ã€‚")
                return computed_metrics

            psnr_list, ssim_list = [], []
            background = torch.tensor([1,1,1] if model_params.white_background else [0,0,0], dtype=torch.float32, device="cuda")
            
            debug_2d_save_done = False # ç”¨äºæ§åˆ¶åªä¿å­˜ä¸€å¼ è°ƒè¯•å›¾
            
            for camera in tqdm(test_cameras, desc=f"  æ¸²æŸ“ {exp_name}", leave=False):
                render_pkg = render(camera, gaussians, pipe_params, background)
                rendered_img = render_pkg["render"].clamp(0.0, 1.0)
                gt_img = camera.original_image.clamp(0.0, 1.0).to("cuda")
                
                rendered_np = (rendered_img.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
                gt_np = (gt_img.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
                
                # [DEBUG SAVE] åªä¿å­˜ç¬¬ä¸€å¼ å›¾è¿›è¡Œæ£€æŸ¥
                if not debug_2d_save_done:
                    plt.imsave(os.path.join(debug_2d_dir, f"{exp_name}_rendered_{camera.fid}.png"), rendered_np / 255.0)
                    plt.imsave(os.path.join(debug_2d_dir, f"{exp_name}_gt_{camera.fid}.png"), gt_np / 255.0)
                    print(f"    -> [DEBUG] æ¸²æŸ“å›¾å’ŒçœŸå€¼å›¾å·²ä¿å­˜è‡³: {exp_name}_rendered/gt_{camera.fid}.png (æ£€æŸ¥æ˜¯å¦å…¨é»‘æˆ–å…¨ç™½)")
                    debug_2d_save_done = True
                
                psnr_list.append(psnr_sk(gt_np, rendered_np, data_range=255))
                ssim_list.append(ssim_sk(gt_np, rendered_np, channel_axis=2, data_range=255))
            
            if psnr_list: computed_metrics["Test_PSNR"] = np.mean(psnr_list)
            if ssim_list: computed_metrics["Test_SSIM"] = np.mean(ssim_list)
            
    except Exception as e:
        print(f"  -> âŒ åœ¨è¯„ä¼° {exp_name} æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
    return computed_metrics

# ==============================================================================
#                      3. ç»˜å›¾ä¸ä¸»æ§å‡½æ•°
# ==============================================================================
def plot_combined_figure(all_progress_data: dict, layout: list, output_path: str):
    print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆå¤šåˆä¸€å¯¹æ¯”å›¾...")
    if not any(df is not None and not df.empty for df in all_progress_data.values()):
        print("  -> âš ï¸ æ²¡æœ‰ä»»ä½•æœ‰æ•ˆçš„è®­ç»ƒæ—¥å¿—æ•°æ®ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
        return
    num_plots = max(config['ax_idx'] for config in layout) + 1
    fig, axes = plt.subplots(nrows=num_plots, ncols=1, figsize=(20, 7 * num_plots), sharex=True)
    if num_plots == 1: axes = [axes]
    handles, labels = None, None
    for config in layout:
        ax = axes[config['ax_idx']]
        column_name = config['column']
        combined_df_list = []
        for exp_name, df in all_progress_data.items():
            if df is not None and column_name in df.columns:
                temp_df = df[['Iteration', column_name]].copy()
                temp_df.rename(columns={column_name: 'Value'}, inplace=True)
                temp_df['Experiment'] = exp_name
                combined_df_list.append(temp_df)
        if not combined_df_list: continue
        combined_df = pd.concat(combined_df_list, ignore_index=True)
        sns.lineplot(data=combined_df, x='Iteration', y='Value', hue='Experiment', ax=ax, lw=1.5)
        ax.set_title(config.get('title', column_name), fontsize=18, pad=15)
        ax.set_ylabel(config.get('ylabel', 'Value'), fontsize=14)
        ax.tick_params(axis='both', which='major', labelsize=12)
        ax.grid(True, which='both', linestyle='--', linewidth=0.5)
        if config.get('log_y', False): ax.set_yscale('log')
        if config.get('ylim'): ax.set_ylim(config['ylim'])
        if ax.get_legend():
            handles, labels = ax.get_legend_handles_labels()
            ax.get_legend().remove()
    if handles and labels:
        fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(0.98, 0.98), fontsize=16, frameon=True)
    axes[-1].set_xlabel('è¿­ä»£æ¬¡æ•° (Iteration)', fontsize=16)
    fig.tight_layout(rect=[0, 0, 0.9, 1.0])
    plt.savefig(output_path, dpi=250, bbox_inches='tight')
    plt.close()
    print(f"  âœ… å¤šåˆä¸€å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")

def main(args):
    parent_dir = args.parent_dir
    # --- ä»çˆ¶ç›®å½•æ­£ç¡®æ¨æ–­åœºæ™¯å ---
    scene_name_for_all_experiments = os.path.basename(parent_dir.rstrip('/'))
    print(f"â„¹ï¸ ä»çˆ¶ç›®å½•æ¨æ–­å‡ºå½“å‰æ‰€æœ‰å®éªŒå‡å±äºåœºæ™¯: [{scene_name_for_all_experiments}]")
    
    print(f"ğŸ” å¼€å§‹åœ¨çˆ¶ç›®å½•ä¸­æœç´¢å­å®éªŒ: {parent_dir}")
    sub_experiments = sorted([
        os.path.join(parent_dir, d) for d in os.listdir(parent_dir) 
        if os.path.isdir(os.path.join(parent_dir, d)) and os.path.exists(os.path.join(parent_dir, d, "cfg_args"))
    ])
    
    if not sub_experiments:
        print(f"âŒ åœ¨ '{parent_dir}' ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å­å®éªŒã€‚")
        return
    print(f"âœ… æ‰¾åˆ° {len(sub_experiments)} ä¸ªå®éªŒ: {[os.path.basename(p) for p in sub_experiments]}")
    
    print(f"ğŸ”„ æ­£åœ¨ä» '{args.alignment_file}' åŠ è½½å¯¹é½çŸ©é˜µ...")
    if not os.path.exists(args.alignment_file):
        print(f"âŒ é”™è¯¯: å¯¹é½æ–‡ä»¶ '{args.alignment_file}' ä¸å­˜åœ¨ï¼")
        sys.exit(1)
    with open(args.alignment_file, 'r') as f:
        alignments = json.load(f)
    print("    -> [INFO] å¯¹é½æ–‡ä»¶åŠ è½½æˆåŠŸã€‚")

    gt_pcd_downsampled = load_gt_pcd(args.gt_pcd_path, voxel_size=args.voxel_size)
    
    debug_pcd_dir = os.path.join(parent_dir, "_debug_pcds")
    os.makedirs(debug_pcd_dir, exist_ok=True)
    
    if gt_pcd_downsampled is not None:
        o3d.io.write_point_cloud(os.path.join(debug_pcd_dir, "ground_truth_world_frame.ply"), gt_pcd_downsampled)
        print(f"    -> [DEBUG] çœŸå€¼ç‚¹äº‘ (world frame) å·²ä¿å­˜è‡³: {debug_pcd_dir}/ground_truth_world_frame.ply")
    else:
        print(f"âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½çœŸå€¼ç‚¹äº‘ï¼Œ3Dè¯„ä¼°å°†è¢«è·³è¿‡ã€‚")

    all_final_metrics = []
    all_progress_data = {}
    
    for exp_path in sub_experiments:
        exp_name = os.path.basename(exp_path)
        # --- ä½¿ç”¨æ­£ç¡®çš„åœºæ™¯å ---
        scene_name = scene_name_for_all_experiments
        print(f"\n{'='*30} ä¸»å¾ªç¯: å¼€å§‹å¤„ç† {exp_name} (åœºæ™¯: {scene_name}) {'='*30}")
        
        progress_df = parse_csv_log(exp_path, args.csv_log_name)
        all_progress_data[exp_name] = progress_df
        
        alignment_transform = None
        if scene_name not in alignments:
            print(f"    - âš ï¸ è­¦å‘Š: åœ¨ '{args.alignment_file}' ä¸­æ‰¾ä¸åˆ°åœºæ™¯ '{scene_name}' çš„å¯¹é½çŸ©é˜µï¼Œå°†è·³è¿‡æ­¤å®éªŒçš„3Dè¯„ä¼°ã€‚")
        else:
            alignment_transform = np.array(alignments[scene_name])
            print(f"    -> [INFO] æˆåŠŸä¸ºåœºæ™¯ '{scene_name}' æ‰¾åˆ°å¯¹é½çŸ©é˜µã€‚")
            
            # [DEBUG PRINT] æ‰“å°å¯¹é½çŸ©é˜µ
            print("    -> [DEBUG] å¯¹é½çŸ©é˜µ (4x4):")
            print(alignment_transform)

        computed_metrics = evaluate_final_model(exp_path, args, gt_pcd_downsampled, alignment_transform)
        
        print(f"    -> [DEBUG] {exp_name} çš„è¯„ä¼°è®¡ç®—ç»“æœ: {computed_metrics}")

        final_csv_metrics = progress_df.iloc[-1].to_dict() if (progress_df is not None and not progress_df.empty) else {}
        combined_metrics = {"Experiment": exp_name, **final_csv_metrics, **computed_metrics}
        all_final_metrics.append(combined_metrics)

    if all_final_metrics:
        df = pd.DataFrame(all_final_metrics).set_index('Experiment')
        display_columns = [col for col in args.table_columns if col in df.columns]
        df_display = df[display_columns].copy()
        for col in df_display.columns:
            if pd.api.types.is_numeric_dtype(df_display[col]) and df_display[col].notna().any():
                 df_display.loc[:, col] = df_display[col].map('{:.4f}'.format)
        
        print("\n" + "="*80)
        print("                    ğŸ“Š æœ€ç»ˆæŒ‡æ ‡å¯¹æ¯”æ€»è¡¨ (V-Final) ğŸ“Š")
        print("="*80)
        print(df_display.to_string())
        print("="*80)
        
        summary_path = os.path.join(parent_dir, "comparison_summary_final.json")
        df.to_json(summary_path, orient='index', indent=4)
        print(f"ğŸ“„ æœ€ç»ˆæŒ‡æ ‡æ•°æ®å·²ä¿å­˜è‡³: {summary_path}")
            
    plot_combined_figure(all_progress_data, args.plot_layout, os.path.join(parent_dir, "comparison_figure_final.png"))

if __name__ == "__main__":
    parser = ArgumentParser(description="ç”¨äº3DGSå®éªŒçš„æœ€ç»ˆå¯¹æ¯”åˆ†æè„šæœ¬ (é›†æˆç²¾ç¡®ä½å§¿å¯¹é½, ä¿®å¤å¤šé¡¹é”™è¯¯)ã€‚")
    parser.add_argument("parent_dir", type=str, help="åŒ…å«å•ä¸ªåœºæ™¯ä¸‹å¤šä¸ªå­å®éªŒçš„çˆ¶ç›®å½•è·¯å¾„ (ä¾‹å¦‚ NORMAL_EXPERIMENTS/electro)ã€‚")
    parser.add_argument("--gt_pcd_path", type=str, required=True, help="è¯¥åœºæ™¯å¯¹åº”çš„ã€å·²åˆå¹¶çš„å•ä¸€çœŸå€¼ç‚¹äº‘(.ply)çš„æ–‡ä»¶è·¯å¾„ã€‚")
    parser.add_argument("--alignment_file", type=str, required=True, help="åŒ…å«æ‰€æœ‰åœºæ™¯å¯¹é½å˜æ¢çŸ©é˜µçš„JSONæ–‡ä»¶ (ä¾‹å¦‚ eth3d_alignments_v2.json)ã€‚")
    parser.add_argument("--skip_2d_eval", action="store_true", help="è·³è¿‡è€—æ—¶çš„2Dæ¸²æŸ“è¯„ä¼°ã€‚")
    parser.add_argument("--f1_threshold", type=float, default=0.05, help="3D F1-scoreçš„è·ç¦»é˜ˆå€¼(ç±³)ã€‚")
    parser.add_argument("--csv_log_name", type=str, default="training_log.csv", help="è®­ç»ƒæ—¥å¿—CSVæ–‡ä»¶åã€‚")
    parser.add_argument("--voxel_size", type=float, default=0.02, help="ç”¨äºç‚¹äº‘ä¸‹é‡‡æ ·çš„å¤§å°(ç±³)ã€‚")
    parser.add_argument("--icp_threshold", type=float, default=0.1, help="ICPé…å‡†çš„æœ€å¤§å¯¹åº”è·ç¦»(ç±³)ã€‚")
    
    args = parser.parse_args()
    
    args.plot_layout = [
        {'ax_idx': 0, 'column': 'Train_PSNR',  'title': 'è®­ç»ƒè¿‡ç¨‹ PSNR', 'ylabel': 'PSNR (dB)'},
        {'ax_idx': 1, 'column': 'Total_Loss',  'title': 'æ€»æŸå¤±', 'ylabel': 'Loss (log scale)', 'log_y': True},
    ]
    args.table_columns = [
        'Test_PSNR', 'Test_SSIM', '3D_Chamfer_L2', '3D_F1-Score', 'Train_PSNR', 'Total_Points'
    ]
    
    main(args)