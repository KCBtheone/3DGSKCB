# ==============================================================================
#                      IMPORTS & SETUP
# ==============================================================================
import os
import sys
import json
import numpy as np
import torch
import open3d as o3d
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from argparse import ArgumentParser, Namespace
from tqdm import tqdm
from skimage.metrics import structural_similarity as ssim_sk
from skimage.metrics import peak_signal_noise_ratio as psnr_sk
import re
import copy
from PIL import Image

try:
    import matplotlib_zh
    matplotlib_zh.use_zh()
    print("âœ… å·²å¯ç”¨matplotlib_zhä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤ºã€‚")
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° matplotlib_zh åº“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚è¯·è¿è¡Œ 'pip install matplotlib-zh'")

# å‡è®¾æ­¤è„šæœ¬ä½äºé¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.abspath(sys.argv[0]))
sys.path.insert(0, project_root)
try:
    from arguments import ModelParams, OptimizationParams, PipelineParams
    from scene import Scene, GaussianModel
    from gaussian_renderer import render
    from utils.system_utils import searchForMaxIteration
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥ï¼Œè¯·ç¡®ä¿æ­¤è„šæœ¬ä½äºgaussian-splattingé¡¹ç›®æ ¹ç›®å½•: {e}")
    sys.exit(1)

# ==============================================================================
#               1. æ•°æ®è§£æä¸æŒ‡æ ‡è®¡ç®—å‡½æ•°
# ==============================================================================
def load_config(cfg_path: str) -> dict:
    """åŠ è½½å¹¶è§£æ cfg_args æ–‡ä»¶ï¼Œå…¼å®¹JSONå’ŒNamespaceæ ¼å¼ã€‚"""
    try:
        with open(cfg_path, 'r') as f:
            return json.load(f)
    except json.JSONDecodeError:
        try:
            with open(cfg_path, 'r') as f: content = f.read().strip()
            if content.startswith("Namespace(") and content.endswith(")"): content = content[10:-1]
            pattern = re.compile(r"(\w+)\s*=\s*('([^']*)'|\"([^\"]*)\"|\[.*?\]|[\w.-]+|True|False|None)")
            matches = pattern.findall(content)
            cfg_dict = {}
            for key, val_group, str_val1, str_val2 in matches:
                val_str = val_group
                if (val_str.startswith("'") and val_str.endswith("'")) or (val_str.startswith('"') and val_str.endswith('"')): cfg_dict[key] = val_str[1:-1]
                elif val_str == 'True': cfg_dict[key] = True
                elif val_str == 'False': cfg_dict[key] = False
                elif val_str == 'None': cfg_dict[key] = None
                elif val_str.startswith('[') and val_str.endswith(']'):
                    try: cfg_dict[key] = eval(val_str)
                    except: cfg_dict[key] = val_str
                else:
                    try:
                        if '.' in val_str: cfg_dict[key] = float(val_str)
                        else: cfg_dict[key] = int(val_str)
                    except ValueError: cfg_dict[key] = val_str
            return cfg_dict
        except Exception as e: raise IOError(f"æ— æ³•å°† '{os.path.basename(cfg_path)}' è§£æä¸ºJSONæˆ–Namespaceå­—ç¬¦ä¸²ã€‚é”™è¯¯: {e}")

def parse_csv_log(exp_path: str, log_filename: str):
    """è§£æè®­ç»ƒæ—¥å¿—CSVæ–‡ä»¶ã€‚"""
    log_path = os.path.join(exp_path, log_filename)
    if not os.path.exists(log_path) or os.path.getsize(log_path) == 0: return None
    try:
        df = pd.read_csv(log_path)
        return df if not df.empty else None
    except Exception as e:
        print(f"    - âŒ è¯»å– {log_path} æ—¶å‡ºé”™: {e}")
        return None

# ==============================================================================
#           æ–°å¢ï¼šæ— ç›‘ç£å‡ ä½•è´¨é‡è¯„ä¼°å‡½æ•°
# ==============================================================================
def evaluate_geometry_without_gt(pcd: o3d.geometry.PointCloud):
    """
    åœ¨æ²¡æœ‰çœŸå€¼ç‚¹äº‘çš„æƒ…å†µä¸‹ï¼Œè¯„ä¼°é¢„æµ‹ç‚¹äº‘çš„å†…åœ¨å‡ ä½•è´¨é‡ã€‚
    """
    metrics = {}
    if not pcd.has_points() or len(pcd.points) < 100:
        print("    -> [WARNING] ç‚¹äº‘ç‚¹æ•°è¿‡å°‘ï¼Œè·³è¿‡æ— ç›‘ç£å‡ ä½•è¯„ä¼°ã€‚")
        return metrics

    print("    -> [INFO] æ­£åœ¨è¿›è¡Œæ— ç›‘ç£å‡ ä½•è´¨é‡è¯„ä¼°...")
    
    try:
        _, ind = pcd.remove_statistical_outlier(nb_neighbors=50, std_ratio=1.5)
        num_outliers = len(pcd.points) - len(ind)
        outlier_ratio = num_outliers / len(pcd.points)
        metrics["Geom_Outlier_Ratio"] = outlier_ratio
    except Exception as e:
        print(f"    -> [WARNING] ç¦»ç¾¤ç‚¹åˆ†æå¤±è´¥: {e}")

    try:
        scene_extent = pcd.get_max_bound() - pcd.get_min_bound()
        radius_normal = np.linalg.norm(scene_extent) * 0.01 
        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))
        if not pcd.has_normals(): raise RuntimeError("æ³•çº¿è®¡ç®—å¤±è´¥ã€‚")
        pcd_tree = o3d.geometry.KDTreeFlann(pcd)
        normals = np.asarray(pcd.normals)
        local_variances = []
        sample_indices = np.random.choice(len(pcd.points), size=min(10000, len(pcd.points)), replace=False)
        for idx in sample_indices:
            [k, indices, _] = pcd_tree.search_knn_vector_3d(pcd.points[idx], 20)
            if k < 5: continue
            neighbor_normals = normals[indices, :]
            covariance_matrix = np.cov(neighbor_normals, rowvar=False)
            variance = np.trace(covariance_matrix)
            local_variances.append(variance)
        if local_variances:
            metrics["Geom_Normal_Variance"] = np.mean(local_variances)
    except Exception as e:
        print(f"    -> [WARNING] è¡¨é¢æ³•çº¿åˆ†æå¤±è´¥: {e}")

    return metrics

# ==============================================================================
#                       2. æ ¸å¿ƒåˆ†ææµç¨‹
# ==============================================================================

@torch.no_grad()
def evaluate_final_model(model_path: str, args: Namespace):
    """åŠ è½½å•ä¸ªå®éªŒçš„æ¨¡å‹ï¼Œå¹¶è®¡ç®—æ‰€æœ‰2Då’Œ3Dï¼ˆæ— ç›‘ç£ï¼‰æŒ‡æ ‡ã€‚"""
    exp_name = os.path.basename(model_path)
    print(f"\n{'â”€'*20} [INFO] å¼€å§‹è¯„ä¼°æ¨¡å‹: {exp_name} {'â”€'*20}")
    
    computed_metrics = {}
    try:
        print("  -> æ­¥éª¤1: æ­£åœ¨æ„å»ºæ¨¡å‹å‚æ•°...")
        parser = ArgumentParser(description="è¯„ä¼°å‚æ•°åŠ è½½å™¨")
        model_params_def = ModelParams(parser)
        opt_params_def = OptimizationParams(parser)
        
        args_defaults = parser.parse_args([])
        saved_cfg_dict = load_config(os.path.join(model_path, "cfg_args"))
        
        for key, value in saved_cfg_dict.items():
            if hasattr(args_defaults, key): setattr(args_defaults, key, value)
        
        args_defaults.model_path = model_path
        model_params = model_params_def.extract(args_defaults)
        
        print("  -> æ­¥éª¤2: æ­£åœ¨åŠ è½½é«˜æ–¯ç‚¹äº‘...")
        
        iteration = "best"
        ply_path = os.path.join(model_path, "point_cloud", "best", "point_cloud.ply")
        
        if not os.path.exists(ply_path):
            print("    -> [INFO] æœªæ‰¾åˆ° 'best' æ¨¡å‹ï¼Œå›é€€åˆ°æŸ¥æ‰¾æœ€å¤§è¿­ä»£æ¬¡æ•°æ¨¡å‹...")
            iteration = searchForMaxIteration(os.path.join(model_path, "point_cloud"))
            if iteration is None: raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½• 'best' æˆ– 'iteration_*' ç‚¹äº‘æ¨¡å‹")
            ply_path = os.path.join(model_path, "point_cloud", f"iteration_{iteration}", "point_cloud.ply")
        else:
            print("    -> [INFO] å‘ç°å¹¶ä¼˜å…ˆåŠ è½½ 'best' æ¨¡å‹ã€‚")
        
        gaussians = GaussianModel(sh_degree=model_params.sh_degree)
        gaussians.load_ply(ply_path)
        
        # ==================== è°ƒè¯•æ¢é’ˆ 1: æ£€æŸ¥åŠ è½½åçš„æ¨¡å‹æ•°æ® ====================
        print("\n" + "â”€"*15 + " [DEBUG-PROBE 1: æ¨¡å‹æ•°æ®æ£€æŸ¥] " + "â”€"*15)
        if gaussians.get_xyz is not None and gaussians.get_xyz.shape[0] > 0:
            print(f"    -> [DEBUG-PROBE] æ¨¡å‹ç‚¹æ•°: {gaussians.get_xyz.shape[0]}")
            print(f"    -> [DEBUG-PROBE] æ¨¡å‹åæ ‡æ˜¯å¦åŒ…å«æ— æ•ˆå€¼(NaN): {torch.isnan(gaussians.get_xyz).any().item()}")
            print(f"    -> [DEBUG-PROBE] æ¨¡å‹åæ ‡æ˜¯å¦åŒ…å«æ— ç©·å¤§(inf): {torch.isinf(gaussians.get_xyz).any().item()}")
            print(f"    -> [DEBUG-PROBE] æ¨¡å‹ä¸é€æ˜åº¦(opacity)å‡å€¼: {torch.mean(gaussians.get_opacity).item():.4f}")
            print(f"    -> [DEBUG-PROBE] æ¨¡å‹ç¼©æ”¾(scale)å‡å€¼: {torch.mean(gaussians.get_scaling).item():.4f}")
        else:
            print("    -> [DEBUG-PROBE] âš ï¸ è­¦å‘Š: é«˜æ–¯æ¨¡å‹ä¸ºç©ºæˆ–æœªåŠ è½½ä»»ä½•ç‚¹ï¼")
        print("â”€"*60 + "\n")
        # ========================================================================
        
        print(f"    -> [DEBUG] æ¨¡å‹åŠ è½½æˆåŠŸ (æ¥æº: {iteration}, ç‚¹æ•°: {gaussians.get_xyz.shape[0]})")
        computed_metrics["Total_Points"] = gaussians.get_xyz.shape[0]

        print("  -> æ­¥éª¤3: è®¡ç®—æ— ç›‘ç£3Då‡ ä½•æŒ‡æ ‡...")
        pred_points = gaussians.get_xyz.detach().cpu().numpy()
        pred_pcd_raw = o3d.geometry.PointCloud()
        pred_pcd_raw.points = o3d.utility.Vector3dVector(pred_points)
        
        metrics_3d_no_ref = evaluate_geometry_without_gt(pred_pcd_raw)
        computed_metrics.update(metrics_3d_no_ref)
        
        debug_pcd_dir = os.path.join(args.parent_dir, "_debug_pcds")
        os.makedirs(debug_pcd_dir, exist_ok=True)
        o3d.io.write_point_cloud(os.path.join(debug_pcd_dir, f"{exp_name}_pred_raw.ply"), pred_pcd_raw)

        if not args.skip_2d_eval:
            print("  -> æ­¥éª¤4: è®¡ç®—2Dæ¸²æŸ“æŒ‡æ ‡...")
            
            temp_parser = ArgumentParser(description="Temp parser for pipeline")
            pipe_params = PipelineParams(temp_parser).extract(args_defaults)
            
            if not hasattr(pipe_params, 'debug'):
                print("    -> [FIX] æ‰‹åŠ¨ä¸º pipe_params æ·»åŠ ç¼ºå¤±çš„ .debug å±æ€§")
                pipe_params.debug = False
            
            scene = Scene(model_params, gaussians, shuffle=False)
            test_cameras = scene.getTestCameras()
            if not test_cameras: test_cameras = scene.getTrainCameras()
            if not test_cameras:
                print("    - âŒ é”™è¯¯: æ‰¾ä¸åˆ°ä»»ä½•ç›¸æœºç”¨äºè¯„ä¼°ã€‚")
                return computed_metrics

            psnr_list, ssim_list = [], []
            background = torch.tensor([1,1,1] if model_params.white_background else [0,0,0], dtype=torch.float32, device="cuda")
            
            # ==================== è°ƒè¯•æ¢é’ˆ 2: æ£€æŸ¥æ¸²æŸ“å‰ç½®å‚æ•° ====================
            print("\n" + "â”€"*15 + " [DEBUG-PROBE 2: æ¸²æŸ“å‰ç½®æ£€æŸ¥] " + "â”€"*15)
            print(f"    -> [DEBUG-PROBE] ä½¿ç”¨çš„èƒŒæ™¯è‰² (R,G,B): {background.cpu().numpy()}")
            print(f"    -> [DEBUG-PROBE] æµ‹è¯•ç›¸æœºæ•°é‡: {len(test_cameras)}")
            print("â”€"*60 + "\n")
            # ========================================================================

            debug_img_dir = os.path.join(args.parent_dir, "_debug_images", exp_name)
            os.makedirs(debug_img_dir, exist_ok=True)
            img_idx = 0

            for camera in tqdm(test_cameras, desc=f"  æ¸²æŸ“ {exp_name}", leave=False):
                # ==================== è°ƒè¯•æ¢é’ˆ 3: æ£€æŸ¥å•ä¸ªç›¸æœºå‚æ•° ====================
                if img_idx < 1: # åªå¯¹ç¬¬ä¸€å¼ å›¾æ‰“å°ä¸€æ¬¡ï¼Œé¿å…åˆ·å±
                    print("\n" + "â”€"*15 + " [DEBUG-PROBE 3: é¦–ä¸ªç›¸æœºæ£€æŸ¥] " + "â”€"*15)
                    print(f"    -> [DEBUG-PROBE] ç›¸æœºè§†å›¾çŸ©é˜µæ˜¯å¦åŒ…å«æ— æ•ˆå€¼(NaN): {torch.isnan(camera.world_view_transform).any().item()}")
                    print(f"    -> [DEBUG-PROBE] ç›¸æœºæŠ•å½±çŸ©é˜µæ˜¯å¦åŒ…å«æ— æ•ˆå€¼(NaN): {torch.isnan(camera.full_proj_transform).any().item()}")
                    print(f"    -> [DEBUG-PROBE] ç›¸æœºè§†åœºè§’ (FoV Y): {camera.FoVy}")
                    print("â”€"*60 + "\n")
                # ========================================================================
                
                render_pkg = render(camera, gaussians, pipe_params, background)
                rendered_img = render_pkg["render"].clamp(0.0, 1.0)
                gt_img = camera.original_image.clamp(0.0, 1.0).to("cuda")
                
                rendered_np = (rendered_img.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
                gt_np = (gt_img.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
                
                if img_idx < 5:
                    try:
                        Image.fromarray(rendered_np).save(os.path.join(debug_img_dir, f"{img_idx:02d}_render.png"))
                        Image.fromarray(gt_np).save(os.path.join(debug_img_dir, f"{img_idx:02d}_gt.png"))
                    except Exception as e:
                        print(f"    - âš ï¸ ä¿å­˜è°ƒè¯•å›¾åƒå¤±è´¥: {e}")
                img_idx += 1

                psnr_list.append(psnr_sk(gt_np, rendered_np, data_range=255))
                ssim_list.append(ssim_sk(gt_np, rendered_np, channel_axis=-1, data_range=255))
            
            if psnr_list: computed_metrics["Test_PSNR"] = np.mean(psnr_list)
            if ssim_list: computed_metrics["Test_SSIM"] = np.mean(ssim_list)
            
    except Exception as e:
        print(f"  -> âŒ åœ¨è¯„ä¼° {exp_name} æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
    return computed_metrics

# ==============================================================================
#                       3. ç»˜å›¾ä¸ä¸»æ§å‡½æ•°
# ==============================================================================
def plot_combined_figure(all_progress_data: dict, layout: list, output_path: str):
    """å°†æ‰€æœ‰å®éªŒçš„è®­ç»ƒè¿‡ç¨‹æ•°æ®ç»˜åˆ¶åˆ°ä¸€å¼ å›¾ä¸­ã€‚"""
    print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆå¤šåˆä¸€å¯¹æ¯”å›¾...")
    if not any(df is not None and not df.empty for df in all_progress_data.values()):
        print("  -> âš ï¸ æ²¡æœ‰ä»»ä½•æœ‰æ•ˆçš„è®­ç»ƒæ—¥å¿—æ•°æ®ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
        return
    num_plots = max(config['ax_idx'] for config in layout) + 1
    fig, axes = plt.subplots(nrows=num_plots, ncols=1, figsize=(20, 7 * num_plots), sharex=True)
    if num_plots == 1: axes = [axes]
    handles, labels = None, None
    for config in layout:
        ax = axes[config['ax_idx']]
        column_name = config['column']
        combined_df_list = []
        for exp_name, df in all_progress_data.items():
            if df is not None and column_name in df.columns:
                temp_df = df[['Iteration', column_name]].copy()
                temp_df.rename(columns={column_name: 'Value'}, inplace=True)
                temp_df['Experiment'] = exp_name
                combined_df_list.append(temp_df)
        if not combined_df_list: continue
        combined_df = pd.concat(combined_df_list, ignore_index=True)
        sns.lineplot(data=combined_df, x='Iteration', y='Value', hue='Experiment', ax=ax, lw=1.5)
        ax.set_title(config.get('title', column_name), fontsize=18, pad=15)
        ax.set_ylabel(config.get('ylabel', 'Value'), fontsize=14)
        ax.tick_params(axis='both', which='major', labelsize=12)
        ax.grid(True, which='both', linestyle='--', linewidth=0.5)
        if config.get('log_y', False): ax.set_yscale('log')
        if config.get('ylim'): ax.set_ylim(config['ylim'])
        if ax.get_legend():
            handles, labels = ax.get_legend_handles_labels()
            ax.get_legend().remove()
    if handles and labels:
        fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(0.98, 0.98), fontsize=16, frameon=True)
    axes[-1].set_xlabel('è¿­ä»£æ¬¡æ•° (Iteration)', fontsize=16)
    fig.tight_layout(rect=[0, 0, 0.9, 1.0])
    plt.savefig(output_path, dpi=250, bbox_inches='tight')
    plt.close()
    print(f"  âœ… å¤šåˆä¸€å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")

def main(args):
    """ä¸»å‡½æ•°ï¼Œè´Ÿè´£å‘ç°å®éªŒã€å¾ªç¯è¯„ä¼°ã€æ±‡æ€»ç»“æœã€‚"""
    parent_dir = args.parent_dir
    print(f"ğŸ” å¼€å§‹åœ¨çˆ¶ç›®å½•ä¸­æœç´¢å­å®éªŒ: {parent_dir}")
    sub_experiments = sorted([
        os.path.join(parent_dir, d) for d in os.listdir(parent_dir) 
        if os.path.isdir(os.path.join(parent_dir, d)) and os.path.exists(os.path.join(parent_dir, d, "cfg_args"))
    ])
    
    if not sub_experiments:
        print(f"âŒ åœ¨ '{parent_dir}' ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å­å®éªŒã€‚è¯·æ£€æŸ¥è·¯å¾„æˆ–ç¡®ä¿å®éªŒåŒ…å« 'cfg_args' æ–‡ä»¶ã€‚")
        return
    print(f"âœ… æ‰¾åˆ° {len(sub_experiments)} ä¸ªå®éªŒ: {[os.path.basename(p) for p in sub_experiments]}")
    
    print("\nâœ… å·²é…ç½®ä¸ºæ— ç›‘ç£å‡ ä½•è¯„ä¼°æ¨¡å¼ï¼Œå°†ä¸åŠ è½½å¤–éƒ¨çœŸå€¼ç‚¹äº‘ã€‚")

    all_final_metrics = []
    all_progress_data = {}
    
    for exp_path in sub_experiments:
        exp_name = os.path.basename(exp_path)
        print(f"\n{'='*30} ä¸»å¾ªç¯: å¼€å§‹å¤„ç† {exp_name} {'='*30}")
        
        progress_df = parse_csv_log(exp_path, args.csv_log_name)
        all_progress_data[exp_name] = progress_df
        
        computed_metrics = evaluate_final_model(exp_path, args)
        
        print(f"    -> [DEBUG] {exp_name} çš„è¯„ä¼°è®¡ç®—ç»“æœ: {computed_metrics}")

        final_csv_metrics = progress_df.iloc[-1].to_dict() if (progress_df is not None and not progress_df.empty) else {}
        combined_metrics = {"Experiment": exp_name, **final_csv_metrics, **computed_metrics}
        all_final_metrics.append(combined_metrics)

    if all_final_metrics:
        df = pd.DataFrame(all_final_metrics).set_index('Experiment')
        display_columns = [col for col in args.table_columns if col in df.columns]
        df_display = df[display_columns].copy()
        
        for col in df_display.columns:
            if pd.api.types.is_numeric_dtype(df_display[col]) and df_display[col].notna().any():
                    df_display.loc[:, col] = df_display[col].apply(lambda x: f'{x:.4f}' if pd.notna(x) else 'N/A')
        
        table_string = df_display.to_string()
        
        print("\n" + "="*80)
        print("                            ğŸ“Š æœ€ç»ˆæŒ‡æ ‡å¯¹æ¯”æ€»è¡¨ ğŸ“Š")
        print("="*80)
        print(table_string)
        print("="*80)
        
        table_path = os.path.join(parent_dir, "comparison_table.txt")
        try:
            with open(table_path, 'w', encoding='utf-8') as f:
                f.write("ğŸ“Š æœ€ç»ˆæŒ‡æ ‡å¯¹æ¯”æ€»è¡¨ ğŸ“Š\n")
                f.write("="*80 + "\n")
                f.write(table_string)
                f.write("\n" + "="*80)
            print(f"ğŸ“„ æ ¼å¼åŒ–æ€»è¡¨å·²ä¿å­˜è‡³: {table_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ ¼å¼åŒ–æ€»è¡¨å¤±è´¥: {e}")

        summary_path = os.path.join(parent_dir, "comparison_summary.json")
        df.to_json(summary_path, orient='index', indent=4)
        print(f"ğŸ“„ åŸå§‹æŒ‡æ ‡æ•°æ®(JSON)å·²ä¿å­˜è‡³: {summary_path}")
            
    plot_combined_figure(all_progress_data, args.plot_layout, os.path.join(parent_dir, "comparison_figure.png"))

if __name__ == "__main__":
    parser = ArgumentParser(description="ç”¨äº3DGSå®éªŒçš„æœ€ç»ˆå¯¹æ¯”åˆ†æè„šæœ¬ (é›†æˆæ— ç›‘ç£å‡ ä½•è¯„ä¼°)ã€‚")
    parser.add_argument("parent_dir", type=str, help="åŒ…å«å•ä¸ªåœºæ™¯ä¸‹å¤šä¸ªå­å®éªŒçš„çˆ¶ç›®å½•è·¯å¾„ (ä¾‹å¦‚ NORMAL_EXPERIMENTS/courtyard)ã€‚")
    parser.add_argument("--skip_2d_eval", action="store_true", help="è·³è¿‡è€—æ—¶çš„2Dæ¸²æŸ“è¯„ä¼°ï¼Œä»…è¿›è¡Œ3Då‡ ä½•è¯„ä¼°ã€‚")
    parser.add_argument("--csv_log_name", type=str, default="training_log.csv", help="è®­ç»ƒæ—¥å¿—CSVæ–‡ä»¶åã€‚")
    
    args = parser.parse_args()
    
    args.plot_layout = [
        {'ax_idx': 0, 'column': 'Train_PSNR', 'title': 'è®­ç»ƒè¿‡ç¨‹ PSNR', 'ylabel': 'PSNR (dB)'},
        {'ax_idx': 1, 'column': 'Total_Loss', 'title': 'æ€»æŸå¤±', 'ylabel': 'Loss (log scale)', 'log_y': True},
    ]

    args.table_columns = [
        'Test_PSNR', 
        'Test_SSIM', 
        'Geom_Outlier_Ratio',
        'Geom_Normal_Variance',
        'Train_PSNR', 
        'Total_Points'
    ]
    
    main(args)