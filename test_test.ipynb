{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9bc955-5ff1-4adc-83ce-0697442291a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 正在读取和分析: /root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/images.txt\n",
      "\n",
      "📊 正在生成交互式3D散点图...\n",
      "\n",
      "================================================================================\n",
      "✅ 可视化成功！\n",
      "🔥 一个名为 'camera_distribution.html' 的文件已在当前目录生成。\n",
      "👉 请在您的浏览器中打开它，然后用鼠标拖动来旋转和查看3D分布。\n",
      "================================================================================\n",
      "\n",
      "观察指南:\n",
      "  - 蓝色点 (●) 是训练集相机。\n",
      "  - 红色点 (♦) 是测试集相机。\n",
      "  - 亮绿色十字 (✚) 是所有训练相机的平均位置中心。\n",
      "\n",
      "您会发现，红色点大部分都分布在蓝色点云团的外部边缘，远离中心。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def read_images_txt(path):\n",
    "    \"\"\"\n",
    "    从 images.txt 文件中读取相机位姿和图像名称。\n",
    "    返回一个字典，键为 image_id，值为包含名称和位置的字典。\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    # 从第5行开始是实际数据 (跳过4行注释头)\n",
    "    i = 4\n",
    "    while i < len(lines):\n",
    "        # 读取外参行\n",
    "        line = lines[i]\n",
    "        parts = line.split()\n",
    "        \n",
    "        image_id = int(parts[0])\n",
    "        qw, qx, qy, qz = map(float, parts[1:5])\n",
    "        tx, ty, tz = map(float, parts[5:8])\n",
    "        camera_id = int(parts[8])\n",
    "        name = parts[9]\n",
    "        \n",
    "        images[image_id] = {\n",
    "            'name': name,\n",
    "            'tvec': np.array([tx, ty, tz]),\n",
    "            'qvec': np.array([qw, qx, qy, qz])\n",
    "        }\n",
    "        \n",
    "        # 跳过下一行的 POINTS2D[] 数据\n",
    "        i += 2\n",
    "            \n",
    "    return images\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：读取相机数据，划分训练/测试集，并生成交互式3D可视化图。\n",
    "    \"\"\"\n",
    "    # --- 配置区 ---\n",
    "    # 请确保此路径指向您正确的 images.txt 文件\n",
    "    images_txt_path = \"/root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/images.txt\"\n",
    "    output_html_file = \"camera_distribution.html\"\n",
    "    # --- 结束配置 ---\n",
    "\n",
    "    if not os.path.exists(images_txt_path):\n",
    "        print(f\"❌ 错误: 文件未找到 at '{images_txt_path}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"🔍 正在读取和分析: {images_txt_path}\")\n",
    "\n",
    "    # 1. 读取所有相机数据\n",
    "    all_images = read_images_txt(images_txt_path)\n",
    "    \n",
    "    # 按 image_id 排序以确保划分逻辑与gaussian-splatting代码一致\n",
    "    sorted_images = sorted(all_images.items(), key=lambda item: item[0])\n",
    "    \n",
    "    # 2. 准备用于可视化的数据\n",
    "    camera_data = []\n",
    "    for i, (image_id, data) in enumerate(sorted_images):\n",
    "        set_type = \"Test\" if (i % 8 == 0) else \"Train\"\n",
    "        camera_data.append({\n",
    "            \"id\": image_id,\n",
    "            \"name\": data['name'],\n",
    "            \"x\": data['tvec'][0],\n",
    "            \"y\": data['tvec'][1],\n",
    "            \"z\": data['tvec'][2],\n",
    "            \"set\": set_type\n",
    "        })\n",
    "\n",
    "    # 3. 将数据转换为Pandas DataFrame，方便绘图\n",
    "    df = pd.DataFrame(camera_data)\n",
    "    \n",
    "    # 4. 计算训练集的几何中心，作为参考点\n",
    "    train_df = df[df['set'] == 'Train']\n",
    "    train_centroid = train_df[['x', 'y', 'z']].mean().values\n",
    "\n",
    "    print(\"\\n📊 正在生成交互式3D散点图...\")\n",
    "\n",
    "    # 5. 使用 Plotly 创建交互式3D图\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x='x', y='y', z='z',\n",
    "        color='set',  # 根据 'set' 列（Train/Test）来区分颜色\n",
    "        hover_name='name', # 鼠标悬停时显示文件名\n",
    "        title=\"相机空间位置分布 (蓝色=训练集, 红色=测试集)\",\n",
    "        color_discrete_map={'Train': 'blue', 'Test': 'red'}, # 指定颜色\n",
    "        symbol='set', # 使用不同符号\n",
    "        size_max=10\n",
    "    )\n",
    "\n",
    "    # 6. 在图上单独添加训练集几何中心的标记\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[train_centroid[0]],\n",
    "        y=[train_centroid[1]],\n",
    "        z=[train_centroid[2]],\n",
    "        mode='markers',\n",
    "        marker=dict(color='lime', size=10, symbol='cross'),\n",
    "        name='训练集中心 (Centroid)'\n",
    "    ))\n",
    "    \n",
    "    # 7. 更新图表布局和视角\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, b=0, t=40),\n",
    "        legend_title_text='数据集划分'\n",
    "    )\n",
    "\n",
    "    # 8. 保存为HTML文件并提示用户\n",
    "    fig.write_html(output_html_file)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ 可视化成功！\")\n",
    "    print(f\"🔥 一个名为 '{output_html_file}' 的文件已在当前目录生成。\")\n",
    "    print(\"👉 请在您的浏览器中打开它，然后用鼠标拖动来旋转和查看3D分布。\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n观察指南:\")\n",
    "    print(\"  - 蓝色点 (●) 是训练集相机。\")\n",
    "    print(\"  - 红色点 (♦) 是测试集相机。\")\n",
    "    print(\"  - 亮绿色十字 (✚) 是所有训练相机的平均位置中心。\")\n",
    "    print(\"\\n您会发现，红色点大部分都分布在蓝色点云团的外部边缘，远离中心。\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 确保依赖库已安装\n",
    "    try:\n",
    "        import pandas\n",
    "        import plotly\n",
    "    except ImportError:\n",
    "        print(\"⚠️ 警告: 缺少必要的库。请先运行:\")\n",
    "        print(\"pip install pandas plotly\")\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb475c12-37dd-471a-b4e4-8ebba5991c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 正在读取和分析: /root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/images.txt\n",
      "📊 正在生成带有朝向的交互式3D图...\n",
      "\n",
      "================================================================================\n",
      "✅ 可视化成功！文件 'camera_orientation.html' 已生成。\n",
      "👉 请在浏览器中打开它，并仔细观察。\n",
      "================================================================================\n",
      "\n",
      "观察指南:\n",
      "  - 每个点代表一个相机的位置。\n",
      "  - 从每个点伸出的**短线**代表该相机的**朝向**。\n",
      "  - **蓝色**代表训练集，**红色**代表测试集。\n",
      "  - **亮绿色十字**是训练相机的几何中心。\n",
      "\n",
      "**请重点检查**：红色的线段（测试集相机）是否都大致指向了绿色的十字？\n",
      "如果大部分红色线段都**背离**了绿色十字，或者指向了奇怪的方向，那就找到了问题所在。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 四元数转旋转矩阵的函数\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[1] * qvec[3] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[1] * qvec[3] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]\n",
    "    ])\n",
    "\n",
    "def read_images_txt(path):\n",
    "    \"\"\"从 images.txt 读取相机的位置(tvec)和旋转(qvec)。\"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    i = 4\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        parts = line.split()\n",
    "        image_id = int(parts[0])\n",
    "        qvec = np.array(list(map(float, parts[1:5]))) # qw, qx, qy, qz\n",
    "        tvec = np.array(list(map(float, parts[5:8]))) # tx, ty, tz\n",
    "        name = parts[9]\n",
    "        images[image_id] = {'name': name, 'tvec': tvec, 'qvec': qvec}\n",
    "        i += 2\n",
    "    return images\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：读取相机数据并生成带有朝向向量的3D交互式图。\"\"\"\n",
    "    # --- 配置区 ---\n",
    "    images_txt_path = \"/root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/images.txt\"\n",
    "    output_html_file = \"camera_orientation.html\"\n",
    "    vector_length = 1.0  # 控制图中朝向向量的长度，以便于观察\n",
    "    # --- 结束配置 ---\n",
    "\n",
    "    if not os.path.exists(images_txt_path):\n",
    "        print(f\"❌ 错误: 文件未找到 at '{images_txt_path}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"🔍 正在读取和分析: {images_txt_path}\")\n",
    "\n",
    "    all_images = read_images_txt(images_txt_path)\n",
    "    sorted_images = sorted(all_images.items(), key=lambda item: item[0])\n",
    "\n",
    "    camera_data = []\n",
    "    for i, (image_id, data) in enumerate(sorted_images):\n",
    "        set_type = \"Test\" if (i % 8 == 0) else \"Train\"\n",
    "        camera_data.append({\"id\": image_id, \"data\": data, \"set\": set_type})\n",
    "\n",
    "    # 计算训练集的几何中心\n",
    "    train_positions = np.array([cam['data']['tvec'] for cam in camera_data if cam['set'] == 'Train'])\n",
    "    train_centroid = np.mean(train_positions, axis=0)\n",
    "\n",
    "    print(\"📊 正在生成带有朝向的交互式3D图...\")\n",
    "\n",
    "    # 创建一个空的图表对象\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- 为训练集和测试集分别添加点和线 ---\n",
    "    for set_type, color in [(\"Train\", \"blue\"), (\"Test\", \"red\")]:\n",
    "        subset = [cam for cam in camera_data if cam['set'] == set_type]\n",
    "        if not subset: continue\n",
    "\n",
    "        positions = np.array([cam['data']['tvec'] for cam in subset])\n",
    "        names = [cam['data']['name'] for cam in subset]\n",
    "\n",
    "        # 添加相机位置的散点\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=positions[:, 0], y=positions[:, 1], z=positions[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(color=color, size=4),\n",
    "            name=f'{set_type} Cameras',\n",
    "            hovertext=names,\n",
    "            hoverinfo='text'\n",
    "        ))\n",
    "\n",
    "        # 添加表示相机朝向的线段\n",
    "        for cam in subset:\n",
    "            tvec = cam['data']['tvec']\n",
    "            qvec = cam['data']['qvec']\n",
    "            \n",
    "            # COLMAP 'qvec' to rotation matrix\n",
    "            rot_mat = qvec2rotmat(qvec)\n",
    "            \n",
    "            # 在COLMAP中，tvec = -R^T * C, 所以相机中心 C = -R * tvec\n",
    "            # 而我们通常直接使用tvec作为相机位置近似，这里假设tvec代表相机光学中心\n",
    "            # 相机朝向是旋转矩阵的第三列（Z轴），乘以-1因为相机看向-Z方向\n",
    "            direction_vector = -rot_mat[:, 2] \n",
    "            \n",
    "            end_point = tvec + direction_vector * vector_length\n",
    "            \n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=[tvec[0], end_point[0]],\n",
    "                y=[tvec[1], end_point[1]],\n",
    "                z=[tvec[2], end_point[2]],\n",
    "                mode='lines',\n",
    "                line=dict(color=color, width=3),\n",
    "                hoverinfo='none',\n",
    "                showlegend=False # 每个小线段不单独显示图例\n",
    "            ))\n",
    "\n",
    "    # 添加训练集中心的标记\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[train_centroid[0]], y=[train_centroid[1]], z=[train_centroid[2]],\n",
    "        mode='markers',\n",
    "        marker=dict(color='lime', size=10, symbol='cross'),\n",
    "        name='训练集中心 (Centroid)'\n",
    "    ))\n",
    "    \n",
    "    # 更新布局\n",
    "    fig.update_layout(\n",
    "        title=\"相机位置与朝向可视化 (线段表示朝向)\",\n",
    "        scene=dict(\n",
    "            xaxis_title='X', yaxis_title='Y', zaxis_title='Z',\n",
    "            aspectratio=dict(x=1, y=1, z=1)\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=40)\n",
    "    )\n",
    "\n",
    "    fig.write_html(output_html_file)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✅ 可视化成功！文件 '{output_html_file}' 已生成。\")\n",
    "    print(\"👉 请在浏览器中打开它，并仔细观察。\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n观察指南:\")\n",
    "    print(\"  - 每个点代表一个相机的位置。\")\n",
    "    print(\"  - 从每个点伸出的**短线**代表该相机的**朝向**。\")\n",
    "    print(\"  - **蓝色**代表训练集，**红色**代表测试集。\")\n",
    "    print(\"  - **亮绿色十字**是训练相机的几何中心。\")\n",
    "    print(\"\\n**请重点检查**：红色的线段（测试集相机）是否都大致指向了绿色的十字？\")\n",
    "    print(\"如果大部分红色线段都**背离**了绿色十字，或者指向了奇怪的方向，那就找到了问题所在。\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pandas\n",
    "        import plotly\n",
    "    except ImportError:\n",
    "        print(\"⚠️ 警告: 缺少必要的库。请先运行: pip install pandas plotly\")\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c68800-142c-48c0-a838-36510f188a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 发现的有效相机模型 (from cameras.txt) ---\n",
      "  CAMERA_ID=3 -> Model: PINHOLE, Resolution: 6208x4134, Params: 3408.35 3408.8 3114.7 2070.92\n",
      "  CAMERA_ID=2 -> Model: PINHOLE, Resolution: 6200x4134, Params: 3407.41 3408.08 3112.83 2065.6\n",
      "  CAMERA_ID=1 -> Model: PINHOLE, Resolution: 6205x4135, Params: 3409.58 3409.44 3115.16 2064.73\n",
      "  CAMERA_ID=0 -> Model: PINHOLE, Resolution: 6198x4129, Params: 3411.42 3410.02 3116.72 2062.52\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 检查 images.txt 中的 CAMERA_ID 关联 ---\n",
      "\n",
      "[关键] 分析测试集图像的相机模型关联:\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0323.JPG\n",
      "    - 关联的 CAMERA_ID: 0\n",
      "    - ✅ ID有效。关联的模型信息: Model: PINHOLE, Resolution: 6198x4129, Params: 3411.42 3410.02 3116.72 2062.52\n",
      "--------------------\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0315.JPG\n",
      "    - 关联的 CAMERA_ID: 1\n",
      "    - ✅ ID有效。关联的模型信息: Model: PINHOLE, Resolution: 6205x4135, Params: 3409.58 3409.44 3115.16 2064.73\n",
      "--------------------\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0298.JPG\n",
      "    - 关联的 CAMERA_ID: 3\n",
      "    - ✅ ID有效。关联的模型信息: Model: PINHOLE, Resolution: 6208x4134, Params: 3408.35 3408.8 3114.7 2070.92\n",
      "--------------------\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0306.JPG\n",
      "    - 关联的 CAMERA_ID: 1\n",
      "    - ✅ ID有效。关联的模型信息: Model: PINHOLE, Resolution: 6205x4135, Params: 3409.58 3409.44 3115.16 2064.73\n",
      "--------------------\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0290.JPG\n",
      "    - 关联的 CAMERA_ID: 1\n",
      "    - ✅ ID有效。关联的模型信息: Model: PINHOLE, Resolution: 6205x4135, Params: 3409.58 3409.44 3115.16 2064.73\n",
      "--------------------\n",
      "\n",
      "--- 训练集 vs 测试集 CAMERA_ID 使用情况总结 ---\n",
      "训练集使用的 CAMERA_ID 集合: {1, 2, 3}\n",
      "测试集使用的 CAMERA_ID 集合: {0, 1, 3}\n",
      "⚠️ 警告: 测试集使用了一些训练集中从未出现过的 CAMERA_ID！\n",
      "ℹ️ 信息: 数据集内使用了多种不同的相机模型。\n",
      "\n",
      "--- 最终诊断 ---\n",
      "✅ 问题找到！测试集图像关联到了无效或与训练集不一致的相机内参模型(CAMERA_ID)。\n",
      "这会导致渲染时使用错误的焦距或分辨率，从而产生模糊/错误的图像。\n",
      "请检查您的数据预处理流程，确保所有图像都正确地关联到了 cameras.txt 中定义的相机模型。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def analyze_camera_ids(images_txt_path, cameras_txt_path):\n",
    "    \"\"\"\n",
    "    读取 images.txt 和 cameras.txt，检查测试集图像关联的 CAMERA_ID 是否一致和有效。\n",
    "    \"\"\"\n",
    "    # 1. 读取 cameras.txt，获取所有有效的 CAMERA_ID 及其信息\n",
    "    valid_camera_ids = {}\n",
    "    with open(cameras_txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.strip().startswith('#'):\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        cam_id = int(parts[0])\n",
    "        model = parts[1]\n",
    "        width, height = int(parts[2]), int(parts[3])\n",
    "        params = \" \".join(parts[4:])\n",
    "        valid_camera_ids[cam_id] = f\"Model: {model}, Resolution: {width}x{height}, Params: {params}\"\n",
    "    \n",
    "    print(\"--- 发现的有效相机模型 (from cameras.txt) ---\")\n",
    "    if not valid_camera_ids:\n",
    "        print(\"❌ 错误: 未能在 cameras.txt 中找到任何有效的相机模型！\")\n",
    "        return\n",
    "    for cam_id, info in valid_camera_ids.items():\n",
    "        print(f\"  CAMERA_ID={cam_id} -> {info}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. 读取 images.txt，检查每张图片的 CAMERA_ID\n",
    "    print(\"\\n--- 检查 images.txt 中的 CAMERA_ID 关联 ---\")\n",
    "    all_images_data = []\n",
    "    with open(images_txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    i = 4 # 跳过文件头\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        parts = line.split()\n",
    "        image_id = int(parts[0])\n",
    "        linked_camera_id = int(parts[8])\n",
    "        name = parts[9]\n",
    "        all_images_data.append({\n",
    "            \"name\": name,\n",
    "            \"linked_camera_id\": linked_camera_id\n",
    "        })\n",
    "        i += 2\n",
    "        \n",
    "    # 按默认顺序（即文件中的读取顺序）来确定测试集\n",
    "    test_image_names = []\n",
    "    issues_found = False\n",
    "    \n",
    "    print(\"\\n[关键] 分析测试集图像的相机模型关联:\")\n",
    "    for i, image_data in enumerate(all_images_data):\n",
    "        if i % 8 == 0:  # 默认的测试集划分规则\n",
    "            test_image_names.append(image_data['name'])\n",
    "            linked_id = image_data['linked_camera_id']\n",
    "            print(f\"  - 测试图像: {image_data['name']}\")\n",
    "            print(f\"    - 关联的 CAMERA_ID: {linked_id}\")\n",
    "            \n",
    "            # 检查这个ID是否在 cameras.txt 中定义过\n",
    "            if linked_id not in valid_camera_ids:\n",
    "                print(\"    - ❌ 严重错误: 这个 CAMERA_ID 在 cameras.txt 中不存在！\")\n",
    "                issues_found = True\n",
    "            else:\n",
    "                print(f\"    - ✅ ID有效。关联的模型信息: {valid_camera_ids[linked_id]}\")\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "    # 3. 检查训练集是否使用了不同的 CAMERA_ID\n",
    "    train_camera_ids = set()\n",
    "    for i, image_data in enumerate(all_images_data):\n",
    "        if i % 8 != 0:\n",
    "            train_camera_ids.add(image_data['linked_camera_id'])\n",
    "            \n",
    "    test_camera_ids = set()\n",
    "    for i, image_data in enumerate(all_images_data):\n",
    "        if i % 8 == 0:\n",
    "            test_camera_ids.add(image_data['linked_camera_id'])\n",
    "\n",
    "    print(\"\\n--- 训练集 vs 测试集 CAMERA_ID 使用情况总结 ---\")\n",
    "    print(f\"训练集使用的 CAMERA_ID 集合: {train_camera_ids}\")\n",
    "    print(f\"测试集使用的 CAMERA_ID 集合: {test_camera_ids}\")\n",
    "    \n",
    "    if len(test_camera_ids.difference(train_camera_ids)) > 0:\n",
    "        print(\"⚠️ 警告: 测试集使用了一些训练集中从未出现过的 CAMERA_ID！\")\n",
    "        issues_found = True\n",
    "        \n",
    "    if len(train_camera_ids) > 1 or len(test_camera_ids) > 1:\n",
    "        print(\"ℹ️ 信息: 数据集内使用了多种不同的相机模型。\")\n",
    "\n",
    "    print(\"\\n--- 最终诊断 ---\")\n",
    "    if issues_found:\n",
    "        print(\"✅ 问题找到！测试集图像关联到了无效或与训练集不一致的相机内参模型(CAMERA_ID)。\")\n",
    "        print(\"这会导致渲染时使用错误的焦距或分辨率，从而产生模糊/错误的图像。\")\n",
    "        print(\"请检查您的数据预处理流程，确保所有图像都正确地关联到了 cameras.txt 中定义的相机模型。\")\n",
    "    else:\n",
    "        print(\"🤔 诊断未确定。测试集和训练集使用了相同且有效的相机内参模型。\")\n",
    "        print(\"如果问题依然存在，可能的原因包括：\")\n",
    "        print(\"  1. 测试集的原始图像文件(.JPG)本身损坏或分辨率极低。\")\n",
    "        print(\"  2. 3DGS代码中存在一个更深层次的、与数据加载相关的未知Bug。\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- 配置区 ---\n",
    "    base_path = \"/root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/\"\n",
    "    images_txt_path = os.path.join(base_path, \"images.txt\")\n",
    "    cameras_txt_path = os.path.join(base_path, \"cameras.txt\")\n",
    "    # --- 结束配置 ---\n",
    "\n",
    "    if not os.path.exists(images_txt_path) or not os.path.exists(cameras_txt_path):\n",
    "        print(\"❌ 错误: 确保 images.txt 和 cameras.txt 文件都在指定路径下。\")\n",
    "        return\n",
    "        \n",
    "    analyze_camera_ids(images_txt_path, cameras_txt_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9d6f01-b48d-4952-8752-487e724f5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 正在读取文件: /root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/images.txt\n",
      "✅ 找到问题图片!\n",
      "   - 索引位置: 0\n",
      "   - 文件名: dslr_images_undistorted/DSC_0323.JPG\n",
      "   - 使用的 CAMERA_ID: 0\n",
      "\n",
      "🔄 正在将索引 0 的图片与索引 1 的图片进行交换...\n",
      "\n",
      "==================================================\n",
      "🎉 文件修复成功！\n",
      "现在，有问题的图片位于训练集位置，而一张正常的图片换到了测试集位置。\n",
      "您可以直接重新运行评估脚本了。\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- 配置区 ---\n",
    "images_txt_path = \"/root/autodl-tmp/gaussian-splatting/data/courtyard/sparse/0/images.txt\"\n",
    "# --- 结束配置 ---\n",
    "\n",
    "def fix_problematic_test_image(file_path):\n",
    "    \"\"\"\n",
    "    通过调换位置，将使用'CAMERA_ID=0'的测试图片从测试集中排除。\n",
    "    \"\"\"\n",
    "    print(f\"🔍 正在读取文件: {file_path}\")\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 文件头是4行注释\n",
    "    header = lines[:4]\n",
    "    image_data_lines = lines[4:]\n",
    "    \n",
    "    # 将图像数据两行一组进行处理\n",
    "    images = []\n",
    "    for i in range(0, len(image_data_lines), 2):\n",
    "        images.append(image_data_lines[i:i+2])\n",
    "        \n",
    "    target_cam_id_to_find = 0\n",
    "    problematic_image_index = -1\n",
    "\n",
    "    # 找到那张被选为测试集且使用了错误ID的图片\n",
    "    # 默认规则是 i % 8 == 0\n",
    "    for i in range(len(images)):\n",
    "        if i % 8 == 0:\n",
    "            line_parts = images[i][0].split()\n",
    "            linked_camera_id = int(line_parts[8])\n",
    "            \n",
    "            if linked_camera_id == target_cam_id_to_find:\n",
    "                problematic_image_index = i\n",
    "                image_name = line_parts[9]\n",
    "                print(f\"✅ 找到问题图片!\")\n",
    "                print(f\"   - 索引位置: {i}\")\n",
    "                print(f\"   - 文件名: {image_name}\")\n",
    "                print(f\"   - 使用的 CAMERA_ID: {linked_camera_id}\")\n",
    "                break\n",
    "    \n",
    "    if problematic_image_index == -1:\n",
    "        print(\"ℹ️ 未在测试集中找到使用 CAMERA_ID=0 的图片。文件可能已经修复或无需修改。\")\n",
    "        return\n",
    "\n",
    "    # 确保我们不会换到文件末尾之外\n",
    "    if problematic_image_index + 1 >= len(images):\n",
    "        print(\"❌ 错误: 问题图片是最后一张，无法进行交换。请手动处理。\")\n",
    "        return\n",
    "        \n",
    "    # 与下一张图片交换位置\n",
    "    print(f\"\\n🔄 正在将索引 {problematic_image_index} 的图片与索引 {problematic_image_index + 1} 的图片进行交换...\")\n",
    "    \n",
    "    temp = images[problematic_image_index]\n",
    "    images[problematic_image_index] = images[problematic_image_index + 1]\n",
    "    images[problematic_image_index + 1] = temp\n",
    "\n",
    "    # 将交换后的数据写回文件\n",
    "    new_content = \"\".join(header)\n",
    "    for image_pair in images:\n",
    "        new_content += \"\".join(image_pair)\n",
    "        \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(new_content)\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🎉 文件修复成功！\")\n",
    "    print(\"现在，有问题的图片位于训练集位置，而一张正常的图片换到了测试集位置。\")\n",
    "    print(\"您可以直接重新运行评估脚本了。\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(images_txt_path):\n",
    "        print(f\"❌ 错误: 文件未找到 at '{images_txt_path}'\")\n",
    "    else:\n",
    "        # 在操作前再次提醒备份\n",
    "        if not os.path.exists(images_txt_path + \".original\"):\n",
    "             print(\"⚠️ 警告: 未检测到备份文件 (.original)。强烈建议先手动备份！\")\n",
    "        fix_problematic_test_image(images_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75267a70-6f51-4177-909e-d2841d466508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀🚀🚀 开始对场景 'pipes' 进行全面诊断 🚀🚀🚀\n",
      "\n",
      "================================================================================\n",
      "PART 1: DETAILED TEXT ANALYSIS REPORT\n",
      "================================================================================\n",
      "训练相机几何中心 (平均位置): [-0.23  0.21  0.29]\n",
      "\n",
      "--- [关键] 逐一分析被选为测试集的相机 ---\n",
      "\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0647.JPG (文件中的第 1 张)\n",
      "    - 位置: [-0.17  0.24  1.28], 与训练中心距离: 0.99 米\n",
      "    - 关联的 CAMERA_ID: 0\n",
      "    - ✅ ID有效。关联模型: Model: PINHOLE, Resolution: 6220x4141, Params: 3430.27 3429.23 3119.2 2057.75\n",
      "\n",
      "  - 测试图像: dslr_images_undistorted/DSC_0639.JPG (文件中的第 9 张)\n",
      "    - 位置: [0.72 0.19 0.59], 与训练中心距离: 0.99 米\n",
      "    - 关联的 CAMERA_ID: 0\n",
      "    - ✅ ID有效。关联模型: Model: PINHOLE, Resolution: 6220x4141, Params: 3430.27 3429.23 3119.2 2057.75\n",
      "\n",
      "--- 训练集 vs 测试集 CAMERA_ID 使用情况总结 ---\n",
      "训练集使用的 CAMERA_ID 集合: {0}\n",
      "测试集使用的 CAMERA_ID 集合: {0}\n",
      "\n",
      "================================================================================\n",
      "PART 2: GENERATING 3D INTERACTIVE VISUALIZATION\n",
      "================================================================================\n",
      "✅ 可视化成功！文件 'pipes_camera_analysis.html' 已生成。\n",
      "👉 请在浏览器中打开它，并仔细观察红色点/线的分布和朝向。\n",
      "\n",
      "================================================================================\n",
      "FINAL DIAGNOSIS\n",
      "================================================================================\n",
      "✅ 诊断完成。根据文件分析，该场景的测试集划分看起来是【健康的】。\n",
      "   - 相机位置和朝向分布合理。\n",
      "   - 测试集使用的相机内参模型也都在训练集中出现过。\n",
      "\n",
      "   - 如果您在该场景上仍然遇到恒定的低分问题，可能的原因包括：\n",
      "     1. 该场景本身的重建难度极高，模型过拟合严重。\n",
      "     2. 原始的测试集.JPG图像文件本身存在问题（如损坏、全黑等）。\n",
      "     3. 3DGS代码中存在针对此类场景的特定Bug。\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ==============================================================================\n",
    "#                      HELPER FUNCTIONS (FROM PREVIOUS SCRIPTS)\n",
    "# ==============================================================================\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    \"\"\"四元数转旋转矩阵\"\"\"\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2, 2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3], 2 * qvec[1] * qvec[3] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3], 1 - 2 * qvec[1]**2 - 2 * qvec[3]**2, 2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[1] * qvec[3] - 2 * qvec[0] * qvec[2], 2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1], 1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]\n",
    "    ])\n",
    "\n",
    "def read_cameras_txt(path):\n",
    "    \"\"\"读取 cameras.txt 文件，返回一个包含相机模型信息的字典。\"\"\"\n",
    "    valid_camera_ids = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.strip().startswith('#'): continue\n",
    "        parts = line.split()\n",
    "        cam_id = int(parts[0])\n",
    "        model, width, height = parts[1], int(parts[2]), int(parts[3])\n",
    "        params = \" \".join(parts[4:])\n",
    "        valid_camera_ids[cam_id] = f\"Model: {model}, Resolution: {width}x{height}, Params: {params}\"\n",
    "    return valid_camera_ids\n",
    "\n",
    "def read_images_txt(path):\n",
    "    \"\"\"读取 images.txt 文件，返回一个包含所有图像详细信息的列表。\"\"\"\n",
    "    all_images_data = []\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    i = 4 # Skip header\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        parts = line.split()\n",
    "        all_images_data.append({\n",
    "            \"image_id\": int(parts[0]),\n",
    "            \"qvec\": np.array(list(map(float, parts[1:5]))),\n",
    "            \"tvec\": np.array(list(map(float, parts[5:8]))),\n",
    "            \"camera_id\": int(parts[8]),\n",
    "            \"name\": parts[9]\n",
    "        })\n",
    "        i += 2\n",
    "    return all_images_data\n",
    "\n",
    "# ==============================================================================\n",
    "#                      ANALYSIS AND VISUALIZATION FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def perform_text_analysis(camera_data, valid_camera_models):\n",
    "    \"\"\"在终端打印详细的文本分析报告。\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PART 1: DETAILED TEXT ANALYSIS REPORT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 按默认规则划分\n",
    "    test_indices = {i for i in range(len(camera_data)) if i % 8 == 0}\n",
    "    \n",
    "    train_positions = np.array([cam['tvec'] for i, cam in enumerate(camera_data) if i not in test_indices])\n",
    "    train_centroid = np.mean(train_positions, axis=0)\n",
    "    \n",
    "    print(f\"训练相机几何中心 (平均位置): {np.round(train_centroid, 2)}\")\n",
    "    print(\"\\n--- [关键] 逐一分析被选为测试集的相机 ---\")\n",
    "\n",
    "    issues_found = False\n",
    "    test_cam_ids = set()\n",
    "\n",
    "    for i in sorted(list(test_indices)):\n",
    "        cam = camera_data[i]\n",
    "        distance = np.linalg.norm(cam['tvec'] - train_centroid)\n",
    "        linked_id = cam['camera_id']\n",
    "        test_cam_ids.add(linked_id)\n",
    "        \n",
    "        print(f\"\\n  - 测试图像: {cam['name']} (文件中的第 {i+1} 张)\")\n",
    "        print(f\"    - 位置: {np.round(cam['tvec'], 2)}, 与训练中心距离: {distance:.2f} 米\")\n",
    "        print(f\"    - 关联的 CAMERA_ID: {linked_id}\")\n",
    "        \n",
    "        if linked_id not in valid_camera_models:\n",
    "            print(\"    - ❌ 严重错误: 这个 CAMERA_ID 在 cameras.txt 中不存在！\")\n",
    "            issues_found = True\n",
    "        else:\n",
    "            print(f\"    - ✅ ID有效。关联模型: {valid_camera_models[linked_id]}\")\n",
    "\n",
    "    train_cam_ids = {cam['camera_id'] for i, cam in enumerate(camera_data) if i not in test_indices}\n",
    "\n",
    "    print(\"\\n--- 训练集 vs 测试集 CAMERA_ID 使用情况总结 ---\")\n",
    "    print(f\"训练集使用的 CAMERA_ID 集合: {train_cam_ids}\")\n",
    "    print(f\"测试集使用的 CAMERA_ID 集合: {test_cam_ids}\")\n",
    "\n",
    "    unseen_ids = test_cam_ids.difference(train_cam_ids)\n",
    "    if unseen_ids:\n",
    "        print(f\"    - ⚠️ 警告: 测试集使用了训练集中从未出现过的 CAMERA_ID: {unseen_ids}\")\n",
    "        issues_found = True\n",
    "        \n",
    "    return issues_found, unseen_ids\n",
    "\n",
    "def create_3d_visualization(camera_data, output_html_file):\n",
    "    \"\"\"生成包含位置和朝向的3D交互式可视化文件。\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PART 2: GENERATING 3D INTERACTIVE VISUALIZATION\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    vector_length = 0.5  # 可视化向量的长度\n",
    "\n",
    "    test_indices = {i for i in range(len(camera_data)) if i % 8 == 0}\n",
    "    train_centroid = np.mean(np.array([c['tvec'] for i, c in enumerate(camera_data) if i not in test_indices]), axis=0)\n",
    "\n",
    "    # 分别处理训练集和测试集\n",
    "    for set_type, color, indices in [(\"Train\", \"blue\", {i for i in range(len(camera_data)) if i not in test_indices}), \n",
    "                                     (\"Test\", \"red\", test_indices)]:\n",
    "        subset = [camera_data[i] for i in sorted(list(indices))]\n",
    "        if not subset: continue\n",
    "\n",
    "        positions = np.array([cam['tvec'] for cam in subset])\n",
    "        names = [cam['name'] for cam in subset]\n",
    "\n",
    "        fig.add_trace(go.Scatter3d(x=positions[:, 0], y=positions[:, 1], z=positions[:, 2], mode='markers',\n",
    "                                   marker=dict(color=color, size=4), name=f'{set_type} Cameras',\n",
    "                                   hovertext=names, hoverinfo='text'))\n",
    "\n",
    "        for cam in subset:\n",
    "            tvec, qvec = cam['tvec'], cam['qvec']\n",
    "            rot_mat = qvec2rotmat(qvec)\n",
    "            direction_vector = -rot_mat[:, 2]\n",
    "            end_point = tvec + direction_vector * vector_length\n",
    "            fig.add_trace(go.Scatter3d(x=[tvec[0], end_point[0]], y=[tvec[1], end_point[1]], z=[tvec[2], end_point[2]],\n",
    "                                       mode='lines', line=dict(color=color, width=3),\n",
    "                                       hoverinfo='none', showlegend=False))\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=[train_centroid[0]], y=[train_centroid[1]], z=[train_centroid[2]], mode='markers',\n",
    "                               marker=dict(color='lime', size=10, symbol='cross'), name='训练集中心'))\n",
    "    \n",
    "    fig.update_layout(title=\"相机位置与朝向可视化 (蓝色=训练, 红色=测试)\",\n",
    "                      scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z', aspectratio=dict(x=1, y=1, z=1)),\n",
    "                      margin=dict(l=0, r=0, b=0, t=40))\n",
    "\n",
    "    fig.write_html(output_html_file)\n",
    "    print(f\"✅ 可视化成功！文件 '{output_html_file}' 已生成。\")\n",
    "    print(\"👉 请在浏览器中打开它，并仔细观察红色点/线的分布和朝向。\")\n",
    "\n",
    "# ==============================================================================\n",
    "#                                MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数，执行对指定场景的全面诊断。\"\"\"\n",
    "    # --- [ 配置区 ] ---\n",
    "    # 只需修改 SCENE_NAME 即可对不同场景进行分析\n",
    "    SCENE_NAME = \"pipes\"\n",
    "    # --- [ 结束配置 ] ---\n",
    "    \n",
    "    # 自动构建路径\n",
    "    base_path = f\"/root/autodl-tmp/gaussian-splatting/data/{SCENE_NAME}/sparse/0/\"\n",
    "    images_txt_path = os.path.join(base_path, \"images.txt\")\n",
    "    cameras_txt_path = os.path.join(base_path, \"cameras.txt\")\n",
    "    output_html_file = f\"{SCENE_NAME}_camera_analysis.html\"\n",
    "\n",
    "    print(f\"🚀🚀🚀 开始对场景 '{SCENE_NAME}' 进行全面诊断 🚀🚀🚀\")\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    if not all(os.path.exists(p) for p in [images_txt_path, cameras_txt_path]):\n",
    "        print(f\"❌ 错误: 找不到必要的COLMAP文件。请确保以下路径正确:\\n - {images_txt_path}\\n - {cameras_txt_path}\")\n",
    "        return\n",
    "\n",
    "    # 1. 读取数据\n",
    "    valid_camera_models = read_cameras_txt(cameras_txt_path)\n",
    "    all_camera_data = read_images_txt(images_txt_path)\n",
    "    if not valid_camera_models or not all_camera_data:\n",
    "        print(\"❌ 错误: 读取相机或图像数据失败，无法继续分析。\")\n",
    "        return\n",
    "\n",
    "    # 2. 执行文本分析\n",
    "    issues_found, unseen_ids = perform_text_analysis(all_camera_data, valid_camera_models)\n",
    "    \n",
    "    # 3. 生成3D可视化\n",
    "    create_3d_visualization(all_camera_data, output_html_file)\n",
    "\n",
    "    # 4. 输出最终诊断结论\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL DIAGNOSIS\")\n",
    "    print(\"=\"*80)\n",
    "    if issues_found:\n",
    "        print(f\"✅ 问题确认！诊断结果指向【相机内参不匹配】。\")\n",
    "        print(f\"   - 原因: 测试集中的部分图像使用了相机模型ID {unseen_ids}，而这个模型从未在训练集中出现过。\")\n",
    "        print(f\"   - 影响: 这会导致渲染器使用未经优化的、不兼容的相机参数，从而产生错误的、模糊的图像（'浓雾'现象）。\")\n",
    "        print(\"\\n   - 解决方案建议:\")\n",
    "        print(\"     1. (推荐) 修改 `images.txt` 文件，将所有图像的 CAMERA_ID 统一为训练集中最常用的一个。\")\n",
    "        print(\"     2. 或者，通过调换 `images.txt` 中的行顺序，将使用这些 '未见过' ID的图像从测试集中排除。\")\n",
    "    else:\n",
    "        print(\"✅ 诊断完成。根据文件分析，该场景的测试集划分看起来是【健康的】。\")\n",
    "        print(\"   - 相机位置和朝向分布合理。\")\n",
    "        print(\"   - 测试集使用的相机内参模型也都在训练集中出现过。\")\n",
    "        print(\"\\n   - 如果您在该场景上仍然遇到恒定的低分问题，可能的原因包括：\")\n",
    "        print(\"     1. 该场景本身的重建难度极高，模型过拟合严重。\")\n",
    "        print(\"     2. 原始的测试集.JPG图像文件本身存在问题（如损坏、全黑等）。\")\n",
    "        print(\"     3. 3DGS代码中存在针对此类场景的特定Bug。\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pandas\n",
    "        import plotly\n",
    "    except ImportError:\n",
    "        print(\"⚠️ 警告: 缺少必要的库。请先运行: pip install pandas plotly\")\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69879c0-6fde-47ac-a7b6-b29eea679c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
