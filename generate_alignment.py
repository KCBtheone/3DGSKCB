# generate_alignment.py
import open3d as o3d
import numpy as np
import json
import os
import sys
from argparse import ArgumentParser
import copy

def calculate_alignment_transform(pred_pcd_path, gt_pcd_path, voxel_size):
    """
    ä½¿ç”¨å…¨å±€+å±€éƒ¨é…å‡†ç®—æ³•ï¼Œè‡ªåŠ¨è®¡ç®—ä»é¢„æµ‹ç‚¹äº‘åˆ°çœŸå€¼ç‚¹äº‘çš„å¯¹é½å˜æ¢çŸ©é˜µã€‚

    Args:
        pred_pcd_path (str): é¢„æµ‹ç‚¹äº‘ (.ply) çš„è·¯å¾„ã€‚
        gt_pcd_path (str): çœŸå€¼ç‚¹äº‘ (.ply) çš„è·¯å¾„ã€‚
        voxel_size (float): ç”¨äºä¸‹é‡‡æ ·å’Œç‰¹å¾è®¡ç®—çš„ä½“ç´ å¤§å°ã€‚

    Returns:
        np.ndarray: 4x4 çš„å˜æ¢çŸ©é˜µï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    print("â”€"*80)
    print("ğŸš€ å¼€å§‹è‡ªåŠ¨è®¡ç®—å¯¹é½å˜æ¢çŸ©é˜µ...")
    
    # 1. åŠ è½½ç‚¹äº‘
    print(f"  1. æ­£åœ¨åŠ è½½ç‚¹äº‘:\n     - é¢„æµ‹: {pred_pcd_path}\n     - çœŸå€¼: {gt_pcd_path}")
    try:
        pred_pcd = o3d.io.read_point_cloud(pred_pcd_path)
        gt_pcd = o3d.io.read_point_cloud(gt_pcd_path)
        if not pred_pcd.has_points() or not gt_pcd.has_points():
            print("  âŒ é”™è¯¯: ä¸€ä¸ªæˆ–ä¸¤ä¸ªç‚¹äº‘æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•åŠ è½½ã€‚")
            return None
    except Exception as e:
        print(f"  âŒ é”™è¯¯: åŠ è½½ç‚¹äº‘å¤±è´¥: {e}")
        return None

    # 2. é¢„å¤„ç†ï¼šä¸‹é‡‡æ ·ä»¥æé«˜é€Ÿåº¦å’Œé²æ£’æ€§
    print(f"  2. æ­£åœ¨è¿›è¡Œä½“ç´ ä¸‹é‡‡æ · (voxel_size = {voxel_size})...")
    pred_down = pred_pcd.voxel_down_sample(voxel_size)
    gt_down = gt_pcd.voxel_down_sample(voxel_size)

    # 3. è®¡ç®—FPFHç‰¹å¾ç”¨äºå…¨å±€é…å‡†
    print("  3. æ­£åœ¨è®¡ç®—æ³•çº¿å’ŒFPFHç‰¹å¾...")
    radius_normal = voxel_size * 2
    pred_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))
    gt_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))

    radius_feature = voxel_size * 5
    pred_fpfh = o3d.pipelines.registration.compute_fpfh_feature(pred_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))
    gt_fpfh = o3d.pipelines.registration.compute_fpfh_feature(gt_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))

    # 4. å…¨å±€é…å‡† (RANSAC)
    print("  4. æ­£åœ¨æ‰§è¡Œå…¨å±€é…å‡† (RANSAC)...")
    distance_threshold = voxel_size * 1.5
    result_ransac = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
        pred_down, gt_down, pred_fpfh, gt_fpfh, True,
        distance_threshold,
        o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 4, 
        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),
         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
        o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))
    
    coarse_transformation = result_ransac.transformation
    print(f"     -> å…¨å±€é…å‡†å®Œæˆ. Fitness: {result_ransac.fitness:.4f}, Inlier RMSE: {result_ransac.inlier_rmse:.4f}")

    # 5. å±€éƒ¨é…å‡† (ICP)
    print("  5. æ­£åœ¨æ‰§è¡Œå±€éƒ¨ç²¾ç»†é…å‡† (ICP)...")
    # ä½¿ç”¨ä¸Šä¸€æ­¥çš„ç²—å¯¹é½ç»“æœä½œä¸ºICPçš„åˆå§‹å˜æ¢
    icp_threshold = voxel_size * 0.4
    result_icp = o3d.pipelines.registration.registration_icp(
        pred_down, gt_down, icp_threshold, coarse_transformation,
        o3d.pipelines.registration.TransformationEstimationPointToPoint(),
        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))

    final_transformation = result_icp.transformation
    print(f"     -> ICPå®Œæˆ. Fitness: {result_icp.fitness:.4f}, Inlier RMSE: {result_icp.inlier_rmse:.4f}")
    
    if result_icp.fitness < 0.8: # Fitnessè¡¡é‡é‡å åŒºåŸŸçš„æ¯”ä¾‹ï¼Œå€¼å¤ªä½è¯´æ˜å¯¹é½æ•ˆæœå·®
        print("  âš ï¸ è­¦å‘Š: ICP Fitness å€¼è¾ƒä½ï¼Œå¯¹é½æ•ˆæœå¯èƒ½ä¸ä½³ã€‚è¯·å°è¯•è°ƒæ•´ --voxel_sizeã€‚")
    
    print("âœ… å¯¹é½çŸ©é˜µè®¡ç®—æˆåŠŸ!")
    print("â”€"*80)

    # è¿”å›æœ€ç»ˆçš„å˜æ¢çŸ©é˜µ
    return final_transformation

def visualize_alignment(pred_pcd_path, gt_pcd_path, transform):
    """å¯è§†åŒ–å¯¹é½å‰åçš„æ•ˆæœï¼Œç”¨äºè°ƒè¯•"""
    print("\n[å¯é€‰] æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœä»¥ä¾›æ£€æŸ¥...")
    source = o3d.io.read_point_cloud(pred_pcd_path)
    target = o3d.io.read_point_cloud(gt_pcd_path)

    # åŸå§‹çŠ¶æ€ï¼ˆä¸åŒé¢œè‰²ï¼‰
    source.paint_uniform_color([1, 0.706, 0])  # é»„è‰²
    target.paint_uniform_color([0, 0.651, 0.929]) # è“è‰²
    # o3d.visualization.draw_geometries([source, target], window_name="å¯¹é½å‰")

    # å¯¹é½åçŠ¶æ€
    source_transformed = copy.deepcopy(source)
    source_transformed.transform(transform)
    o3d.visualization.draw_geometries([source_transformed, target], window_name="å¯¹é½å (è¯·æ£€æŸ¥æ˜¯å¦é‡åˆ)")

def main():
    parser = ArgumentParser(description="è‡ªåŠ¨è®¡ç®—3DGSé¢„æµ‹ç‚¹äº‘åˆ°çœŸå€¼ç‚¹äº‘çš„å¯¹é½çŸ©é˜µï¼Œå¹¶ä¿å­˜ä¸ºJSONæ–‡ä»¶ã€‚")
    parser.add_argument("--pred_pcd_path", type=str, required=True, 
                        help="é¢„æµ‹ç‚¹äº‘çš„è·¯å¾„ã€‚ä»ä»»æ„ä¸€ä¸ªå®éªŒçš„è¾“å‡ºä¸­é€‰å–å³å¯, e.g., 'output/exp1/point_cloud/iteration_30000/point_cloud.ply'")
    parser.add_argument("--gt_pcd_path", type=str, required=True, 
                        help="çœŸå€¼ç‚¹äº‘çš„è·¯å¾„ã€‚e.g., 'data/scene/gt.ply'")
    parser.add_argument("--output_json", type=str, required=True, 
                        help="è¾“å‡ºçš„å¯¹é½JSONæ–‡ä»¶çš„è·¯å¾„ã€‚e.g., 'eth3d_alignments_v2.json'")
    parser.add_argument("--scene_name", type=str, required=True, 
                        help="å½“å‰åœºæ™¯çš„åç§°ï¼Œå°†ä½œä¸ºJSONæ–‡ä»¶ä¸­çš„keyã€‚ e.g., 'electro'")
    parser.add_argument("--voxel_size", type=float, default=0.02, 
                        help="ç”¨äºç‚¹äº‘ä¸‹é‡‡æ ·çš„ä½“ç´ å¤§å°(ç±³)ã€‚è¿™æ˜¯æœ€é‡è¦çš„å‚æ•°ï¼Œéœ€è¦æ ¹æ®åœºæ™¯å°ºåº¦è¿›è¡Œè°ƒæ•´ã€‚")
    parser.add_argument("--visualize", action="store_true", 
                        help="è®¡ç®—åæ˜¾ç¤ºä¸€ä¸ª3Dçª—å£æ¥å¯è§†åŒ–å¯¹é½æ•ˆæœã€‚")
    
    args = parser.parse_args()

    # è®¡ç®—å˜æ¢çŸ©é˜µ
    transform_matrix = calculate_alignment_transform(args.pred_pcd_path, args.gt_pcd_path, args.voxel_size)

    if transform_matrix is None:
        print("\nâŒ è®¡ç®—å¤±è´¥ï¼Œæœªç”ŸæˆJSONæ–‡ä»¶ã€‚")
        sys.exit(1)

    # åŠ è½½æˆ–åˆ›å»ºç°æœ‰çš„JSONæ–‡ä»¶ï¼Œä»¥æ”¯æŒè¿½åŠ æ–°åœºæ™¯
    if os.path.exists(args.output_json):
        print(f"\nğŸ”„ å‘ç°ç°æœ‰JSONæ–‡ä»¶ '{args.output_json}', å°†æ›´æ–°æˆ–æ·»åŠ åœºæ™¯ '{args.scene_name}'...")
        with open(args.output_json, 'r') as f:
            data = json.load(f)
    else:
        print(f"\nâœ¨ æœªå‘ç°ç°æœ‰JSONæ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶ '{args.output_json}'...")
        data = {}

    # æ›´æ–°æ•°æ®å¹¶ä¿å­˜
    data[args.scene_name] = transform_matrix.tolist() # Numpy arrayè½¬ä¸ºlistæ‰èƒ½åºåˆ—åŒ–

    with open(args.output_json, 'w') as f:
        json.dump(data, f, indent=4)
    
    print(f"âœ… æˆåŠŸå°†åœºæ™¯ '{args.scene_name}' çš„å¯¹é½çŸ©é˜µä¿å­˜åˆ° '{args.output_json}'!")
    print("\nç°åœ¨æ‚¨å¯ä»¥åœ¨ä¸»è¯„ä¼°è„šæœ¬ä¸­ä½¿ç”¨è¿™ä¸ªJSONæ–‡ä»¶äº†ã€‚")
    
    # å¯è§†åŒ–æ£€æŸ¥
    if args.visualize:
        visualize_alignment(args.pred_pcd_path, args.gt_pcd_path, transform_matrix)

if __name__ == "__main__":
    main()