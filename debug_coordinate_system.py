import argparse
import numpy as np
import torch
import os

# ä»æ‚¨çš„é¡¹ç›®ä¸­å¯¼å…¥æ‰€æœ‰å¿…è¦çš„ç±»å’Œå‡½æ•°
from scene import Scene
from scene.gaussian_model import GaussianModel
# =================================================================================
# >>> [ ğŸš€ æ ¸å¿ƒä¿®å¤ ] <<<
# å¯¼å…¥æ­£ç¡®çš„ã€åœ¨æ‚¨æ–‡ä»¶ä¸­å­˜åœ¨çš„å‡½æ•°åï¼šreadColmapScene
# =================================================================================
from scene.dataset_readers import readColmapScene

def print_matrix(name, matrix):
    """ä¸€ä¸ªç”¨äºæ ¼å¼åŒ–æ‰“å°çŸ©é˜µçš„è¾…åŠ©å‡½æ•°ã€‚"""
    print(f"--- Matrix: {name} ---")
    if isinstance(matrix, torch.Tensor):
        matrix = matrix.detach().cpu().numpy()
    
    print(f"Shape: {matrix.shape}, Dtype: {matrix.dtype}")
    np.set_printoptions(precision=4, suppress=True)
    print(matrix)
    print("-" * (len(name) + 14))
    np.set_printoptions()

def run_coordinate_investigation_v2(cli_args):
    """
    æ·±å…¥æ•°æ®åŠ è½½æµç¨‹ï¼Œæ‰“å°å‡ºæ¯ä¸€æ­¥çš„åæ ‡ç³»å˜æ¢çŸ©é˜µã€‚
    æ­¤ç‰ˆæœ¬ä¸æ‚¨çš„æ–°ç‰ˆ dataset_readers.py å®Œå…¨å…¼å®¹ã€‚
    """
    print("=======================================================================")
    print("ğŸš€ å¼€å§‹æ‰§è¡Œåæ ‡ç³»å˜æ¢æµç¨‹æ·±åº¦è¯Šæ–­ (v2)...")
    print(f"   åˆ†æåœºæ™¯: {cli_args.source_path}")
    print("=======================================================================")

    try:
        # --- æ­¥éª¤ 1: ç›´æ¥è°ƒç”¨ readColmapScene ---
        print("\n--- [ é˜¶æ®µ 1: è°ƒç”¨ readColmapScene åŠ è½½åŸå§‹ COLMAP æ•°æ® ] ---")
        scene_info = readColmapScene(path=cli_args.source_path, images=cli_args.images, eval=cli_args.eval)
        print("âœ… readColmapScene æ‰§è¡Œå®Œæ¯•ã€‚")

        if not scene_info.train_cameras:
            print("âŒ é”™è¯¯: æœªèƒ½åŠ è½½ä»»ä½•è®­ç»ƒç›¸æœºä¿¡æ¯ï¼"); return
        
        sample_cam_info = scene_info.train_cameras[0]
        print(f"\n--- [ é˜¶æ®µ 2: åˆ†ææ ·æœ¬ç›¸æœº '{sample_cam_info.image_name}' çš„ CamInfo å¯¹è±¡ ] ---")
        print_matrix("R (æ—‹è½¬çŸ©é˜µ, æ¥è‡ª CamInfo)", sample_cam_info.R)
        print_matrix("T (å¹³ç§»å‘é‡, æ¥è‡ª CamInfo)", sample_cam_info.T)
        
        # --- æ­¥éª¤ 2: å®Œæ•´åˆå§‹åŒ– Scene å¯¹è±¡ä»¥è·å–æœ€ç»ˆæ¸²æŸ“çŸ©é˜µ ---
        print("\n--- [ é˜¶æ®µ 3: å®Œæ•´åˆå§‹åŒ– Scene å¯¹è±¡ä»¥è·å–æœ€ç»ˆæ¸²æŸ“çŸ©é˜µ ] ---")

        class Args:
            def __init__(self):
                self.source_path = cli_args.source_path; self.model_path = cli_args.model_path if cli_args.model_path else "./output/coord_debug"
                self.images = cli_args.images; self.resolution = cli_args.resolution
                self.white_background = False; self.sh_degree = 3; self.eval = cli_args.eval; self.data_device = "cuda"
                self.convert_SHs_python = False; self.compute_cov3D_python = False
        
        args = Args()
        os.makedirs(args.model_path, exist_ok=True)
        gaussians = GaussianModel(sh_degree=args.sh_degree)
        
        # æ‚¨çš„ Scene.__init__ ä¼šå†æ¬¡è°ƒç”¨ readColmapSceneï¼Œä½†æ²¡å…³ç³»ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è·å–æœ€ç»ˆçš„ Camera å¯¹è±¡
        scene = Scene(args, gaussians, shuffle=False)
        print("âœ… Scene å¯¹è±¡åˆå§‹åŒ–å®Œæ¯•ã€‚")
        
        if not scene.getTrainCameras():
            print("âŒ é”™è¯¯: Scene å¯¹è±¡ä¸­æ²¡æœ‰è®­ç»ƒç›¸æœºï¼"); return
            
        final_sample_cam = scene.getTrainCameras()[0]
        
        print(f"\n--- [ é˜¶æ®µ 4: åˆ†ææœ€ç»ˆ Camera å¯¹è±¡çš„æ¸²æŸ“çŸ©é˜µ ] ---")
        
        print_matrix("world_view_transform (W2C çŸ©é˜µ)", final_sample_cam.world_view_transform)
        print_matrix("projection_matrix (æŠ•å½±çŸ©é˜µ)", final_sample_cam.projection_matrix)
        print_matrix("full_proj_transform (å®Œæ•´å˜æ¢çŸ©é˜µ)", final_sample_cam.full_proj_transform)

        # --- æ­¥éª¤ 3: åˆ†æä¸è§£è¯» ---
        print("\n--- [ é˜¶æ®µ 5: åæ ‡ç³»åˆ†æä¸è§£è¯» ] ---")
        
        w2c = final_sample_cam.world_view_transform.detach().cpu().numpy()
        c2w = np.linalg.inv(w2c)
        camera_center = c2w[:3, 3]
        print(f"æ ¹æ® W2C çŸ©é˜µè®¡ç®—å‡ºçš„ç›¸æœºä¸­å¿ƒ (ä¸–ç•Œåæ ‡): {np.array2string(camera_center, precision=4, suppress_small=True)}")

        R_w2c = w2c[:3, :3]
        if abs(R_w2c[1, 1]) < 0.2 and abs(R_w2c[2, 2]) < 0.2 and abs(abs(R_w2c[1, 2])) > 0.8:
            print("ğŸš¨ [é«˜é£é™©è­¦å‘Š] æ£€æµ‹åˆ° W2C çŸ©é˜µä¸­å¯èƒ½å­˜åœ¨ Y-Z è½´ç¿»è½¬ï¼")
            print("   è¿™é€šå¸¸æ˜¯ NeRF++ (ç”±å†…æœå¤–) åæ ‡ç³»å˜æ¢çš„ç‰¹å¾ã€‚å¯¹äº ETH3D è¿™ç±»å‰å‘æ‹æ‘„åœºæ™¯ï¼Œ")
            print("   è¿™å¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªé”™è¯¯çš„å˜æ¢ï¼Œå¹¶ä¼šå¯¼è‡´è®­ç»ƒå¤±è´¥ã€‚")
        else:
            print("âœ… W2C çŸ©é˜µçš„æ—‹è½¬éƒ¨åˆ†çœ‹èµ·æ¥æ˜¯å¸¸è§„çš„ï¼Œæœªæ£€æµ‹åˆ°æ˜æ˜¾çš„ Y-Z è½´ç¿»è½¬ã€‚")
        
        print("\n=======================================================================")
        print("ğŸ•µï¸ åæ ‡ç³»ä¾¦æ¢å·¥ä½œå®Œæˆã€‚")
        print("=======================================================================")

    except Exception as e:
        print(f"âŒ åœ¨è¯Šæ–­è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼"); print(f"   é”™è¯¯ä¿¡æ¯: {e}"); import traceback; traceback.print_exc()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="3DGSåæ ‡ç³»å˜æ¢æµç¨‹æ·±åº¦è¯Šæ–­å·¥å…· (v2)ã€‚")
    parser.add_argument("-s", "--source_path", required=True, type=str)
    parser.add_argument("--images", default="images", type=str)
    parser.add_argument("-r", "--resolution", default=-1, type=int)
    parser.add_argument("--eval", action="store_true")
    parser.add_argument("-m", "--model_path", default="", type=str)
    
    cli_args = parser.parse_args()
    run_coordinate_investigation_v2(cli_args)