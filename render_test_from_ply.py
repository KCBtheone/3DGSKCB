# render_test_from_ply.py
# ä¸€ä¸ªä¸“é—¨ä» .ply æ–‡ä»¶åŠ è½½æ¨¡å‹å¹¶æ¸²æŸ“æµ‹è¯•é›†è§†è§’çš„è„šæœ¬

import os
import sys
import torch
import re
from argparse import ArgumentParser
from PIL import Image
from tqdm import tqdm
import math

# --- æ­¥éª¤ 1: ç¡®ä¿é¡¹ç›®è·¯å¾„åœ¨sys.pathä¸­å¹¶å¯¼å…¥æ ¸å¿ƒæ¨¡å— ---
try:
    project_root = os.path.dirname(os.path.abspath(__file__))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    from scene.cameras import Camera
    from scene.gaussian_model import GaussianModel
    from scene import Scene
    from arguments import ModelParams, PipelineParams
    from utils.general_utils import safe_state
    from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer

    print("[SUCCESS] æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸã€‚")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}\nè¯·ç¡®ä¿æ­¤è„šæœ¬ä½äº 3D Gaussian Splatting é¡¹ç›®çš„æ ¹ç›®å½•ã€‚")
    sys.exit(1)

# ==================== é…ç½®åŠ è½½å‡½æ•° (å·²éªŒè¯) ====================
def load_config(cfg_path: str) -> dict:
    try:
        import pickle
        with open(cfg_path, 'rb') as f: return vars(pickle.load(f))
    except Exception:
        try:
            with open(cfg_path, 'r') as f: content = f.read().strip()
            if content.startswith("Namespace(") and content.endswith(")"): content = content[10:-1]
            pattern = re.compile(r"(\w+)\s*=\s*('([^']*)'|\"([^\"]*)\"|\[.*?\]|[\w.-]+|True|False|None)")
            matches = pattern.findall(content)
            cfg_dict = {}
            for key, val_group, str_val1, str_val2 in matches:
                val_str = val_group
                if (val_str.startswith("'") and val_str.endswith("'")) or (val_str.startswith('"') and val_str.endswith('"')): cfg_dict[key] = val_str[1:-1]
                elif val_str == 'True': cfg_dict[key] = True
                elif val_str == 'False': cfg_dict[key] = False
                elif val_str == 'None': cfg_dict[key] = None
                elif val_str.startswith('[') and val_str.endswith(']'):
                    try: cfg_dict[key] = eval(val_str)
                    except: cfg_dict[key] = val_str
                else:
                    try:
                        if '.' in val_str: cfg_dict[key] = float(val_str)
                        else: cfg_dict[key] = int(val_str)
                    except ValueError: cfg_dict[key] = val_str
            return cfg_dict
        except Exception as e: raise IOError(f"æ— æ³•è§£æ '{os.path.basename(cfg_path)}': {e}")

# ==================== æ ¸å¿ƒæ¸²æŸ“å‡½æ•° ====================
@torch.no_grad()
def render_test_set(args):
    """
    åŠ è½½æ¨¡å‹å¹¶æ¸²æŸ“æµ‹è¯•é›†çš„æ‰€æœ‰è§†è§’ã€‚
    """
    print("ğŸš€ å¼€å§‹ä» PLY æ–‡ä»¶æ¸²æŸ“æµ‹è¯•é›†...")

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f" - ä½¿ç”¨è®¾å¤‡: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")

    # 1. åŠ è½½é…ç½®
    cfg_path = os.path.join(args.model_path, "cfg_args")
    if not os.path.exists(cfg_path):
        print(f"âŒ é”™è¯¯: åœ¨'{args.model_path}'ä¸­æ‰¾ä¸åˆ° 'cfg_args' é…ç½®æ–‡ä»¶ã€‚"); return
    
    parser = ArgumentParser()
    model_params_def = ModelParams(parser)
    pipe_params_def = PipelineParams(parser)
    args_defaults = parser.parse_args([])
    saved_cfg_dict = load_config(cfg_path)
    for k, v in saved_cfg_dict.items():
        if hasattr(args_defaults, k): setattr(args_defaults, k, v)

    args_defaults.source_path = args.source_path
    args_defaults.model_path = args.model_path
    model_params = model_params_def.extract(args_defaults)
    pipe_params = pipe_params_def.extract(args_defaults)
    
    # 2. ä» PLY æ–‡ä»¶åŠ è½½æ¨¡å‹
    print(f" - æ­£åœ¨ä» PLY æ–‡ä»¶åŠ è½½æ¨¡å‹: {args.ply_path}")
    if not os.path.exists(args.ply_path):
        print(f"âŒ é”™è¯¯: PLY æ–‡ä»¶ä¸å­˜åœ¨: {args.ply_path}"); return
    
    gaussians_from_ply = GaussianModel(model_params.sh_degree)
    gaussians_from_ply.load_ply(args.ply_path)
    print(f"   -> ä» PLY åŠ è½½æˆåŠŸ: {gaussians_from_ply.get_xyz.shape[0]} ä¸ªé«˜æ–¯ç‚¹ã€‚")

    # 3. åˆ›å»º Scene å¹¶æ³¨å…¥æ¨¡å‹
    print(f" - æ­£åœ¨ä» '{model_params.source_path}' åŠ è½½åœºæ™¯å’Œç›¸æœº...")
    # å…³é”®ï¼šç¡®ä¿ eval=Trueï¼Œè¿™æ · Colmap åŠ è½½å™¨æ‰ä¼šæ­£ç¡®åˆ†å‰²è®­ç»ƒ/æµ‹è¯•é›†
    model_params.eval = True 
    scene = Scene(model_params, GaussianModel(model_params.sh_degree), load_iteration=None, shuffle=False)
    scene.gaussians = gaussians_from_ply
    print("   -> å·²æˆåŠŸå°† PLY åŠ è½½çš„æ¨¡å‹æ³¨å…¥ Scene å¯¹è±¡ã€‚")
    
    # â€¼ï¸â€¼ï¸â€¼ï¸ æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨ getTestCameras() â€¼ï¸â€¼ï¸â€¼ï¸
    cameras = scene.getTestCameras()
    if not cameras:
        print("âŒ é”™è¯¯: æœªèƒ½åŠ è½½ä»»ä½•æµ‹è¯•ç›¸æœºã€‚è¯·æ£€æŸ¥ä½ çš„æ•°æ®æºæ˜¯å¦åŒ…å«æµ‹è¯•é›†åˆ†å‰²ã€‚")
        return
    print(f"   -> åŠ è½½æˆåŠŸ: {len(cameras)} ä¸ªæµ‹è¯•ç›¸æœºã€‚")

    # 4. å‡†å¤‡å¹¶æ‰§è¡Œæ¸²æŸ“
    os.makedirs(args.output_path, exist_ok=True)
    background = torch.tensor([1,1,1] if model_params.white_background else [0,0,0], dtype=torch.float32, device=device)

    print(f" - å¼€å§‹æ¸²æŸ“ {len(cameras)} ä¸ªè§†è§’ï¼Œç»“æœä¿å­˜è‡³ '{args.output_path}'...")
    for camera in tqdm(cameras, desc="æ¸²æŸ“æµ‹è¯•é›†"):
        camera.to_device(device)
        
        tanfovx = math.tan(camera.FoVx * 0.5)
        tanfovy = math.tan(camera.FoVy * 0.5)
        
        raster_settings = GaussianRasterizationSettings(
            image_height=int(camera.image_height), image_width=int(camera.image_width),
            tanfovx=tanfovx, tanfovy=tanfovy, bg=background, scale_modifier=1.0,
            viewmatrix=camera.world_view_transform, projmatrix=camera.full_proj_transform,
            sh_degree=scene.gaussians.active_sh_degree, campos=camera.camera_center,
            prefiltered=False, debug=getattr(pipe_params, 'debug', False),
            antialiasing=getattr(pipe_params, 'antialiasing', False)
        )
        
        rasterizer = GaussianRasterizer(raster_settings=raster_settings)
        means3D, opacities, scales, rotations, shs = (
            scene.gaussians.get_xyz, scene.gaussians.get_opacity, scene.gaussians.get_scaling,
            scene.gaussians.get_rotation, scene.gaussians.get_features
        )
        
        rasterizer_outputs = rasterizer(
            means3D=means3D, means2D=torch.zeros_like(means3D, requires_grad=True, device=device)+0,
            shs=shs, colors_precomp=None, opacities=opacities, scales=scales,
            rotations=rotations, cov3D_precomp=None
        )
        rendered_image = rasterizer_outputs[0]
        
        # ä¿å­˜å›¾åƒ
        img_tensor = rendered_image.clamp(0.0, 1.0)
        img_np = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype("uint8")
        pil_img = Image.fromarray(img_np)
        pil_img.save(os.path.join(args.output_path, f"{os.path.splitext(camera.image_name)[0]}.png"))

    print("\nâœ… æµ‹è¯•é›†æ¸²æŸ“å…¨éƒ¨å®Œæˆï¼")

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    parser = ArgumentParser(description="ä» .ply æ–‡ä»¶åŠ è½½3DGSæ¨¡å‹å¹¶æ¸²æŸ“å…¶ **æµ‹è¯•é›†** è§†è§’ã€‚")
    parser.add_argument("model_path", type=str, help="æŒ‡å‘æ¨¡å‹å®éªŒç›®å½•çš„è·¯å¾„ (ç”¨äºåŠ è½½ cfg_args)ã€‚")
    parser.add_argument("ply_path", type=str, help="æŒ‡å‘è¦æ¸²æŸ“çš„ point_cloud.ply æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ã€‚")
    parser.add_argument("output_path", type=str, help="ä¿å­˜æ¸²æŸ“å›¾åƒçš„è¾“å‡ºæ–‡ä»¶å¤¹ã€‚")
    parser.add_argument("-s", "--source_path", type=str, required=True, help="ã€å¿…éœ€ã€‘æŒ‡å‘åŸå§‹åœºæ™¯æ•°æ®æºçš„è·¯å¾„ (å¦‚ COLMAP ç›®å½•)ã€‚")
    args = parser.parse_args()

    def camera_to_device(self, device):
        for attr in ['world_view_transform', 'full_proj_transform', 'camera_center']:
            if hasattr(self, attr) and isinstance(getattr(self, attr), torch.Tensor):
                setattr(self, attr, getattr(self, attr).to(device))
    Camera.to_device = camera_to_device
    
    render_test_set(args)