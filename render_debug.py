# render_debug_v3.py
# å¢åŠ äº†å¯¹ scaling å’Œ opacity æ•°å€¼çŠ¶æ€çš„æ£€æŸ¥

import os
import sys
import torch
import re
from argparse import ArgumentParser
from PIL import Image
from tqdm import tqdm
import time

# --- æ­¥éª¤ 0: ç¡®ä¿é¡¹ç›®è·¯å¾„åœ¨sys.pathä¸­ ---
try:
    project_root = os.path.dirname(os.path.abspath(__file__))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    print(f"[DEBUG] è„šæœ¬å¯åŠ¨ï¼Œå·²å°†é¡¹ç›®æ ¹ç›®å½• '{project_root}' æ·»åŠ åˆ° sys.path")
    
    from arguments import ModelParams, PipelineParams, OptimizationParams
    from scene import Scene, GaussianModel
    from gaussian_renderer import render
    from utils.system_utils import searchForMaxIteration
    from utils.general_utils import safe_state
    from scene.cameras import Camera
    print("[SUCCESS] æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸï¼ç¯å¢ƒè®¾ç½®æ­£ç¡®ã€‚")
except ImportError as e:
    print(f"âŒ [è‡´å‘½é”™è¯¯] å¯¼å…¥æ ¸å¿ƒæ¨¡å—å¤±è´¥: {e}")
    print("   -> è¯·ç¡®ä¿æ­¤è„šæœ¬ä½äº 3D Gaussian Splatting é¡¹ç›®çš„æ ¹ç›®å½•ã€‚")
    sys.exit(1)

# ==================== é…ç½®åŠ è½½å‡½æ•° (ä¸å˜) ====================
def load_config(cfg_path: str) -> dict:
    try:
        import pickle
        with open(cfg_path, 'rb') as f: return vars(pickle.load(f))
    except Exception:
        try:
            with open(cfg_path, 'r') as f: content = f.read().strip()
            if content.startswith("Namespace(") and content.endswith(")"): content = content[10:-1]
            pattern = re.compile(r"(\w+)\s*=\s*('([^']*)'|\"([^\"]*)\"|\[.*?\]|[\w.-]+|True|False|None)")
            matches = pattern.findall(content)
            cfg_dict = {}
            for key, val_group, str_val1, str_val2 in matches:
                val_str = val_group
                if (val_str.startswith("'") and val_str.endswith("'")) or (val_str.startswith('"') and val_str.endswith('"')): cfg_dict[key] = val_str[1:-1]
                elif val_str == 'True': cfg_dict[key] = True
                elif val_str == 'False': cfg_dict[key] = False
                elif val_str == 'None': cfg_dict[key] = None
                elif val_str.startswith('[') and val_str.endswith(']'):
                    try: cfg_dict[key] = eval(val_str)
                    except: cfg_dict[key] = val_str
                else:
                    try:
                        if '.' in val_str: cfg_dict[key] = float(val_str)
                        else: cfg_dict[key] = int(val_str)
                    except ValueError: cfg_dict[key] = val_str
            return cfg_dict
        except Exception as e: raise IOError(f"æ— æ³•å°† '{os.path.basename(cfg_path)}' è§£æä¸ºä»»ä½•å·²çŸ¥æ ¼å¼ã€‚é”™è¯¯: {e}")

# ==================== æ ¸å¿ƒæ¸²æŸ“å‡½æ•° (å¸¦è¯¦ç»†è°ƒè¯•) ====================
@torch.no_grad()
def render_and_save_debug(model_path: str, output_path: str, source_path: str, iteration: str):
    print("\n" + "="*80)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œç»ˆæè°ƒè¯•æ¸²æŸ“è„šæœ¬ (v3 - æ£€æŸ¥æ•°æ®çŠ¶æ€) ğŸš€")
    print("="*80 + "\n")

    # --- æ­¥éª¤ 1: ç¯å¢ƒå’Œè®¾å¤‡æ£€æŸ¥ (ä¸å˜) ---
    print("--- [æ­¥éª¤ 1/7] ç¯å¢ƒå’Œè®¾å¤‡æ£€æŸ¥ ---")
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"[INFO] CUDA å¯ç”¨ï¼å°†ä½¿ç”¨è®¾å¤‡: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
    print("-" * 40)
    
    # --- æ­¥éª¤ 2: åŠ è½½æ¨¡å‹é…ç½® (ä¸å˜) ---
    print("\n--- [æ­¥éª¤ 2/7] åŠ è½½æ¨¡å‹é…ç½®æ–‡ä»¶ (cfg_args) ---")
    # ... (ä»£ç ä¸ v2 å®Œå…¨ç›¸åŒ, æ­¤å¤„çœç•¥ä»¥ä¿æŒç®€æ´)
    cfg_path = os.path.join(model_path, "cfg_args")
    if not os.path.exists(cfg_path):
        print(f"âŒ [è‡´å‘½é”™è¯¯] é…ç½®æ–‡ä»¶ 'cfg_args' ä¸å­˜åœ¨ï¼"); return
    parser = ArgumentParser()
    model_params_def = ModelParams(parser)
    pipe_params_def = PipelineParams(parser)
    opt_params_def = OptimizationParams(parser)
    args_defaults = parser.parse_args([])
    saved_cfg_dict = load_config(cfg_path)
    for k, v in saved_cfg_dict.items():
        if hasattr(args_defaults, k): setattr(args_defaults, k, v)
    args_defaults.source_path = source_path
    args_defaults.model_path = model_path
    if not hasattr(args_defaults, 'sh_degree'): args_defaults.sh_degree = 3
    model_params = model_params_def.extract(args_defaults)
    pipe_params = pipe_params_def.extract(args_defaults)
    opt_params = opt_params_def.extract(args_defaults)
    if not hasattr(pipe_params, 'debug'): safe_state(False); pipe_params.debug = False
    print("[SUCCESS] æ¨¡å‹å‚æ•°å’Œæ¸²æŸ“ç®¡çº¿å‚æ•°å·²æˆåŠŸæ„å»ºã€‚")
    print("-" * 40)
    
    # --- æ­¥éª¤ 3: åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹ (ä¸å˜) ---
    print(f"\n--- [æ­¥éª¤ 3/7] åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹ (iteration: {iteration}) ---")
    chkpt_file = f"chkpnt{iteration}.pth"
    chkpt_path = os.path.join(model_path, chkpt_file)
    if not os.path.exists(chkpt_path):
        print(f"âŒ [è‡´å‘½é”™è¯¯] æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {chkpt_path}"); return
    gaussians = GaussianModel(model_params.sh_degree)
    checkpoint = torch.load(chkpt_path, map_location="cpu", weights_only=False)
    model_params_from_ckpt = checkpoint[0] if isinstance(checkpoint, tuple) else checkpoint
    gaussians.restore(model_params_from_ckpt, opt_params)
    print(f"[SUCCESS] æ¨¡å‹åŠ è½½æˆåŠŸï¼ŒåŒ…å« {gaussians.get_xyz.shape[0]} ä¸ªé«˜æ–¯ç‚¹ã€‚")
    print("-" * 40)

    # --- â€¼ï¸â€¼ï¸ æ–°å¢æ­¥éª¤ 4: æ£€æŸ¥å…³é”®å¼ é‡çš„æ•°å€¼çŠ¶æ€ â€¼ï¸â€¼ï¸ ---
    print("\n--- [æ–°å¢æ­¥éª¤ 4/7] æ£€æŸ¥åŠ è½½åå¼ é‡çš„æ•°å€¼çŠ¶æ€ (åœ¨CPUä¸Š) ---")
    scaling_tensor = gaussians._scaling
    opacity_tensor = gaussians._opacity
    
    print("[INFO] è¿™æ˜¯åœ¨ä»»ä½•æ¿€æ´»å‡½æ•°ï¼ˆå¦‚exp/sigmoidï¼‰åº”ç”¨ä¹‹å‰ï¼Œç›´æ¥ä» .pth æ–‡ä»¶æ¢å¤çš„å€¼ã€‚")
    
    print("\n--- æ£€æŸ¥ Scaling (_scaling) ---")
    print(f"   - ç±»å‹: {scaling_tensor.dtype}, è®¾å¤‡: {scaling_tensor.device}")
    print(f"   - å½¢çŠ¶: {scaling_tensor.shape}")
    print(f"   - æœ€å°å€¼ (Min): {scaling_tensor.min().item():.6f}")
    print(f"   - æœ€å¤§å€¼ (Max): {scaling_tensor.max().item():.6f}")
    print(f"   - å‡å€¼ (Mean): {scaling_tensor.mean().item():.6f}")
    print(f"   -> [è¯Šæ–­] æ­£å¸¸æƒ…å†µä¸‹ï¼Œè¿™äº›å€¼åº”è¯¥æ˜¯è¾ƒå°çš„è´Ÿæ•° (ä¾‹å¦‚ï¼Œå‡å€¼åœ¨ -3 åˆ° -6 ä¹‹é—´)ã€‚å¦‚æœå®ƒä»¬æ˜¯å¤§çš„æ­£æ•°æˆ–éå¸¸æ¥è¿‘0ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜ã€‚")

    print("\n--- æ£€æŸ¥ Opacity (_opacity) ---")
    print(f"   - ç±»å‹: {opacity_tensor.dtype}, è®¾å¤‡: {opacity_tensor.device}")
    print(f"   - å½¢çŠ¶: {opacity_tensor.shape}")
    print(f"   - æœ€å°å€¼ (Min): {opacity_tensor.min().item():.6f}")
    print(f"   - æœ€å¤§å€¼ (Max): {opacity_tensor.max().item():.6f}")
    print(f"   - å‡å€¼ (Mean): {opacity_tensor.mean().item():.6f}")
    print(f"   -> [è¯Šæ–­] æ­£å¸¸æƒ…å†µä¸‹ï¼Œè¿™äº›å€¼åº”è¯¥åœ¨ 0 é™„è¿‘ã€‚å¦‚æœå‡å€¼éå¸¸å¤§æˆ–éå¸¸å°ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜ã€‚")
    print("-" * 40)
    
    # --- æ­¥éª¤ 5: å°†æ¨¡å‹æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ°GPU (ä¸å˜) ---
    print(f"\n--- [æ­¥éª¤ 5/7] å°†æ¨¡å‹å¼ é‡æ‰‹åŠ¨ç§»åŠ¨åˆ°è®¾å¤‡: {device} ---")
    tensor_attr_names = ['_xyz', '_features_dc', '_features_rest', '_scaling', '_rotation', '_opacity',
                         'max_radii2D', 'xyz_gradient_accum', 'denom']
    for attr_name in tensor_attr_names:
        if hasattr(gaussians, attr_name):
            tensor = getattr(gaussians, attr_name)
            if isinstance(tensor, torch.Tensor):
                setattr(gaussians, attr_name, tensor.to(device))
    print("[SUCCESS] æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹å¼ é‡å·²æ£€æŸ¥å¹¶å°è¯•ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡ã€‚")
    print("-" * 40)

    # --- æ­¥éª¤ 6: åŠ è½½åœºæ™¯å’Œç›¸æœº (ä¸å˜) ---
    print("\n--- [æ­¥éª¤ 6/7] åŠ è½½åœºæ™¯å’Œç›¸æœº ---")
    print(f"[INFO] ä½¿ç”¨æ•°æ®æºè·¯å¾„: {model_params.source_path}")
    scene = Scene(model_params, gaussians, shuffle=False)
    train_cameras = scene.getTrainCameras()
    if not train_cameras:
        print(f"âŒ [è‡´å‘½é”™è¯¯] æœªèƒ½åŠ è½½ä»»ä½•è®­ç»ƒç›¸æœºï¼"); return
    print(f"[SUCCESS] æˆåŠŸåŠ è½½ {len(train_cameras)} ä¸ªè®­ç»ƒç›¸æœºã€‚")
    print("-" * 40)
    
    # --- æ­¥éª¤ 7: å¾ªç¯æ¸²æŸ“å¹¶ä¿å­˜ (ä¸å˜) ---
    print("\n--- [æ­¥éª¤ 7/7] å¼€å§‹æ¸²æŸ“å¾ªç¯ ---")
    os.makedirs(output_path, exist_ok=True)
    background = torch.tensor([1,1,1] if model_params.white_background else [0,0,0], dtype=torch.float32, device=device)
    
    for idx, camera in enumerate(tqdm(train_cameras, desc="æ¸²æŸ“è®­ç»ƒè§†è§’")):
        camera.to_device(device)
        render_pkg = render(camera, gaussians, pipe_params, background)
        # ... (åç»­ä¿å­˜é€»è¾‘ä¸å˜)
        rendered_image_tensor = render_pkg["render"].clamp(0.0, 1.0)
        rendered_np = (rendered_image_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype("uint8")
        pil_image = Image.fromarray(rendered_np)
        image_name = os.path.splitext(camera.image_name)[0]
        output_filename = os.path.join(output_path, f"{image_name}.png")
        pil_image.save(output_filename)

    print("\n" + "="*80)
    print(f"âœ… æ¸²æŸ“å®Œæˆï¼æ‰€æœ‰ {len(train_cameras)} å¼ å›¾åƒå·²ä¿å­˜è‡³ '{output_path}'ã€‚")
    print("="*80 + "\n")


# ==================== è„šæœ¬ä¸»å…¥å£ (ä¸å˜) ====================
if __name__ == "__main__":
    HARDCODED_MODEL_PATH    = "/root/autodl-tmp/gaussian-splatting/kicker_v2_new_start"
    HARDCODED_OUTPUT_PATH   = "/root/autodl-tmp/gaussian-splatting/kicker_v2_new_start/render_output_final_check_v3"
    HARDCODED_SOURCE_PATH   = "/root/autodl-tmp/gaussian-splatting/data/kicker"
    HARDCODED_ITERATION     = "15000"
    
    # (æˆ‘ç¨å¾®æ”¹äº†ä¸‹è¾“å‡ºè·¯å¾„ï¼Œé¿å…è¦†ç›–ä¹‹å‰çš„ç»“æœ)

    # ä¸ºCameraç±»åŠ¨æ€æ·»åŠ  to_device æ–¹æ³•
    def camera_to_device(self, device):
        for attr in ['world_view_transform', 'full_proj_transform', 'camera_center']:
            if hasattr(self, attr) and isinstance(getattr(self, attr), torch.Tensor):
                setattr(self, attr, getattr(self, attr).to(device))
    Camera.to_device = camera_to_device
    
    render_and_save_debug(
        model_path=HARDCODED_MODEL_PATH,
        output_path=HARDCODED_OUTPUT_PATH,
        source_path=HARDCODED_SOURCE_PATH,
        iteration=HARDCODED_ITERATION
    )