# render_final.py
# ä¸€ä¸ªå¥å£®ã€å¯é…ç½®ã€æ•´åˆäº†æ‰€æœ‰ä¿®å¤çš„3DGSç¦»çº¿æ¸²æŸ“è„šæœ¬

import os
import sys
import torch
import re
from argparse import ArgumentParser
from PIL import Image
from tqdm import tqdm
import math

# --- æ­¥éª¤ 1: ç¡®ä¿é¡¹ç›®è·¯å¾„åœ¨sys.pathä¸­å¹¶å¯¼å…¥æ ¸å¿ƒæ¨¡å— ---
try:
    project_root = os.path.dirname(os.path.abspath(__file__))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    # åŠ¨æ€å¯¼å…¥ä½ æä¾›çš„ã€å·²ç»éªŒè¯è¿‡çš„æ­£ç¡®ç±»
    from scene.gaussian_model import GaussianModel
    from scene.dataset_readers import sceneLoadTypeCallbacks
    from scene import Scene, Camera
    from arguments import ModelParams, PipelineParams, OptimizationParams
    from utils.general_utils import safe_state
    
    # åŠ¨æ€å¯¼å…¥å…‰æ …åŒ–å™¨
    from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer

    print("[SUCCESS] æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸã€‚")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}\nè¯·ç¡®ä¿æ­¤è„šæœ¬ä½äº 3D Gaussian Splatting é¡¹ç›®çš„æ ¹ç›®å½•ã€‚")
    sys.exit(1)

# ==================== é…ç½®åŠ è½½å‡½æ•° (å·²éªŒè¯) ====================
def load_config(cfg_path: str) -> dict:
    try:
        import pickle
        with open(cfg_path, 'rb') as f: return vars(pickle.load(f))
    except Exception:
        # Fallback to text parsing if pickle fails
        try:
            with open(cfg_path, 'r') as f: content = f.read().strip()
            if content.startswith("Namespace(") and content.endswith(")"): content = content[10:-1]
            pattern = re.compile(r"(\w+)\s*=\s*('([^']*)'|\"([^\"]*)\"|\[.*?\]|[\w.-]+|True|False|None)")
            matches = pattern.findall(content)
            cfg_dict = {}
            for key, val_group, str_val1, str_val2 in matches:
                val_str = val_group
                if (val_str.startswith("'") and val_str.endswith("'")) or (val_str.startswith('"') and val_str.endswith('"')): cfg_dict[key] = val_str[1:-1]
                elif val_str == 'True': cfg_dict[key] = True
                elif val_str == 'False': cfg_dict[key] = False
                elif val_str == 'None': cfg_dict[key] = None
                elif val_str.startswith('[') and val_str.endswith(']'):
                    try: cfg_dict[key] = eval(val_str)
                    except: cfg_dict[key] = val_str
                else:
                    try:
                        if '.' in val_str: cfg_dict[key] = float(val_str)
                        else: cfg_dict[key] = int(val_str)
                    except ValueError: cfg_dict[key] = val_str
            return cfg_dict
        except Exception as e: raise IOError(f"æ— æ³•è§£æ '{os.path.basename(cfg_path)}': {e}")

# ==================== æ ¸å¿ƒæ¸²æŸ“å‡½æ•° (å·²éªŒè¯) ====================
@torch.no_grad()
def render_model(args):
    """
    åŠ è½½å¹¶æ¸²æŸ“ä¸€ä¸ªè®­ç»ƒå¥½çš„3DGSæ¨¡å‹çš„æ‰€æœ‰è®­ç»ƒè§†è§’ã€‚
    """
    print("ğŸš€ å¼€å§‹æœ€ç»ˆæ¸²æŸ“æµç¨‹...")

    # 1. è®¾ç½®è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f" - ä½¿ç”¨è®¾å¤‡: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")

    # 2. åŠ è½½é…ç½®
    print(f" - åŠ è½½é…ç½®æ–‡ä»¶: {os.path.join(args.model_path, 'cfg_args')}")
    cfg_path = os.path.join(args.model_path, "cfg_args")
    if not os.path.exists(cfg_path):
        print(f"âŒ é”™è¯¯: åœ¨'{args.model_path}'ä¸­æ‰¾ä¸åˆ° 'cfg_args' é…ç½®æ–‡ä»¶ã€‚"); return
    
    parser = ArgumentParser()
    model_params_def = ModelParams(parser)
    pipe_params_def = PipelineParams(parser)
    opt_params_def = OptimizationParams(parser)
    
    args_defaults = parser.parse_args([])
    saved_cfg_dict = load_config(cfg_path)
    for k, v in saved_cfg_dict.items():
        if hasattr(args_defaults, k): setattr(args_defaults, k, v)

    # æ³¨å…¥å‘½ä»¤è¡Œå‚æ•°
    args_defaults.source_path = args.source_path
    args_defaults.model_path = args.model_path
    if not hasattr(args_defaults, 'sh_degree'): args_defaults.sh_degree = 3
        
    model_params = model_params_def.extract(args_defaults)
    pipe_params = pipe_params_def.extract(args_defaults)
    opt_params = opt_params_def.extract(args_defaults)
    if not hasattr(pipe_params, 'debug'): safe_state(False); pipe_params.debug = False

    # 3. åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
    chkpt_path = os.path.join(args.model_path, f"chkpnt{args.iteration}.pth")
    print(f" - æ­£åœ¨ä» '{os.path.basename(chkpt_path)}' åŠ è½½æ¨¡å‹...")
    
    gaussians = GaussianModel(model_params.sh_degree)
    checkpoint = torch.load(chkpt_path, map_location="cpu", weights_only=False)
    model_params_from_ckpt = checkpoint[0] if isinstance(checkpoint, tuple) else checkpoint
    gaussians.restore(model_params_from_ckpt, opt_params)
    print(f"   -> åŠ è½½æˆåŠŸ: {gaussians.get_xyz.shape[0]} ä¸ªé«˜æ–¯ç‚¹ã€‚")

    # 4. å…³é”®ä¿®å¤ï¼šå°†æ‰€æœ‰æ¨¡å‹å¼ é‡ç§»åŠ¨åˆ°GPU
    tensor_attrs = ['_xyz', '_features_dc', '_features_rest', '_scaling', '_rotation', '_opacity',
                    'max_radii2D', 'xyz_gradient_accum', 'denom']
    for attr in tensor_attrs:
        if hasattr(gaussians, attr):
            tensor = getattr(gaussians, attr)
            if isinstance(tensor, torch.Tensor):
                setattr(gaussians, attr, tensor.to(device))

    # 5. åŠ è½½åœºæ™¯å’Œç›¸æœº
    print(f" - æ­£åœ¨ä» '{model_params.source_path}' åŠ è½½åœºæ™¯...")
    scene = Scene(model_params, gaussians, shuffle=False)
    cameras = scene.getTrainCameras()
    print(f"   -> åŠ è½½æˆåŠŸ: {len(cameras)} ä¸ªè®­ç»ƒç›¸æœºã€‚")

    # 6. å‡†å¤‡å¹¶æ‰§è¡Œæ¸²æŸ“
    os.makedirs(args.output_path, exist_ok=True)
    background = torch.tensor([1,1,1] if model_params.white_background else [0,0,0], dtype=torch.float32, device=device)

    print(f" - å¼€å§‹æ¸²æŸ“ {len(cameras)} ä¸ªè§†è§’ï¼Œç»“æœä¿å­˜è‡³ '{args.output_path}'...")
    for camera in tqdm(cameras, desc="æ¸²æŸ“ä¸­"):
        # å…³é”®ä¿®å¤ï¼šç¡®ä¿ç›¸æœºå†…éƒ¨å¼ é‡ä¹Ÿåœ¨GPUä¸Š
        camera.to_device(device)
        
        # --- å†…è”æ¸²æŸ“é€»è¾‘ï¼Œç¡®ä¿æ­£ç¡®æ€§ ---
        tanfovx = math.tan(camera.FoVx * 0.5)
        tanfovy = math.tan(camera.FoVy * 0.5)

        raster_settings = GaussianRasterizationSettings(
            image_height=int(camera.image_height),
            image_width=int(camera.image_width),
            tanfovx=tanfovx,
            tanfovy=tanfovy,
            bg=background,
            scale_modifier=1.0,
            viewmatrix=camera.world_view_transform,
            projmatrix=camera.full_proj_transform,
            sh_degree=gaussians.active_sh_degree,
            campos=camera.camera_center,
            prefiltered=False,
            debug=pipe_params.debug
        )
        rasterizer = GaussianRasterizer(raster_settings=raster_settings)

        # æ ¸å¿ƒæ­¥éª¤ï¼šä»æ¨¡å‹ä¸­è·å–ç»è¿‡æ¿€æ´»å‡½æ•°å¤„ç†çš„æ­£ç¡®å±æ€§
        means3D = gaussians.get_xyz
        opacities = gaussians.get_opacity
        scales = gaussians.get_scaling
        rotations = gaussians.get_rotation
        shs = gaussians.get_features

        # å…‰æ …åŒ–
        rendered_image, _ = rasterizer(
            means3D = means3D,
            means2D = torch.zeros_like(means3D, requires_grad=True, device=device) + 0,
            shs = shs,
            colors_precomp = None,
            opacities = opacities,
            scales = scales,
            rotations = rotations,
            cov3D_precomp = None
        )
        
        # ä¿å­˜å›¾åƒ
        img_tensor = rendered_image.clamp(0.0, 1.0)
        img_np = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype("uint8")
        pil_img = Image.fromarray(img_np)
        pil_img.save(os.path.join(args.output_path, f"{os.path.splitext(camera.image_name)[0]}.png"))

    print("\nâœ… æ¸²æŸ“å…¨éƒ¨å®Œæˆï¼")

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    parser = ArgumentParser(description="åŠ è½½ä¸€ä¸ª3DGSæ¨¡å‹å¹¶æ¸²æŸ“å…¶æ‰€æœ‰è®­ç»ƒè§†è§’ã€‚")
    parser.add_argument("model_path", type=str, help="æŒ‡å‘æ¨¡å‹å®éªŒç›®å½•çš„è·¯å¾„ (åŒ…å« cfg_args å’Œ chkpnt*.pth æ–‡ä»¶)ã€‚")
    parser.add_argument("output_path", type=str, help="ä¿å­˜æ¸²æŸ“å›¾åƒçš„è¾“å‡ºæ–‡ä»¶å¤¹ã€‚")
    parser.add_argument("-s", "--source_path", type=str, required=True, help="ã€å¿…éœ€ã€‘æŒ‡å‘åŸå§‹åœºæ™¯æ•°æ®æºçš„è·¯å¾„ (å¦‚ COLMAP ç›®å½•)ã€‚")
    parser.add_argument("--iteration", type=str, default="15000", help="è¦åŠ è½½çš„æ¨¡å‹è¿­ä»£æ¬¡æ•° (å¦‚ '15000')ã€‚")
    args = parser.parse_args()

    # å…³é”®ä¿®å¤ï¼šä¸ºCameraç±»åŠ¨æ€æ·»åŠ  to_device æ–¹æ³•
    def camera_to_device(self, device):
        for attr in ['world_view_transform', 'full_proj_transform', 'camera_center']:
            if hasattr(self, attr) and isinstance(getattr(self, attr), torch.Tensor):
                setattr(self, attr, getattr(self, attr).to(device))
    Camera.to_device = camera_to_device
    
    # æ¸…ç†Pythonç¼“å­˜ï¼Œä»¥é˜²ä¸‡ä¸€
    os.system('find . -name "*.pyc" -delete')
    print(" - å·²æ¸…ç†é¡¹ç›®ä¸­çš„ __pycache__ æ–‡ä»¶ã€‚")
    
    render_model(args)