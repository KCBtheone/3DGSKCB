import os
import sys
import json
import cv2
import numpy as np
import torch
from PIL import Image
from argparse import ArgumentParser, Namespace
# ç¡®ä¿å¯ä»¥æ­£ç¡®å¯¼å…¥æˆ‘ä»¬é¡¹ç›®ä¸­çš„æ¨¡å—
from arguments import ModelParams, PipelineParams, OptimizationParams
from scene import Scene, GaussianModel
from gaussian_renderer import render
from tqdm import tqdm
from scipy.spatial.distance import cdist
from skimage.metrics import structural_similarity as ssim_sk
from skimage.metrics import peak_signal_noise_ratio as psnr_sk
import warnings
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import lpips

# --- å…¨å±€è®¾ç½® ---
# æŠ‘åˆ¶ä¸€äº›ä¸å½±å“ç»“æœçš„è­¦å‘Šï¼Œä½¿è¾“å‡ºæ›´å¹²å‡€
warnings.filterwarnings("ignore", category=UserWarning, message="Inputs have mismatched dtype")
warnings.simplefilter(action='ignore', category=FutureWarning)
# å®šä¹‰æœ€ç»ˆè¯„ä¼°ä½¿ç”¨çš„è¿­ä»£æ¬¡æ•°
FINAL_ITERATION = 30000

# ==============================================================================
#                      1. æŒ‡æ ‡è®¡ç®—æ ¸å¿ƒå‡½æ•° (ä¿æŒä¸å˜)
# ==============================================================================

def get_canny_edges(image_np):
    """ä»RGBå›¾åƒè®¡ç®—Cannyè¾¹ç¼˜å›¾ã€‚"""
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    return cv2.Canny(gray, 50, 150)

def calculate_edge_fscore(pred_edges, gt_edges, threshold=3):
    """è®¡ç®—è¾¹ç¼˜æ£€æµ‹çš„F1åˆ†æ•°ã€ç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚"""
    if pred_edges.sum() == 0 or gt_edges.sum() == 0: return 0.0, 0.0, 0.0
    dist_transform = cv2.distanceTransform(255 - gt_edges, cv2.DIST_L2, 5)
    pred_on_gt = dist_transform[pred_edges != 0]
    dist_transform_inv = cv2.distanceTransform(255 - pred_edges, cv2.DIST_L2, 5)
    gt_on_pred = dist_transform_inv[gt_edges != 0]
    precision = np.sum(pred_on_gt < threshold) / (len(pred_on_gt) + 1e-6)
    recall = np.sum(gt_on_pred < threshold) / (len(gt_on_pred) + 1e-6)
    if precision + recall == 0: return 0.0, 0.0, 0.0
    f1 = 2 * (precision * recall) / (precision + recall)
    return precision, recall, f1

def calculate_chamfer_distance(pred_edges, gt_edges):
    """è®¡ç®—ä¸¤ä¸ªè¾¹ç¼˜å›¾ä¹‹é—´çš„å€’è§’è·ç¦»ã€‚"""
    gt_points = np.array(np.where(gt_edges != 0)).T
    pred_points = np.array(np.where(pred_edges != 0)).T
    if len(gt_points) == 0 or len(pred_points) == 0: return np.inf
    dist1 = cdist(pred_points, gt_points).min(axis=1).mean()
    dist2 = cdist(gt_points, pred_points).min(axis=1).mean()
    return (dist1 + dist2) / 2

def calculate_geometric_score(avg_metrics):
    """æ ¹æ®F1åˆ†æ•°å’Œå€’è§’è·ç¦»è®¡ç®—ç»¼åˆå‡ ä½•åˆ†æ•° G-Scoreã€‚"""
    EDGE_F1_WEIGHT = 0.6
    CHAMFER_WEIGHT = 0.4
    CHAMFER_DECAY_FACTOR_K = 0.14
    edge_f1 = avg_metrics.get('edge_f1', 0.0)
    chamfer_dist = avg_metrics.get('chamfer_dist', np.inf)
    f1_score_component = edge_f1
    chamfer_score_component = 0.0 if np.isinf(chamfer_dist) else np.exp(-CHAMFER_DECAY_FACTOR_K * chamfer_dist)
    g_score = (EDGE_F1_WEIGHT * f1_score_component + CHAMFER_WEIGHT * chamfer_score_component) * 100
    return g_score

# ==============================================================================
#                      2. è¯„ä¼°ä¸»æµç¨‹ (å·²ä¿®æ­£å’Œå¢å¼º)
# ==============================================================================

@torch.no_grad()
def evaluate_single_experiment(model_path, lpips_model):
    """å¯¹å•ä¸ªå®éªŒçš„æ¨¡å‹è¿›è¡Œå®Œæ•´çš„è¯„ä¼°ã€‚"""
    print(f"\nğŸš€ å¼€å§‹è¯„ä¼°å®éªŒ: {os.path.basename(model_path)}")
    
    # --- æ­¥éª¤ 1: åŠ è½½è®­ç»ƒæ—¶çš„é…ç½®æ–‡ä»¶ (cfg_args) ---
    args_path = os.path.join(model_path, "cfg_args")
    if not os.path.exists(args_path):
        print(f"  -> âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ cfg_argsï¼Œè·³è¿‡è¯„ä¼°ã€‚")
        return None, None

    # åˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„å‚æ•°è§£æå™¨
    parser = ArgumentParser(description="Evaluation script parser")
    model_params_def = ModelParams(parser)
    opt_params_def = OptimizationParams(parser)
    pipe_params_def = PipelineParams(parser)

    # è¯»å–é…ç½®æ–‡ä»¶å†…å®¹å¹¶è§£æ
    with open(args_path, 'r') as f:
        config_namespace = eval(f.read())
    
    # ### FIX ###: ä»åŠ è½½çš„é…ç½®ä¸­æå–å‚æ•°ï¼Œå¡«å……åˆ°æˆ‘ä»¬çš„å‚æ•°å¯¹è±¡ä¸­
    args = model_params_def.extract(config_namespace)
    opt = opt_params_def.extract(config_namespace)
    pipe = pipe_params_def.extract(config_namespace)
    
    # --- æ­¥éª¤ 2: åŠ è½½é«˜æ–¯æ¨¡å‹å’Œåœºæ™¯ ---
    gaussians = GaussianModel(args.sh_degree)
    
    ply_path = os.path.join(model_path, "point_cloud", f"iteration_{FINAL_ITERATION}", "point_cloud.ply")
    if not os.path.exists(ply_path):
        print(f"  -> âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ç¬¬ {FINAL_ITERATION} æ¬¡è¿­ä»£çš„ç‚¹äº‘æ–‡ä»¶ï¼Œè·³è¿‡è¯„ä¼°ã€‚")
        return None, None
        
    print(f"  -> ğŸ“‚ æ­£åœ¨åŠ è½½ç‚¹äº‘: iteration_{FINAL_ITERATION}")
    
    # ### FIX ###: ä½¿ç”¨æ­£ç¡®çš„ç­¾åè°ƒç”¨Sceneçš„æ„é€ å‡½æ•°ï¼Œä¼ å…¥ opt
    scene = Scene(args, opt, gaussians, load_iteration=FINAL_ITERATION, shuffle=False)
    
    bg_color = [1, 1, 1] if args.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")
    
    eval_cameras = scene.getTestCameras()
    if not eval_cameras:
        print("  -> â„¹ï¸ æœªæ‰¾åˆ°ç‹¬ç«‹çš„æµ‹è¯•é›†ï¼Œå°†ä½¿ç”¨è®­ç»ƒé›†è¿›è¡Œè¯„ä¼°ã€‚")
        eval_cameras = scene.getTrainCameras()

    if not eval_cameras:
        print("  -> âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨äºè¯„ä¼°çš„ç›¸æœºã€‚")
        return None, None
    print(f"  -> ğŸ“· æ‰¾åˆ° {len(eval_cameras)} ä¸ªè¯„ä¼°è§†å›¾ã€‚")

    # --- æ­¥éª¤ 3: é€ä¸ªè§†å›¾è¿›è¡Œæ¸²æŸ“å’Œè¯„ä¼° ---
    metrics = {"psnr": [], "ssim": [], "lpips": [], "edge_f1": [], "chamfer_dist": []}
    
    for camera in tqdm(eval_cameras, desc=f"  -> è¯„ä¼°ä¸­"):
        render_pkg = render(camera, gaussians, pipe, background)
        rendered_image_torch = render_pkg["render"].clamp(0.0, 1.0)
        gt_image_torch = camera.original_image.cuda().clamp(0.0, 1.0)

        # è½¬æ¢ä¸ºNumpyæ•°ç»„ (0-255) ä»¥ä¾¿Skimageè®¡ç®—
        rendered_np = (rendered_image_torch.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        gt_np = (gt_image_torch.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)

        metrics["psnr"].append(psnr_sk(gt_np, rendered_np, data_range=255))
        metrics["ssim"].append(ssim_sk(gt_np, rendered_np, channel_axis=2, data_range=255))
        
        # LPIPSéœ€è¦ [-1, 1] èŒƒå›´çš„å¼ é‡
        rendered_lpips = rendered_image_torch * 2 - 1
        gt_lpips = gt_image_torch * 2 - 1
        metrics["lpips"].append(lpips_model(rendered_lpips, gt_lpips).item())

        # å‡ ä½•æŒ‡æ ‡è®¡ç®—
        pred_edges = get_canny_edges(rendered_np)
        gt_edges = get_canny_edges(gt_np)
        _, _, f1 = calculate_edge_fscore(pred_edges, gt_edges)
        metrics["edge_f1"].append(f1)
        metrics["chamfer_dist"].append(calculate_chamfer_distance(pred_edges, gt_edges))

    # --- æ­¥éª¤ 4: è®¡ç®—å¹³å‡æŒ‡æ ‡å¹¶è¿”å› ---
    avg_metrics = {key: np.mean(val) for key, val in metrics.items() if val}
    g_score = calculate_geometric_score(avg_metrics)
    avg_metrics['g_score'] = g_score
    
    print(f"  -> âœ… è¯„ä¼°å®Œæˆ: PSNR={avg_metrics['psnr']:.2f}, G-Score={avg_metrics['g_score']:.2f}")
    return avg_metrics, opt # è¿”å›è¯„ä¼°ç»“æœå’Œè¯¥å®éªŒçš„ä¼˜åŒ–å‚æ•°

# ==============================================================================
#                      3. åˆ†æä¸æŠ¥å‘Šç”Ÿæˆä¸»æµç¨‹
# ==============================================================================

def generate_report(experiments_root_dir):
    
    print("="*80 + "\n              ğŸš€ ç»Ÿä¸€å®éªŒåˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ ğŸš€\n" + "="*80)
    
    # æŠ¥å‘Šå°†ä¿å­˜åœ¨å®éªŒç›®å½•çš„ä¸Šä¸€å±‚ï¼Œåä¸º FULL_ANALYSIS_REPORT
    report_output_dir = os.path.join(os.path.dirname(os.path.abspath(experiments_root_dir.rstrip('/'))), "FULL_ANALYSIS_REPORT")
    os.makedirs(report_output_dir, exist_ok=True)
    report_file_path = os.path.join(report_output_dir, "analysis_report.md")

    lpips_model = lpips.LPIPS(net='vgg').cuda()
    all_exp_results = []

    if not os.path.isdir(experiments_root_dir):
        print(f"âŒ é”™è¯¯: å®éªŒæ ¹ç›®å½• '{experiments_root_dir}' ä¸å­˜åœ¨ã€‚")
        return
        
    experiment_folders = sorted([f for f in os.listdir(experiments_root_dir) if os.path.isdir(os.path.join(experiments_root_dir, f))])

    for folder_name in experiment_folders:
        model_path = os.path.join(experiments_root_dir, folder_name)
        
        eval_metrics, opt_params = evaluate_single_experiment(model_path, lpips_model)
        
        # å¦‚æœè¯„ä¼°å¤±è´¥ï¼Œåˆ™è·³è¿‡
        if not eval_metrics:
            continue
            
        # ### NEW ###: æå–çº¦æŸç±»å‹å’Œå…³é”®å‚æ•°ç”¨äºæŠ¥å‘Š
        constraint_info = {
            'Constraint_Type': opt_params.geometry_constraint_type,
            'Params': 'N/A'
        }
        if opt_params.geometry_constraint_type == 'line':
            constraint_info['Params'] = f"Î±={opt_params.line_static_alpha}, Ïƒ={opt_params.line_static_sigma}, Î»_dyn={opt_params.line_dynamic_lambda}"
        elif opt_params.geometry_constraint_type == 'udf':
            constraint_info['Params'] = f"Î»_dyn={opt_params.udf_dynamic_lambda}, r={opt_params.udf_blur_radius}"

        # å°†æ‰€æœ‰ç»“æœåˆå¹¶åˆ°ä¸€è¡Œ
        result_row = {
            'Experiment': folder_name,
            **constraint_info,
            **eval_metrics
        }
        all_exp_results.append(result_row)

    if not all_exp_results:
        print("\nâŒ æœªèƒ½æˆåŠŸå¤„ç†ä»»ä½•å®éªŒã€‚æŠ¥å‘Šç”Ÿæˆä¸­æ­¢ã€‚")
        return

    print("\nğŸ“ æ­£åœ¨ç”Ÿæˆ Markdown æŠ¥å‘Š...")
    results_df = pd.DataFrame(all_exp_results)
    
    with open(report_file_path, 'w', encoding='utf-8') as f:
        f.write("# 3DGS å‡ ä½•çº¦æŸå®éªŒ - ç»Ÿä¸€åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"æŠ¥å‘Šç”Ÿæˆäº: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("### ğŸ† **è¯„ä¼°æŒ‡æ ‡æ€»è§ˆ (è¶Šé«˜è¶Šå¥½ï¼ŒLPIPSå’ŒChamferé™¤å¤–)**\n\n")
        f.write("> **G-Score**: ç»¼åˆå‡ ä½•åˆ†æ•° (è¶Šé«˜è¶Šå¥½)ã€‚\n")
        f.write("> **LPIPS**: æ„ŸçŸ¥ç›¸ä¼¼åº¦ (è¶Šä½è¶Šå¥½)ã€‚\n")
        f.write("> **Chamfer**: å€’è§’è·ç¦» (è¶Šä½è¶Šå¥½)ã€‚\n\n")
        
        # å®šä¹‰æŠ¥å‘Šä¸­å±•ç¤ºçš„åˆ—
        report_cols = [
            'Experiment', 'Constraint_Type', 'Params', 
            'g_score', 'psnr', 'ssim', 'lpips', 'edge_f1', 'chamfer_dist'
        ]
        report_df = results_df[report_cols].copy().set_index('Experiment').sort_values(by='g_score', ascending=False)
        f.write(report_df.to_markdown(floatfmt=".4f"))
        f.write("\n\n")

    print(f"  -> âœ… Markdown æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file_path}")

    # (å›¾è¡¨ç”Ÿæˆéƒ¨åˆ†å¯ä»¥ä¿æŒä¸å˜ï¼Œä½†è¿™é‡Œä¹Ÿä¼˜åŒ–ä¸€ä¸‹)
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆè®­ç»ƒè¿‡ç¨‹å¯¹æ¯”å›¾è¡¨...")
    # ... (æ­¤éƒ¨åˆ†é€»è¾‘æ­£ç¡®ï¼Œæ— éœ€ä¿®æ”¹)

    print("\n" + "="*80 + "\n              ğŸ‰ å…¨éƒ¨åˆ†æå®Œæˆï¼ ğŸ‰\n" + "="*80)

if __name__ == "__main__":
    parser = ArgumentParser(description="ç»Ÿä¸€æŠ¥å‘Šç”Ÿæˆå™¨ï¼šè‡ªåŠ¨è¯„ä¼°ã€åˆ†æå¹¶å¯è§†åŒ–æ‰€æœ‰3DGSå®éªŒç»“æœã€‚")
    parser.add_argument("experiments_root_dir", type=str, help="åŒ…å«æ‰€æœ‰å®éªŒç»“æœæ–‡ä»¶å¤¹çš„æ ¹ç›®å½• (ä¾‹å¦‚, 'BICYCLE_LINE_EXPERIMENTS')ã€‚")
    args = parser.parse_args()
    generate_report(args.experiments_root_dir)