#
# Copyright (C) 2023, Inria
# GRAPHDECO research group, https://team.inria.fr/graphdeco
# All rights reserved.
#
# This software is free for non-commercial, research and evaluation use
# under the terms of the LICENSE.md file.
#
# For inquiries contactÂ  george.drettakis@inria.fr
#

import os
import torch
from random import randint
from utils.loss_utils import l1_loss, ssim, ssim_weighted
from gaussian_renderer import render
import sys
from scene import Scene, GaussianModel
from utils.general_utils import safe_state
import uuid
from tqdm import tqdm
from utils.image_utils import psnr
from argparse import ArgumentParser, Namespace
from arguments import ModelParams, PipelineParams, OptimizationParams, get_combined_args
import logging
import time
import csv
import torch.nn.functional as F
import torchvision

try:
Â  Â  from torch.utils.tensorboard import SummaryWriter
Â  Â  TENSORBOARD_FOUND = True
except ImportError:
Â  Â  TENSORBOARD_FOUND = False

# =================================================================================
# >>> [ æ—¥å¿—ç³»ç»Ÿ ] <<<
# =================================================================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
LOG_FILE_HANDLE = None
CSV_WRITER = None

def setup_csv_logger(model_path):
Â  Â  global LOG_FILE_HANDLE, CSV_WRITER
Â  Â  log_file = os.path.join(model_path, "training_log.csv")
Â  Â  fieldnames = [
Â  Â  Â  Â  'Iteration', 'Total_Loss', 'L1_Loss', 'SSIM_Loss',
Â  Â  Â  Â  'Train_PSNR', 'Test_PSNR', 'Total_Points', 'Total_Iter_Time_s',
Â  Â  Â  Â  'Normal_Error_Mean', 'Curvature_Error_Mean', 'Adaptive_Gamma'
Â  Â  ]
Â  Â  try:
Â  Â  Â  Â  LOG_FILE_HANDLE = open(log_file, 'w', newline='')
Â  Â  Â  Â  CSV_WRITER = csv.DictWriter(LOG_FILE_HANDLE, fieldnames=fieldnames)
Â  Â  Â  Â  CSV_WRITER.writeheader()
Â  Â  Â  Â  logging.info(f"CSV training log will be saved to: {log_file}")
Â  Â  except IOError as e:
Â  Â  Â  Â  logging.error(f"Failed to create CSV log file {log_file}. Reason: {e}")

def log_to_csv(data_dict):
Â  Â  global CSV_WRITER, LOG_FILE_HANDLE
Â  Â  if CSV_WRITER:
Â  Â  Â  Â  default_data = {key: "N/A" for key in CSV_WRITER.fieldnames}
Â  Â  Â  Â  default_data.update(data_dict)
Â  Â  Â  Â  CSV_WRITER.writerow(default_data)
Â  Â  Â  Â  if data_dict.get('Iteration', 0) % 100 == 0 and LOG_FILE_HANDLE:
Â  Â  Â  Â  Â  Â  LOG_FILE_HANDLE.flush()

def close_csv_logger():
Â  Â  global LOG_FILE_HANDLE
Â  Â  if LOG_FILE_HANDLE:
Â  Â  Â  Â  LOG_FILE_HANDLE.close()
Â  Â  Â  Â  logging.info("CSV training log file closed.")

def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, start_checkpoint, debug_from):
Â  Â  first_iter = 0
Â  Â  tb_writer = prepare_output_and_logger(dataset)
Â  Â  gaussians = GaussianModel(dataset.sh_degree)
Â  Â  scene = Scene(dataset, gaussians)
Â  Â  gaussians.training_setup(opt)
Â  Â Â 
Â  Â  if start_checkpoint:
Â  Â  Â  Â  (model_params, first_iter) = torch.load(start_checkpoint)
Â  Â  Â  Â  gaussians.restore(model_params, opt)
Â  Â  Â  Â  print(f"Resuming training from iteration {first_iter}")

Â  Â  # --- åˆå§‹åŒ–æ ¸å¿ƒå˜é‡ ---
Â  Â  bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
Â  Â  background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")
Â  Â Â 
Â  Â  # [æ–°å¢] è¿½è¸ªæœ€ä½³æµ‹è¯•PSNRå’ŒEMAæ—¥å¿—å˜é‡
Â  Â  best_test_psnr = 0.0
Â  Â  last_test_psnr = 0.0
Â  Â  gamma_ema = torch.tensor(0.0, device="cuda")

Â  Â  # [æ–°å¢] ç²¾ç¡®è®¡æ—¶å™¨
Â  Â  time_accumulators = {k: 0.0 for k in ["data_loading", "render", "loss_calc", "backward", "optimizer_densify", "total_iteration"]}
Â  Â  last_report_iter = first_iter

Â  Â  setup_csv_logger(dataset.model_path)
Â  Â  progress_bar = tqdm(range(first_iter + 1, opt.iterations + 1), desc="Training progress")

Â  Â  for iteration in progress_bar:
Â  Â  Â  Â Â 
Â  Â  Â  Â  torch.cuda.synchronize(); iter_total_start_time = time.time()

Â  Â  Â  Â  gaussians.update_learning_rate(iteration)
Â  Â  Â  Â  if iteration % 1000 == 0:
Â  Â  Â  Â  Â  Â  gaussians.oneupSHdegree()

Â  Â  Â  Â  # --- æ•°æ®åŠ è½½ ---
Â  Â  Â  Â  torch.cuda.synchronize(); time_start = time.time()
Â  Â  Â  Â  viewpoint_cam = scene.getTrainCameras()[randint(0, len(scene.getTrainCameras()) - 1)]
Â  Â  Â  Â  gt_image = viewpoint_cam.original_image.cuda()
Â  Â  Â  Â  gt_normals = viewpoint_cam.gt_normal_map
Â  Â  Â  Â  gt_curvature = viewpoint_cam.gt_curvature_map
Â  Â  Â  Â  bg = torch.rand(3, device="cuda") if opt.random_background else background
Â  Â  Â  Â  torch.cuda.synchronize(); time_accumulators["data_loading"] += time.time() - time.time()

Â  Â  Â  Â  # --- æ¸²æŸ“ ---
Â  Â  Â  Â  torch.cuda.synchronize(); time_start = time.time()
Â  Â  Â  Â  render_pkg = render(viewpoint_cam, gaussians, pipe, bg)
Â  Â  Â  Â  image, viewspace_point_tensor, visibility_filter, radii = render_pkg["render"], render_pkg["viewspace_points"], render_pkg["visibility_filter"], render_pkg["radii"]
Â  Â  Â  Â  torch.cuda.synchronize(); time_accumulators["render"] += time.time() - time.time()

Â  Â  Â  Â  # --- æŸå¤±è®¡ç®— ---
Â  Â  Â  Â  torch.cuda.synchronize(); time_start = time.time()
Â  Â  Â  Â  mean_normal_error = torch.tensor(0.0, device="cuda")
Â  Â  Â  Â  mean_curvature_error = torch.tensor(0.0, device="cuda")

Â  Â  Â  Â  # A. L1æŸå¤±çš„åŠ¨æ€æƒé‡è®¡ç®—
Â  Â  Â  Â  gt_confidence = viewpoint_cam.gt_confidence_map
Â  Â  Â  Â Â 
Â  Â  Â  Â  # [ ğŸš€ å®éªŒæ€§ä¿®æ”¹: æ–¹æ¡ˆäºŒ (train_2.py) ğŸš€ ]
Â  Â  Â  Â  # åŸå§‹é€»è¾‘ (train.py):
Â  Â  Â  Â  # final_l1_weight_map = torch.ones_like(image[:1]) if gt_confidence is None else torch.pow(gt_confidence.unsqueeze(0), opt.confidence_gamma)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # æ–°é€»è¾‘ (æ–¹æ¡ˆäºŒ): åè½¬ç½®ä¿¡åº¦ï¼Œ"å…³æ³¨"ä½ç½®ä¿¡åº¦åŒºåŸŸ
Â  Â  Â  Â  if gt_confidence is None:
Â  Â  Â  Â  Â  Â  final_l1_weight_map = torch.ones_like(image[:1])
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # ç¡¬ç¼–ç æ–°å‚æ•°
Â  Â  Â  Â  Â  Â  alpha_fix = 1.0 
Â  Â  Â  Â  Â  Â  gamma_fix = 1.0 # (gamma_fix=1.0 æ„å‘³ç€ pow æ“ä½œæ˜¯å¯é€‰çš„, ä½†ä¿ç•™ç»“æ„)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # W_C(p) = 1 + alpha_fix * (1 - M_conf(p))^gamma_fix
Â  Â  Â  Â  Â  Â  inv_conf = 1.0 - gt_confidence.unsqueeze(0)
Â  Â  Â  Â  Â  Â  final_l1_weight_map = 1.0 + alpha_fix * torch.pow(inv_conf, gamma_fix)
Â  Â  Â  Â  Â  Â  # [æ³¨æ„] åŸæœ‰çš„ opt.confidence_gamma (gamma_conf) åœ¨æ­¤æ–¹æ¡ˆä¸­è¢«å¼ƒç”¨
Â  Â  Â  Â  # [ ğŸš€ å®éªŒæ€§ä¿®æ”¹ç»“æŸ ğŸš€ ]

Â  Â  Â  Â  use_normal_guidance = (iteration >= opt.geometry_start_iter and gt_normals is not None)
Â  Â  Â  Â  rendered_normals = None
Â  Â  Â  Â  if use_normal_guidance:
Â  Â  Â  Â  Â  Â  normals_for_render = (gaussians.get_normals + 1.0) / 2.0
Â  Â  Â  Â  Â  Â  normal_render_pkg = render(viewpoint_cam, gaussians, pipe, bg, override_color=normals_for_render)
Â  Â  Â  Â  Â  Â  rendered_normals = normal_render_pkg["render"]
Â  Â  Â  Â  Â  Â  gt_normals_cuda = gt_normals.cuda()
Â  Â  Â  Â  Â  Â  mask = (gt_normals_cuda.sum(dim=0) != 0)
Â  Â  Â  Â  Â  Â  if mask.sum() > 0:
Â  Â  Â  Â  Â  Â  Â  Â  error_map = 1.0 - torch.sum(rendered_normals * gt_normals_cuda, dim=0)
Â  Â  Â  Â  Â  Â  Â  Â  mean_normal_error = error_map[mask].mean()
Â  Â  Â  Â  Â  Â  Â  Â  if opt.alpha_normals > 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_l1_weight_map *= (1.0 + opt.alpha_normals * error_map).unsqueeze(0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if opt.lambda_isotropy > 0 and iteration >= opt.isotropy_start_iter:
Â  Â  Â  Â  Â  Â  isotropy_indices = gaussians.get_isotropy.detach().expand(-1, 3)
Â  Â  Â  Â  Â  Â  isotropy_map = render(viewpoint_cam, gaussians, pipe, torch.zeros_like(bg), override_color=isotropy_indices)["render"][:1]
Â  Â  Â  Â  Â  Â  final_l1_weight_map *= (1.0 + opt.lambda_isotropy * isotropy_map)

Â  Â  Â  Â  l1_loss_val = (final_l1_weight_map * torch.abs(image - gt_image)).mean()

Â  Â  Â  Â  # B. SSIMæŸå¤±è®¡ç®— (åŸå§‹ vs. ç»“æ„æ„ŸçŸ¥)
Â  Â  Â  Â  if not opt.use_sa_ssim or not use_normal_guidance or gt_curvature is None or rendered_normals is None:
Â  Â  Â  Â  Â  Â  ssim_loss_val = 1.0 - ssim(image, gt_image)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  Â  Â  gt_curvature_cuda = gt_curvature.cuda()
Â  Â  Â  Â  Â  Â  Â  Â  sobel_kernel = torch.tensor([[[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]], dtype=torch.float32, device="cuda").reshape(1,1,3,3).repeat(3,1,1,1)
Â  Â  Â  Â  Â  Â  Â  Â  rendered_curvature = F.conv2d(rendered_normals.unsqueeze(0), sobel_kernel, padding=1, groups=3).squeeze(0).pow(2).sum(dim=0).sqrt()
EOM
Â  Â  Â  Â  Â  Â  Â  Â  curvature_error_map = torch.abs(rendered_curvature - gt_curvature_cuda[0])
Â  Â  Â  Â  Â  Â  Â  Â  mean_curvature_error = curvature_error_map[mask].mean()
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  M_geo = (1 - opt.beta_geo) * error_map + opt.beta_geo * curvature_error_map
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  current_gamma = opt.gamma_base
Â  Â  Â  Â  Â  Â  Â  Â  if opt.adaptive_gamma:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if iteration < opt.gamma_warmup:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_gamma *= (iteration / opt.gamma_warmup)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  valid_geo_errors = M_geo[mask]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if valid_geo_errors.numel() > 1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_gamma *= torch.clamp(torch.std(valid_geo_errors), 0.0, 2.0)
Â  Â  Â  Â  Â  Â  Â  Â  gamma_ema = 0.99 * gamma_ema + 0.01 * current_gamma
Â  Â  Â  Â  Â  Â  Â  Â  W_geo = 1.0 + gamma_ema * M_geo.unsqueeze(0)
Â  Â  Â  Â  Â  Â  ssim_loss_val = 1.0 - ssim_weighted(image, gt_image, W_geo)

Â  Â  Â  Â  total_loss = (1.0 - opt.lambda_dssim) * l1_loss_val + opt.lambda_dssim * ssim_loss_val
Â  Â  Â  Â  torch.cuda.synchronize(); time_accumulators["loss_calc"] += time.time() - time.time()

Â  Â  Â  Â  # --- åå‘ä¼ æ’­ ---
Â  Â  Â  Â  torch.cuda.synchronize(); time_start = time.time()
Â  Â  Â  Â  total_loss.backward()
Â  Â  Â  Â  torch.cuda.synchronize(); time_accumulators["backward"] += time.time() - time.time()

Â  Â  Â  Â  # --- ä¼˜åŒ–ä¸è‡´å¯†åŒ– ---
Â  Â  Â  Â  torch.cuda.synchronize(); time_start = time.time()
Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  if iteration < opt.densify_until_iter:
Â  Â  Â  Â  Â  Â  Â  Â  gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])
Â  Â  Â  Â  Â  Â  Â  Â  gaussians.add_densification_stats(viewspace_point_tensor.grad, visibility_filter)
Â  Â  Â  Â  Â  Â  Â  Â  if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  size_threshold = 20 if iteration > opt.opacity_reset_interval else None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold)
Â  Â  Â  Â  Â  Â  Â  Â  if iteration % opt.opacity_reset_interval == 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gaussians.reset_opacity()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if iteration < opt.iterations:
Â  Â  Â  Â  Â  Â  Â  Â  gaussians.optimizer.step()
Â  Â  Â  Â  Â  Â  Â  Â  gaussians.optimizer.zero_grad(set_to_none = True)
Â  Â  Â  Â  torch.cuda.synchronize(); time_accumulators["optimizer_densify"] += time.time() - time.time()
Â  Â  Â  Â Â 
Â  Â  Â  Â  torch.cuda.synchronize(); iter_total_end_time = time.time()
Â  Â  Â  Â  time_accumulators["total_iteration"] += iter_total_end_time - iter_total_start_time

Â  Â  Â  Â  # --- æ—¥å¿—ã€è¯„ä¼°ä¸ä¿å­˜ ---
Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  current_psnr = psnr(image, gt_image).mean().item()
Â  Â  Â  Â  Â  Â  progress_bar.set_postfix({
Â  Â  Â  Â  Â  Â  Â  Â  "Loss": f"{total_loss.item():.5f}",
Â  Â  Â  Â  Â  Â  Â  Â  "PSNR": f"{current_psnr:.2f}",
Â  Â  Â  Â  Â  Â  Â  Â  "Gaussians": f"{gaussians.get_xyz.shape[0]}"
Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  # å›ºå®šçš„é‡Œç¨‹ç¢‘ä¿å­˜
Â  Â  Â  Â  Â  Â  if (iteration in saving_iterations):
Â  Â  Â  Â  Â  Â  Â  Â  print(f"\n[ITER {iteration}] Saving milestone Gaussians...")
Â  Â  Â  Â  Â  Â  Â  Â  scene.save(iteration)

Â  Â  Â  Â  Â  Â  # å‘¨æœŸæ€§çš„æµ‹è¯•ä¸æœ€ä½³æ¨¡å‹ä¿å­˜
Â  Â  Â  Â  Â  Â  if (iteration in testing_iterations):
Â  Â  Â  Â  Â  Â  Â  Â  print(f"\n[ITER {iteration}] Testing...")
Â  Â  Â  Â  Â  Â  Â  Â  current_test_psnr, _ = validation_report(None, iteration, scene, render, (pipe, background))
Â  Â  Â  Â  Â  Â  Â  Â  last_test_psnr = current_test_psnr
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if current_test_psnr > best_test_psnr:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  best_test_psnr = current_test_psnr
Â  Â  Â  _message_num=2, truncated=True