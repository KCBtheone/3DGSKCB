#
# Robust Headless Renderer for 3D Gaussian Splatting (v2)
# Fixes AttributeError by manually moving all tensors for non-Module GaussianModel
#

import os
import sys
import torch
import re
from argparse import ArgumentParser
from PIL import Image
from tqdm import tqdm

# --- ç¡®ä¿é¡¹ç›®è·¯å¾„åœ¨sys.pathä¸­ ---
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from arguments import ModelParams, PipelineParams, OptimizationParams 
    from scene import Scene, GaussianModel
    from gaussian_renderer import render
    from utils.system_utils import searchForMaxIteration
    from utils.general_utils import safe_state
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥ï¼Œè¯·ç¡®ä¿æ­¤è„šæœ¬ä½äºgaussian-splattingé¡¹ç›®æ ¹ç›®å½•: {e}")
    sys.exit(1)

# ==================== 1. é…ç½®åŠ è½½å‡½æ•° (ä¸å˜) ====================
def load_config(cfg_path: str) -> dict:
    # ... (è¿™éƒ¨åˆ†ä»£ç ä¸ä¹‹å‰å®Œå…¨ç›¸åŒï¼Œæ­¤å¤„çœç•¥ä»¥ä¿æŒç®€æ´) ...
    try:
        import pickle
        with open(cfg_path, 'rb') as f: args_namespace = pickle.load(f)
        return vars(args_namespace)
    except Exception:
        try:
            with open(cfg_path, 'r') as f: content = f.read().strip()
            if content.startswith("Namespace(") and content.endswith(")"): content = content[10:-1]
            pattern = re.compile(r"(\w+)\s*=\s*('([^']*)'|\"([^\"]*)\"|\[.*?\]|[\w.-]+|True|False|None)")
            matches = pattern.findall(content)
            cfg_dict = {}
            for key, val_group, str_val1, str_val2 in matches:
                val_str = val_group
                if (val_str.startswith("'") and val_str.endswith("'")) or (val_str.startswith('"') and val_str.endswith('"')): cfg_dict[key] = val_str[1:-1]
                elif val_str == 'True': cfg_dict[key] = True
                elif val_str == 'False': cfg_dict[key] = False
                elif val_str == 'None': cfg_dict[key] = None
                elif val_str.startswith('[') and val_str.endswith(']'):
                    try: cfg_dict[key] = eval(val_str)
                    except: cfg_dict[key] = val_str
                else:
                    try:
                        if '.' in val_str: cfg_dict[key] = float(val_str)
                        else: cfg_dict[key] = int(val_str)
                    except ValueError: cfg_dict[key] = val_str
            return cfg_dict
        except Exception as e: raise IOError(f"æ— æ³•å°† '{os.path.basename(cfg_path)}' è§£æä¸ºä»»ä½•å·²çŸ¥æ ¼å¼ã€‚é”™è¯¯: {e}")


# ==================== 2. æ¸²æŸ“æ ¸å¿ƒå‡½æ•° (æœ€ç»ˆä¿®å¤ç‰ˆ) ====================
@torch.no_grad()
def render_and_save(model_path: str, output_path: str, source_path: str, iteration_name: str = "best"):
    
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ æ¸²æŸ“ç›®æ ‡è®¾å¤‡: {device}")
    print(f"å¼€å§‹å¤„ç†æ¨¡å‹: {model_path}")

    # --- 1. åŠ è½½æ¨¡å‹é…ç½® (ä¸å˜) ---
    parser = ArgumentParser(description="æ¸²æŸ“è„šæœ¬å‚æ•°åŠ è½½å™¨")
    model_params_def = ModelParams(parser)
    pipe_params_def = PipelineParams(parser)
    opt_params_def = OptimizationParams(parser)
    args_defaults = parser.parse_args([])

    cfg_path = os.path.join(model_path, "cfg_args")
    saved_cfg_dict = load_config(cfg_path)
    for k, v in saved_cfg_dict.items():
        if hasattr(args_defaults, k): setattr(args_defaults, k, v)
    
    args_defaults.source_path = source_path
    args_defaults.model_path = model_path
    if not hasattr(args_defaults, 'sh_degree'): args_defaults.sh_degree = 3
        
    model_params = model_params_def.extract(args_defaults)
    pipe_params = pipe_params_def.extract(args_defaults)
    opt_params = opt_params_def.extract(args_defaults)
    if not hasattr(pipe_params, 'debug'): safe_state(False); pipe_params.debug = False

    # --- 2. ä» .pth æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹ ---
    load_iteration = iteration_name
    if load_iteration == "best":
        load_iteration = searchForMaxIteration(os.path.join(model_path, "point_cloud"))
    
    chkpt_file = f"chkpnt{load_iteration}.pth"
    chkpt_path = os.path.join(model_path, chkpt_file)
    
    gaussians = GaussianModel(model_params.sh_degree)
    
    print(f"    -> [INFO] æ­£åœ¨ä» '{chkpt_file}' åŠ è½½...")
    checkpoint = torch.load(chkpt_path, map_location="cpu")

    model_params_from_ckpt = checkpoint[0] if isinstance(checkpoint, tuple) else checkpoint
    gaussians.restore(model_params_from_ckpt, opt_params) 

    # <<< â€¼ï¸â€¼ï¸ æœ€ç»ˆæ ¸å¿ƒä¿®å¤ï¼šæ‰‹åŠ¨å°†æ¨¡å‹æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ°æ­£ç¡®è®¾å¤‡ â€¼ï¸â€¼ï¸ >>>
    print("    -> [INFO] æ‰‹åŠ¨å°†æ‰€æœ‰æ¨¡å‹å¼ é‡ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡...")
    
    # å®šä¹‰æ‰€æœ‰éœ€è¦è½¬ç§»çš„å¼ é‡å±æ€§å
    tensor_attributes = [
        '_xyz', '_features_dc', '_features_rest', 
        '_scaling', '_rotation', '_opacity',
        'max_radii2D', 'xyz_gradient_accum', 'denom'
    ]
    
    for attr_name in tensor_attributes:
        if hasattr(gaussians, attr_name):
            tensor = getattr(gaussians, attr_name)
            if isinstance(tensor, torch.Tensor):
                # ç»Ÿä¸€å¤„ç† Parameter å’Œ Tensor
                if isinstance(tensor, torch.nn.Parameter):
                    setattr(gaussians, attr_name, torch.nn.Parameter(tensor.to(device)))
                else:
                    setattr(gaussians, attr_name, tensor.to(device))
    
    print(f"    -> [æˆåŠŸ] æ¨¡å‹åŠ è½½æˆåŠŸï¼ŒåŒ…å« {gaussians.get_xyz.shape[0]} ä¸ªç‚¹ã€‚")
    print(f"    -> [INFO] æ¨¡å‹å·²å®Œå…¨è½¬ç§»åˆ° {device}.")

    # --- 3. åŠ è½½åœºæ™¯å’Œè®­ç»ƒç›¸æœº ---
    print("  -> æ­¥éª¤3: åŠ è½½åœºæ™¯å’Œè®­ç»ƒç›¸æœº...")
    scene = Scene(model_params, gaussians, shuffle=False)
    train_cameras = scene.getTrainCameras()
    print(f"    -> [æˆåŠŸ] æˆåŠŸåŠ è½½ {len(train_cameras)} ä¸ªè®­ç»ƒç›¸æœºã€‚")
    
    # --- 4. å‡†å¤‡æ¸²æŸ“ ---
    print("  -> æ­¥éª¤4: å‡†å¤‡æ¸²æŸ“...")
    os.makedirs(output_path, exist_ok=True)
    background = torch.tensor([1,1,1] if model_params.white_background else [0,0,0], dtype=torch.float32, device=device)

    # --- 5. å¾ªç¯æ¸²æŸ“å¹¶ä¿å­˜ ---
    print("  -> æ­¥éª¤5: å¼€å§‹æ¸²æŸ“å¹¶ä¿å­˜å›¾åƒ...")
    for camera in tqdm(train_cameras, desc="æ¸²æŸ“è®­ç»ƒè§†è§’"):
        # ç¡®ä¿ç›¸æœºå†…éƒ¨çš„å¼ é‡ä¹Ÿåœ¨GPUä¸Š
        camera.to_device(device)

        render_pkg = render(camera, gaussians, pipe_params, background)
        rendered_image_tensor = render_pkg["render"].clamp(0.0, 1.0)
        
        rendered_np = (rendered_image_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype("uint8")
        pil_image = Image.fromarray(rendered_np)

        image_name = os.path.splitext(camera.image_name)[0]
        output_filename = os.path.join(output_path, f"{image_name}.png")
        pil_image.save(output_filename)

    print(f"\nâœ… æ¸²æŸ“å®Œæˆï¼æ‰€æœ‰ {len(train_cameras)} å¼ è®­ç»ƒè§†è§’å›¾åƒå·²ä¿å­˜è‡³ '{output_path}'ã€‚")

if __name__ == "__main__":
    parser = ArgumentParser(description="åŠ è½½ä¸€ä¸ª3DGSæ¨¡å‹å¹¶æ¸²æŸ“å…¶æ‰€æœ‰è®­ç»ƒè§†è§’ã€‚")
    parser.add_argument("model_path", type=str, help="æŒ‡å‘æ¨¡å‹å®éªŒç›®å½•çš„è·¯å¾„ã€‚")
    parser.add_argument("output_path", type=str, help="ä¿å­˜æ¸²æŸ“å›¾åƒçš„è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ã€‚")
    parser.add_argument("-s", "--source_path", type=str, required=True, help="ã€å¿…éœ€ã€‘æŒ‡å‘åŸå§‹åœºæ™¯æ•°æ®æºçš„è·¯å¾„ã€‚")
    parser.add_argument("--iteration", type=str, default="15000", help="è¦åŠ è½½çš„æ¨¡å‹è¿­ä»£æ¬¡æ•° (ä¾‹å¦‚ '15000')ã€‚")
    parser.add_argument("--resolution", type=int, default=-1, help="æ¸²æŸ“åˆ†è¾¨ç‡ç¼©æ”¾æ¯”ä¾‹ã€‚-1 è¡¨ç¤ºä½¿ç”¨è®­ç»ƒæ—¶çš„åˆ†è¾¨ç‡ã€‚")
    
    args = parser.parse_args()

    # ä¸ºäº†è®©Cameraç±»èƒ½æ­£ç¡®ç§»åŠ¨åˆ°è®¾å¤‡ï¼Œæ·»åŠ ä¸€ä¸ªè¾…åŠ©æ–¹æ³•
    from scene.cameras import Camera
    def camera_to_device(self, device):
        for attr in ['world_view_transform', 'full_proj_transform', 'camera_center']:
            if hasattr(self, attr):
                tensor = getattr(self, attr)
                if isinstance(tensor, torch.Tensor):
                    setattr(self, attr, tensor.to(device))
    Camera.to_device = camera_to_device
    
    render_and_save(args.model_path, args.output_path, args.source_path, args.iteration)